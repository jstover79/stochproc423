# Random walks

The random walk will be one of our first official stochastic process models. It models a particle on a line jumping one unit left or right with equal probability. Variations of this can be used for modeling many physical phenomena, including:

1. a viral particle floating in the air (a 3D random walk), 

2. an animal moving in its habitat (2D for most land animals, but 1D can work for a restricted habitat), or

3. a stock price (1D).

## The simple symmetric random walk (SSRW)

We let $X_n$ be the state of the process at time step $n$ and fix $X_0=0$ (the particle starts at the origin). The particle moves left or right with equal probability, which is given as
$$P(X_{n+1}=j-1\mid X_n=j)=\frac12,$$
$$P(X_{n+1}=j+1\mid X_n=j)=\frac12.$$
We consider the choice at each time step to go up or down as being independent of every other time step. This model is of a special class of stochastic processes called Markov chains,b ut we'll discuss those in more detail later.

We can construct this model mathematically in more detail be letting the $n^{th}$ step be random variable $Y_n$ which takes values $\pm1$ with equal probability and all being independent. We say that the $Y_n$ are **i.i.d. (independent and identically distributed)** with $P(Y_n=1)=P(Y_n=-1)=\frac12$ for all $n$. Independence here means that if we want to calculate probabilities for multiple $Y_n$ simultaneously, we can calculate them individually and multiply:
$$P(Y_j=a,Y_k=b)=P(Y_j=a)P(Y_k=b)$$
for any $i,j\in\mathbb N$ (with $i\neq j$) and any $a,b\in\{-1,1\}$. Then we can write
$$X_n=\sum_{j=1}^n Y_j.$$

::: exbox
**Example.** Calculate $P(X_3=3)$. This is only possible if $Y_1=Y_2=Y_3=1$ and so we calculate
$$P(Y_1=1,Y_2=1,Y_3=1)=P(Y_1=1)P(Y_2=1)P(Y_3=1)=\frac12\cdot\frac12\cdot\frac12=\frac18.$$
:::


::: exbox
**Example.** Calculate $P(X_2=0)$. This is only possible if $Y_1=1,Y_2=-1$ or $Y_1=-1,Y_2=1$ and so we calculate each probability and add the result.
$$P(X_2=0)=P(Y_1=1,Y_2=-1)+P(Y_1=-1,Y_2=1)=\frac14+\frac14=\frac12.$$
:::

The state space of the SSRW is thus the set of integers $\mathbb Z$ and the time index set is $\mathbb N_0$. The sample path space will be all infinitely long sequences of integers where consecutive integers only differ by $\pm1$. We could say that the sample path space is all infinite sequences of integers, but most of those will have probability zero since any sequence which jumps outside of $\pm1$ would be considered as not possible.

So we have our sequence of random variables $(X_0,X_1,X_2,\ldots)$. Of course, $X_0$ is deterministically set to one, but we can still consider it a random variable with full probability mass on one. Now $X_1$ is equally likely to be $\pm1$. If $X_1=1$, then $X_2$ is equally likely to be $0,2$, and if $X_1=-1$, then $X_2$ is equally likely to be $0,-2$.


<!-- We illustrate part of the sample path space below. -->



## Distribution of $X_n$

Since $X_n$ is a random sum of a bunch of plus and minus ones, we can realte it to a sum of Bernoulli random variables. If we think of flipping a fair coint $n$ times and let $H$ be the number of heads and $T$ be the number of tails, then we must have $H+T=n$. If the $j^{th}$ coint flip is heads, we set $Y_j=1$ and if it is tails, we set $Y_j=-1$. In this way, we can reason that $$X_n=(\# \text{ heads})-(\# \text{ tails})=H-T=H-(n-H)=2H-n.$$
Since we know that $H\sim\mathsf{binom}(n,\frac12)$ ($H$ is governed by the binomial distribution with $n$ trials and $p=\frac12$ probability of success), we can use this to calculate probabilities for $X_n$:

::: thmbox
**Distribution of $X_n$ for SSRW.** 
$$P(X_n=j)=P(2H-n=j)=P\left(H=\frac{n+j}{2}\right)={n\choose \frac{n+j}{2}}\frac1{2^n}.$$
:::

Now we refresh the normal approximation to the binomial.

::: defbox
**Normal approximation to binomial.** 
Let $X\sim\mathsf{binom}(n,p)$, then for $n$ large (usually $n\geq 30$ with $np\geq5$ and $n(1-p)\geq5$ is acceptable, but it might still be a rough approximation). Then we can say that 
$$X\overset{\small approx}{\sim} \mathsf{N}(\mu=np,\sigma^2=np(1-p)).$$
:::

The binomial is a discrete distribution, but the normal is a continuous distribution. Any time we use a continuous distribution to approximate a discrete distribution, it might be useful to use a **continuity correction**.

<!-- ::: defbox -->
**Continuity correction.** 
If discrete random variable $X$ has values $x_1,x_2,\ldots$ and we wish to approximate $P(X=x_j)$ by continuous random variable $Y$, then we can integrate the probability density function of $Y$ from halfway to the next $x$-values on the left and right:
$$P(X=x_j)\approx P(x_j-(x_j-x_{j-1})/2 < Y \leq x_j+(x_j-x_{j-1})/2).$$
For the normal approximation to the binomial random variable $X\sim binom(n,p)$, this translates to using $Y\sim N(np,np(1-p))$ and 
$$P(X=k)\approx P\left(k-\frac12 < Y \leq k+\frac12\right).$$
<!-- ::: -->

<!-- ::: thmbox -->
**Normal approximation to distribution of $X_n$ for SSRW.** 
We have that 
$$P(X_n=j)=P(2H-n=j)=P\left(H=\frac{n+j}{2}\right)$$
and that $H$ is binomial distributed with parameters $n,p$ and hence is approximately normally distributed with mean $\mu=np$ and variance $\sigma^2=np(1-p)$. Now we can then write
$$P(X_n=j)=P(2H-n=j)=P\left(H=\frac{n+j}{2}\right)\approx P\left(\frac{n+j}{2}-\frac12<Y\leq \frac{n+j}{2}+\frac12\right)$$
where $Y\sim\mathsf N(\mu=np,\sigma^2=np(1-p))$.

In R we can calculate normal cumulative probabilities using `pnorm()`, so the above probability for $P(X_n=j)$ is given by the R code (with the continuity correction)
<!-- $$P(X_n=j)=\texttt{pnorm((n+j)/2+1/2,n*p,sqrt(n*p*(1-p)))-pnorm((n+j)/2-1/2,n*p,sqrt(n*p*(1-p)))}}$$ -->
<!-- $$P(X_n=j)=$$ -->
```{r, eval=FALSE, echo=TRUE}
pnorm((n+j)/2+1/2,mean=n*p,sd=sqrt(n*p*(1-p)))-pnorm((n+j)/2-1/2,mean=n*p,sd=sqrt(n*p*(1-p)))
```
<!-- ::: -->

::: exbox
**Example.** Let's calculate $P(X_7=-3)$. We have $n=7$, $p=0.5$, and $j=-3$. The exact calculation using the distribution we derived from the bionomial is:
$$P(X_7=-3)={7\choose\frac{7-3}{2}}\frac1{2^7}={7\choose2}\frac1{2^7}=\frac{7\cdot 3}{2^7}\approx0.1640625.$$
And using the normal approximation (with continuity correction) we get:
$P(X_7=-3)\approx$`pnorm(2.5,7/2,sqrt(7)/2)-pnorm(1.5,7/2,sqrt(7)/2)`$\approx0.1595609$ which is a reasonable approximation.
:::

We can make the R code a bit simpler though.

<!-- ::: thmbox -->
If $X\sim N(\mu\sigma^2)$ then $aX+b\sim N(a\mu+b,a^2\sigma^2)$. This means that $aX+b$ is a normal random variable as well with $E(aX+b)=a\mu+b$ and $Var(aX+b=a^2\sigma^2)$. Since we are approximating $H$, the number of up steps, as a normal random variable, then $2H-n$ is also approximately normally distributed. 
$$X_n=2H-n\overset{\small approx}{\sim}\mathsf{N}(\mu=2np-n,\sigma^2=4np(1-p)).$$
And for the SSRW this means
$$X_n=2H-n\overset{\small approx}{\sim}\mathsf{N}(\mu=0,\sigma^2=n).$$
Now to apply the continuity correction is a bit trickier though, because $X_n$ only takes on values $-n,-n+2,\ldots,n-2,n$. Instead of adding and subtracting $\frac12$, we must add and subtract $1$ and $P(X_n=j)$ is approximated by `pnorm(j+1,0,sqrt(n))-pnorm(j-1,0,sqrt(n))`.

<!-- ::: -->


## Reflection principle

Now we'll look at a property of the sample path space which will help us understand a few more properties for the random walk. Consider some state $m$ which we are interested in the RW hitting at some time step $n=0,1,2,\ldots,k$. Clearly we must consider $m$ between $-k$ and $k$ since the RW can only go that far in $k$ time steps.

## Maximum state

## Hit time for state $1$

<!-- ## RW2 -->

<!-- ::: exbox -->
<!-- **Example.** -->
<!-- here is an example problem... -->
<!-- <details> -->
<!-- <summary> -->
<!-- show/hide solution -->
<!-- </summary> -->
<!-- Here is the solution, we use the following theorem: -->

<!-- ::: thmbox -->
<!-- **Theorem.** Here is a hidden theorem... -->
<!-- ::: -->

<!-- and that solves it! -->
<!-- </details> -->
<!-- ::: -->



## Summary {-}

::: defbox
**Summary of notation, formulas, and terminology**

For $X_n$ the simple 1D random walk with $p$ probability of an up step:

$P(X_n=j)={n\choose (n+j)/2}p^{(n+j)/2}(1-p)^{(n-j)/2}$<br>
&nbsp;&nbsp;&nbsp; For SSRW: $P(X_n=j)={n\choose (n+j)/2}\frac1{2^n}$

$P(X_n=j)\approx$`pnorm(j+1,2*n*p-n,sqrt(4*n*p*(1-p)))-pnorm(j-1,2*n*p-n,sqrt(4*n*p*(1-p)))`<br>
&nbsp;&nbsp;&nbsp; For SSRW: $P(X_n=j)\approx$`pnorm(j+1,0,sqrt(n)-pnorm(j-1,0,sqrt(n))`<br>

$P(T_1=2k+1)=\frac1{k+1}{2k\choose k}\frac1{2^{2k+1}}$, $T_1=~$first time SSRW ($p=\frac12$) to hit state $1$

$P(T_1=2k+1)=\frac1{k+1}{2k\choose k}p^{k+1}(1-p)^k$, $T_1=~$first time SARW (any $p\in[0,1]$) to hit state $1$

:::
