[["markov-chains.html", "Chapter 7 Markov Chains 7.1 Graph of a Markov chain 7.2 Classification of states Summary", " Chapter 7 Markov Chains Markov chains are one of the most important classes of stochastic process. A discrete-time Markov chain (DTMC) consists of specifying a state space and a transition matrix. For us, our state space will generally be \\(S=\\{0,1,\\ldots,k\\}\\) and our time index set will be \\(\\mathbb N_0\\). The transition matrix gives us the transition probabilities between each pair of states and is given as \\[T= \\left(\\begin{matrix} T_{00} &amp; T_{01} &amp; \\cdots &amp; T_{0k}\\\\ T_{10} &amp; T_{11} &amp; \\cdots &amp; T_{1k}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ T_{k0} &amp; T_{k1} &amp; \\cdots &amp; T_{kk}\\\\ \\end{matrix}\\right)\\] where \\[T_{ij}=P(X_n=j\\mid X_{n-1}=i).\\] 7.1 Graph of a Markov chain For a Markov chain with state space \\(S\\), we can represent the possible transitions graphically in Euclidean space. For now, lets assume the state space is finite, but even chains with infinite state spaces can have graphs constructed in this way. Plot a point for each state in the plane \\(\\mathbb R^2\\), and label each point by the state it corresponds to. Draw a directed edge (an arrow) from \\(i\\) to \\(j\\) whenever \\(T_{ij}&gt;0\\). We can use install.packages(\"igraph\") if we wish to plot transition graphs for Markov chains. Consider the transition matrix \\[ T=\\begin{pmatrix} 0.5 &amp; 0.3 &amp; 0.2\\\\ 0 &amp; 0.3 &amp; 0.7\\\\ 0.5 &amp; 0.5 &amp; 0 \\end{pmatrix}. \\] Here is some R code for plotting the transition diagram along with the plot. library(igraph) tmvec &lt;- c(0.5,0.3,0.2, 0.0,0.7,0.3, 0.5,0.5,0.0) TM &lt;- matrix(tmvec,byrow=T,nrow=3) mcg &lt;- graph_from_adjacency_matrix(1*(TM&gt;0)) plot.igraph(mcg, vertex.size=50, vertex.color=&quot;grey90&quot;, edge.curved=0.25, edge.color=&quot;black&quot;, edge.label=tmvec[tmvec&gt;0], edge.loop.angle=c(pi,0,0), margin=0.1, loop.size=2) 7.2 Classification of states State \\(j\\) is accessible from state \\(i\\), denoted \\(i\\to j\\) if there is a path from state \\(i\\) to state \\(j\\) in the graph. This means that \\((T^n)_{ij}&gt;0\\) for some \\(n\\). States \\(i\\) and \\(j\\) communicate if they are both accessible from each other, i.e.Â that \\(i\\to j\\) and \\(j\\to i\\). This is denoted \\(i\\leftrightarrow j\\). Summary Summary of notation, formulas, and terminology Markov property (memorylessness): \\[P(X_n=k \\mid X_{n-1}=\\ell,X_{n-2}=\\ell_{n-2},\\ldots,X_{1}=\\ell_{1},X_{0}=\\ell_{0})=P(X_n=k \\mid X_{n-1}=\\ell)\\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
