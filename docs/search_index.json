[["index.html", "Math 423 Stochastic Processes Course Notes Introduction", " Math 423 Stochastic Processes Course Notes Joseph Stover 2023-01-25 Introduction Stochastic processes is the mathematical theory of random phenomena. Our working definition of a random phenomenon or process, is one that we cannot predict accurately. Physical processes are often not predictable for a variety of reasons. Typically, we quantify a physical process somehow, e.g. by taking measurement at specific times. If each measurement is unpredicatable (random), then our sequence of measurements is a stochastic process! You have seen random variables in previous probability or statistics courses. A random variable \\(X\\) takes on real number values, but we cannot predict what precise value it will take perfectly… it is random. One can think of performing a random experiment such as rolling a die and letting \\(X\\) be the number of dots on the upper face or observing some physical process like drilling an oil well with \\(X\\) being the amount of oil produced on the first day or growing a plant and letting \\(X\\) be the height of the plant after one month of growth. In all of the examples \\(X\\) just takes on a single numerical value. A stochastic process tracks these processes over time. Let \\(X_n\\) be the outcome of the \\(n^{th}\\) die roll, the height of the plant after month \\(n\\), or the amount of oil produced during day \\(n\\). In this way a stochastic process can initially be thought of as a sequence of random variables. Here are some examples of how a stochastic process might model a physical process. Modeling the daily closing price of a stock for one year. Modeling the number of insurance claims in each month over a year. The number of new infections each day for a particular disease. Tracking radioactive decays over time. The location of an animal as it moves through its habitat, e.g. the distance from a bird to its nest as a funciton of time. Each of these physical phenomena are highly unpredictable, and so we generally treat them as “random.” "],["introduction-to-r-and-rstudio.html", "Chapter 1 Introduction to R and RStudio 1.1 Getting access to R and RStudio 1.2 Installing and using packages in R 1.3 Calculating probabilities 1.4 Simulation of random variables 1.5 Basics of programming, R scripts 1.6 Importing datasets", " Chapter 1 Introduction to R and RStudio R is a statistical software package and a computer programming language. It is widely used in both industry (e.g. by data scientists) and academic research. RStudio is a graphical interface for R. Here I will give a brief introduction to R and RStudio. 1.1 Getting access to R and RStudio There are two main ways to use R: install R and RStudio locally on your computer, or use Posit cloud. (Posit is the company that makes RStudio) Posit Cloud: I strongly suggest getting an account on Posit Cloud (this is the company that makes RStudio). Then you have access to a fully-capable and up-to-date version of R and RStudio form any web browser on any device. Go to: https://posit.cloud/, and sign up. Their free account simply has computation time limitations which should be no problem for most casual users. Alternatively, you can download and install R and RStudio Desktop locally on your computer. I recommend doing this, especially if you are more serious about learning R or running programs that require more computation time. Downloading and installing R statistical software: I recommend two things: Install R. This is the actual statistical software. Install RStudio Desktop. This is a nice user interface for R. *Note that the actual software version numbers change frequently, and they are, as of writing, R 4.2.2 and RStudio Desktop 2022.12.0+353. Getting R: First, download the appropriate version (Windows, Mac, etc.) of R from here: https://cloud.r-project.org/ For Windows: Click on “Download R for Windows”, then click on “install R for the first time”, then click on “Download R-4.2.2 for Windows”. Then install the software. For Mac OS: Click on “Download R for macOS”, then click on either “R-4.2.2-arm64.pkg” or “R-4.2.2.pkg” (depending on macOS version and processor type). Then install the software. I am more proficient at Windows than Mac, but if you have trouble installing it, come see me and I should be able to help you get it figured out. There are also Linux/Unix options—I am familiar with Ubuntu and so should be able to help on those platforms as well. Getting RStudio Desktop: After you have R installed, I recommend installing RStudio Desktop in order to have access to a more friendly user interface. I will always be using RStudio when I show demonstrations in class. Simply go here: https://posit.co/download/rstudio-desktop/#download and choose your desired version. The webpage should automatically detect your operating system and provide you with a link to the correct version of RStudio. You can scroll down the page and see links to various versions though. For Windows, the first link should work: “Windows 10/11 RSTUDIO-2022.12.0-353.EXE”. For MacOS the second link should work: “macOS 11+ RSTUDIO-2022.12.0-353.DMG”. Install the software. Done! There is also a link for older versions of RStudio in case you have an older version of Windows, MacOS, or Linux, etc. Brief test of R &amp; RStudio: Launch RStudio Desktop or open a Posit Cloud Workspace/Project. Locate the “Console” subwindow. This is where we will type our commands. Type x &lt;- 3 in the console next to the “&gt;” (which is a command prompt that you will always type command next to). Then press the enter or return key on your keyboard. This saves the value of 3 for the variable x. Then type x+5 and hit enter. You should see the output [1] 8. This indicates the result of the computation. The “[1]” indicates that the output is a single number. Later on we will learn many interesting commands that are useful. Now you know how to open RStudio and use it as a calculator! The RStudio user interface is shown below. The most important parts are highlighted and labeled wtih brief descriptions. The RStudio user interface. Using R online through other sources: Another option for using R statistical software is to use one of the many places online where you can use it through a web browser. There are many such websites. Here is one website where you can conveniently evaluate R code online from a web browser in any device: https://rdrr.io/snippets/ Another option for having quick access to R (and this is useful for a smartphone) is SageCell at: https://sagecell.sagemath.org/. This website can be used to evaluate commands from a variety of programming languages (including MATLAB and Python). Just select R from the language tab at the lower right of the textbox. If you are familiar with MATLAB, choose the option “Octave”. Octave is basically an open source version of MATLAB and you can run MATLAB code using the Octave language option on SageCell. 1.2 Installing and using packages in R It is common for software developers to develop libraries or packages which contain functions and methods. The purpose is the same as a mathematical function. Rather than you rewriting the equation each time, you can program the function and simply call that computer function with a single letter rather than a complicated formula. As an example, R has some base functionality for matrix computations, but in order to raise matrices to exponents, you need to expm package. Generally to install a package named “packagename” we execute the command install.packages(\"packagename\"). Once a package is installed, in order to use the methods and functions it includes, they must be loaded into R’s active workspace and can be done by executing the command library(packagename). In order to run the stock simulation code we need to install the packages quantmod and RQuantLib. To do this, execute the commands: install.packages(\"quantmod\") and install.packages(\"RQuantLib\"). You’ll see some output indicating what R is doing, downloading some files, unpacking them, and installing them. Sometimes it may even be compiling some code in the background. Usually it takes a few seconds to minutes to install a new package. Once a package is installed, in order to use the methods and functions it includes, execute the command library(packagename), e.g. library(quantmod). Notice that installing a package require quotation marks around the package name, but calling it into R’s workspace does not. 1.3 Calculating probabilities under construction 1.4 Simulation of random variables under construction 1.5 Basics of programming, R scripts under construction 1.6 Importing datasets under construction "],["stochastic-processes.html", "Chapter 2 Stochastic Processes", " Chapter 2 Stochastic Processes Generally, a stochastic process consists of an index set \\(T\\) which can usually be thought of as time, and at each time \\(t\\in T\\) we have a (real-valued) random variable \\(X_t\\). We write this as \\((X_t)_{t\\in T}\\) or \\(\\{X_t\\}_{t\\in T}\\). We can think of \\(X_t\\) as a random function of time. You have seen functions of time like \\(x(t)\\) where you plug in a \\(t\\)-value and it outputs an exact \\(x(t)\\)-value according to some formula, but for a stochastic process \\(X_t\\), even when the \\(t\\)-value is specified, we cannot know the precise value for \\(X_t\\) since it is still random. The index set is usually a subset of the set of natural numbers \\(\\mathbb N=\\{1,2,\\ldots\\}\\) or those including zero \\(\\mathbb N_0=\\{0,1,2,\\ldots\\}\\) or a subset of the real numbers \\(\\mathbb R\\). For example, we can have \\(T=\\{1,2\\}\\), \\(T=\\mathbb N_0\\), \\(T=[0,\\infty)\\subset\\mathbb R\\), or \\(T=[0,1]\\). If the index set is discrete, we call it a discrete-time stochastic process and if the index set is continuous (an interval subset of \\(\\mathbb R\\)), we call it a continuous-time stochastic process. Normally, we use \\(X_n\\) for discrete time and \\(X_t\\) for continuous time. If \\(T=\\{1,2\\}\\), then our stochastic process is \\((X_1,X_2)\\) and is a random point in the plane \\(\\mathbb R^2\\). If \\(T=\\mathbb N_0\\), then our stochastic process is \\((X_0, X_1,X_2,\\ldots)\\) and is a random point in \\(\\mathbb R^\\infty\\) (in other words, a infinite sequence of random numbers). If the index set is a continuous interval such as \\(T=[0,1]\\) or \\(T=[0,\\infty)\\), then we can think of \\(X_t\\) as a random function of \\(t\\). The state space \\(S\\) is the set where each random variable \\(X_t\\) takes its values in. Normally, the state space is a subset of the real numbers. Often, we are counting things and the state space will be \\(\\mathbb N\\) or \\(\\mathbb N_0\\), e.g., counting the number of insurance claims that arrive each day or counting the number of radioactive decays every hour. We call such a stochastic process discrete-space. In other cases, we are measuring something like length or amount of money, and the state space is \\([0,\\infty)\\) or some other real line interval. Such stochastic processes are called continuous-space. There are two intuitive ways to think about a stochastic process. We can think of it as \\(X_t\\) where it is implied that we have several random variables, one variable for each value of \\(t\\). Alternatively, we can think of the entire random sequence or function as a single object and write \\(X=(X_t)_{t\\in T}\\). This \\(X\\) is not a random variable, it is a stochastic process. Each \\(X_t\\) is a real-valued random variable, but \\(X\\) is vector-valued, sequence-valued, or function-valued. In order to know the “value” of \\(X\\), we have to know the value of each \\(X_t\\) for every possible \\(t\\)-value. We can think of \\(X\\) as a random sequence of numbers, \\(X=(X_0,X_1,X_2,\\ldots)\\) where each \\(X_n\\) is a real-valued random variable. Definition. A stochastic process \\(X\\) with state space \\(S\\) and index set \\(T\\) is a collection of random variables \\(X=(X_t)_{t\\in T}\\). For each \\(t\\in T\\), \\(X_t\\) is a \\(S\\)-valued random variable, that is each \\(X_t\\) takes values in \\(S\\). Definition. For stochastic process \\(X=(X_t)_{t\\in T}\\) with state space \\(S\\) and (time) index set \\(T\\), a sample path is a particular full realization of the stochastic process. That is, we know the precise value of \\(X_t\\) for every \\(t\\). Sample paths are specific determined realizations, and we can say \\(x(t)\\) is a specific sample path, that is, it is just a (fixed) function of \\(t\\). Definition. For stochastic process \\(X=(X_t)_{t\\in T}\\) with state space \\(S\\) and (time) index set \\(T\\), the sample path space is \\(\\Omega=S^T\\), that is, if we know the precise value of \\(X_t\\) for all \\(t\\in T\\), then \\(X\\) is a function from \\(T\\) to \\(S\\). Example. Consider the stochastic process \\(X_n\\) for \\(n\\in\\mathbb N\\) and \\(X_n\\sim\\textsf{Bernoulli}(p)\\) for each \\(n\\). The state space is \\(S=\\{0,1\\}\\) since each \\(X_n\\) is a Bernoulli random variable, and the time index set is \\(\\mathbb N\\). The sample path space is \\(\\Omega=\\{0,1\\}^{\\mathbb N}\\) which can also be written as \\(\\{0,1\\}^\\infty\\) or \\(\\{0,1\\}\\times\\{0,1\\}\\times\\cdots\\). In this case \\(\\Omega\\) is just the set of all infinitely long sequences of 0’s and 1’s, which we call binary sequences. A particular sample path realization is a particuler fixed sequence of zeros and ones, e.g. \\((0,1,1,0,1,0,0,0,1,0,1,1,0,0,\\ldots)\\). A “typical” sample path should contain roughly an equal number of 1’s and 0’s over most of it. For example, the first 1000 states will be fairly close to equal parts 0 and 1 to high probability. We can precisely calculate the probability there are, say, less than 450 or more than 550 ones in this case using the binomial distribution. Let \\(Y\\sim\\textsf{Binom}(n=1000,p)\\) be the number of ones. Then \\(P(Y&lt;450\\text{ or }Y&gt;550)=1-P(450\\leq Y\\leq 550)=1-\\sum_{j=450}^{550}{1000\\choose j}p^j(1-p)^{1000-j}\\). If we let \\(p=\\frac12\\), then this is \\(1-\\sum_{j=450}^{550}{1000\\choose j}\\frac1{2^{1000}}\\). In \\(\\textsf{R}\\), we can compute this as 1-sum(dbinom(450:550,1000,0.5)). Since the number of trials is large, we can use the normal approximation 1-pnorm(550,500,sqrt(250))+pnorm(450,500,sqrt(250)) to see it is about 0.14% probability. Here are some examples of how a stochastic process might model a physical process. Example. Consider the following examples. A plant is growing in a pot and we want to model its total biomass over time for 1 year. Let \\(X_t\\) be the total biomass at time \\(t\\). We consider \\(X_t\\) for each \\(t\\) to be \\([0,\\infty)\\)-valued since biomass is nonnegative and we won’t impose any particular upper limit on biomass. We let \\([0,365]\\) be the (time) index set and will measure time in days. The state space is thus \\([0,\\infty)\\) and the sample path space is \\(\\Omega=[0,\\infty)^{[0,365]}\\). Each physical realization of a plant growing from germination to death will give us a particular sample path realization which will be a function from \\([0,365]\\) to \\([0,\\infty)\\). This is a continuous-time stochastic process. The number of insurance claims per month for a twelve month year. We let \\(X_n\\) be the number of insurance claims in month \\(n\\) with index set \\(\\{1,2,\\ldots,12\\}\\). The state space is \\(\\mathbb N_0\\) as we could have zero claims in a month or potentially any positive number of claims without any specific upper limit. The sample path space is \\(\\Omega=\\mathbb N_0^{12}\\). A particular sample path realization will be a twelve-tuple (duodecuple) of nonnegative integers, e.g. \\(x=(10,4,0,1,0,8,12,25,37,22,13,9)\\in\\Omega\\). Note that it is important that we consider the ordering of the index set, i.e. that \\(X_1=10, X_2=4\\), etc. Try to construct the following example using the technical stochastic process notation. Practice. Write stochastic process notation for the closing price of a stock each day for one week of five trading days. What is the index set? What is the sample path space? Give a possible sample path realization. Show/hide solution. Solution. Let the index set \\(\\{1,2,\\ldots,5\\}\\) represent days one to five. For each day \\(n\\), the random variable \\(X_t\\) is the closing price of the stock on that day. We can write \\(X=(X_n)_{n=1,2,\\ldots,5}\\) or \\(X=(X_1,X_2,X_3,X_4,X_{5})\\). The sample path space is \\([0,\\infty)^{5}\\) since each full realization of the stochastic process is a sequence of five dollar amounts. Each dollar amount should be nonnegative since a stock doesn’t ever have a negative price. An example sample path realization might be \\((105.27,103.52,97.21,95.13,96.83)\\) representing a possible realization of the closing prices on the five days. Summary of terminology and notation. \\(\\mathbb N=\\{1,2,\\ldots\\}\\) is the set of natural numbers. \\(\\mathbb N_0=\\{0,1,2,\\ldots\\}\\) is the set of natural numbers including zero. \\(\\mathbb R=(-\\infty,\\infty)\\) is the set of real numbers. \\(t\\in T\\) means \\(t\\) is an element of the set \\(T\\), e.g. \\(3\\in [-1,5]\\) or \\(\\pi\\in\\mathbb R\\). stochastic process \\(X=(X_t)_{t\\in T}\\), for each \\(t\\), \\(X_t\\) is a random variable. state space \\(S\\) is where observations of \\(X_t\\) will take values in, e.g. \\(S=[0,\\infty)\\) or \\(S=\\mathbb N_0\\). index set \\(T\\) gives the times we observe \\(X_t\\) at. discrete-time if \\(T\\) is discrete, and continuous-time if \\(T\\) is a continuous interval. discrete-space if \\(S\\) is discrete, and continuous-space if \\(S\\) is continuous. sample path space \\(\\Omega=S^T=\\) all functions from \\(T\\) to \\(S\\). sample path or path realization \\(x(t)\\in\\Omega\\) with \\(x:T\\to S\\). Next we’ll do some review of probability theory. "],["probability-review.html", "Chapter 3 Probability review 3.1 Probability basics 3.2 Random variables and distributions", " Chapter 3 Probability review under construction 3.1 Probability basics 3.2 Random variables and distributions Definition. A random variable \\(X\\) is a variable where you must perform a random experiment to determine its value. The sample space \\(S\\) is the set of numerical values that the random variable can take. An event is a subset of the sample space. A random variable can be either discrete (if it takes values in a discrete set such as \\(\\mathbb N\\)) or continuous (if it can take on any value in some intveral). Examples. Let \\(X\\) be the number of dots on the upper face of a dice roll. Let \\(X\\) be the mass of a randomly selected person form a specific population. Let \\(X\\) be the number of cars that pass by a given intersection druing a particular day. Let \\(X\\) be the number of radioactive decays in one hour of some particular material. Definition. A probability function allows us to calculate the probabilities of observing specific numerical values or ranges of values for random variable \\(X\\). A discrete random variable has a probability mass function (pmf) \\(f_X(x)=P(X=x)\\), and a continuous random variable has a probability density function (pdf) \\(f_X(x)\\) which we must integrate to get probabilities \\(P(a&lt;X&lt;b)=\\int_a^b f_X(x)dx\\). The cumulative distribution function (cdf) gives cumulative probabilities \\(F_X(x)=P(X\\leq x)\\). 3.2.1 Independence of random variables When working with introductory probability the idea of independent events was covered. Events \\(A\\) and \\(B\\) are independent if and only if \\(P(A\\cap B)=P(A)P(B)\\). Independence for random variables works similarly. Definition. Random variables \\(X\\) and \\(Y\\) are independent if and only if every \\(X\\)-event is independent of every \\(Y\\)-event. That is for every subset of possible \\(X\\)-values \\(A\\) and every subset of possible \\(Y\\)-values \\(B\\) we have \\[P(\\{X\\in A\\}\\cap \\{Y\\in B\\})=P(X\\in A)P(Y\\in B).\\] For discrete random variables \\(X\\) and \\(Y\\), they are independent if and only if \\(P(X=x,Y=y)=P(X=x)P(Y=y)\\) for all \\(x\\) and \\(y\\). That is the joint pmf must be exactly the product of the marginal pmfs. For continuous random variables \\(X\\) and \\(Y\\), they are independent if and only if their joint pdf is exactly the product of the marginal pdfs: \\(f_{X,Y}(x,y)=f_X(x)f_Y(y)\\). Note that for independent random variables, independence requires that the allowable values for one variable must not be affected by the other variable, e.g. the set of possible \\(X\\)-values must not depend on \\(Y\\) in any way. Example. Let \\(X\\) be the outcome of a fair 6-sided die and \\(Y\\) be the outcome of a fair coin flip (\\(0=~\\)tails,\\(1=~\\)heads). Then we naturally think of them as independent, and they are in the technical sense of the term. It makes physical sense that the coin flip shouldn’t impact the die roll at all unless we are to use some contrived mechanism to force them to interact, e.g. if a machine were to control the force of the coin flip and die roll is some specific way so that the coin tended to be heads when the die tended to be even. Here the marginal pmfs are \\(f_X(x)=\\frac16\\) for \\(x=1,2,3,4,5,6\\) (and zero otherwise), and the pmf for \\(Y\\) is \\(f_Y(y)=\\frac12\\) for \\(y=0,1\\). Their joint pmf is \\(f_{X,Y}(x,y)=\\frac1{12}\\) for \\((x,y)=(1,0),\\ldots,(6,0),(1,1),\\ldots,(6,1)\\). Example. Let \\(X\\) and \\(Y\\) have joint probabilities given by the table below. X 10 20 Y 5 0.5 0.2 500 0.1 0.2 You can actually look at the table and see that \\(X\\) and \\(Y\\) are not independent by seeing the \\(Y\\)-values of 5 and 500 have equal probability mass under the \\(X=20\\) column but unequal probability mass under the \\(X=10\\) column. It isn’t always that simple though. Here is a joint pmf for an independent \\(X,Y\\) pair, and it isn’t obvious they are independent. X 10 20 30 Y 5 0.36 0.18 0.06 500 0.24 0.12 0.04 3.2.2 Bernoulli, binomial, geometric 3.2.3 Uniform, exponential, normal "],["random-walks.html", "Chapter 4 Random walks 4.1 The simple symmetric random walk (SSRW)", " Chapter 4 Random walks The random walk will be one of our first official stochastic process models. It models a particle on a line jumping one unit left or right with equal probability. Variations of this can be used for modeling many physical phenomena, including: a viral particle floating in the air (a 3D random walk), an animal moving in its habitat (2D for most land animals, but 1D can work for a restricted habitat), or a stock price (1D). 4.1 The simple symmetric random walk (SSRW) We let \\(X_n\\) be the state of the process at time step \\(n\\) and fix \\(X_0=0\\) (the particle starts at the origin). The particle moves left or right with equal probability, which is given as \\[P(X_{n+1}=j-1\\mid X_n=j)=\\frac12,\\] \\[P(X_{n+1}=j+1\\mid X_n=j)=\\frac12.\\] We consider the choice at each time step to go up or down as being independent of every other time step. This model is of a special class of stochastic processes called Markov chains,b ut we’ll discuss those in more detail later. We can construct this model mathematically in more detail be letting the \\(n^{th}\\) step be random variable \\(Y_n\\) which takes values \\(\\pm1\\) with equal probability and all being independent. We say that the \\(Y_n\\) are i.i.d. (independent and identically distributed) with \\(P(Y_n=1)=P(Y_n=-1)=\\frac12\\) for all \\(n\\). Independence here means that if we want to calculate probabilities for multiple \\(Y_n\\) simultaneously, we can calculate them individually and multiply: \\[P(Y_j=a,Y_k=b)=P(Y_j=a)P(Y_k=b)\\] for any \\(i,j\\in\\mathbb N\\) (with \\(i\\neq j\\)) and any \\(a,b\\in\\{-1,1\\}\\). Then we can write \\[X_n=\\sum_{j=1}^n Y_j.\\] Example. Calculate \\(P(X_3=3)\\). This is only possible if \\(Y_1=Y_2=Y_3=1\\) and so we calculate \\[P(Y_1=1,Y_2=1,Y_3=1)=P(Y_1=1)P(Y_2=1)P(Y_3=1)=\\frac12\\cdot\\frac12\\cdot\\frac12=\\frac18.\\] Example. Calculate \\(P(X_2=0)\\). This is only possible if \\(Y_1=1,Y_2=-1\\) or \\(Y_1=-1,Y_2=1\\) and so we calculate each probability and add the result. \\[P(X_2=0)=P(Y_1=1,Y_2=-1)+P(Y_1=-1,Y_2=1)=\\frac14+\\frac14=\\frac12.\\] The state space of the SSRW is thus the set of integers \\(\\mathbb Z\\) and the time index set is \\(\\mathbb N_0\\). The sample path space will be all infinitely long sequences of integers where consecutive integers only differ by \\(\\pm1\\). We could say that the sample path space is all infinite sequences of integers, but most of those will have probability zero since any sequence which jumps outside of \\(\\pm1\\) would be considered as not possible. So we have our sequence of random variables \\((X_0,X_1,X_2,\\ldots)\\). Of course, \\(X_0\\) is deterministically set to one, but we can still consider it a random variable with full probability mass on one. Now \\(X_1\\) is equally likely to be \\(\\pm1\\). If \\(X_1=1\\), then \\(X_2\\) is equally likely to be \\(0,2\\), and if \\(X_1=-1\\), then \\(X_2\\) is equally likely to be \\(0,-2\\). 4.1.1 Distribution of \\(X_n\\) Since \\(X_n\\) is a random sum of a bunch of plus and minus ones, we can realte it to a sum of Bernoulli random variables. If we think of flipping a fair coint \\(n\\) times and let \\(H\\) be the number of heads and \\(T\\) be the number of tails, then we must have \\(H+T=n\\). If the \\(j^{th}\\) coint flip is heads, we set \\(Y_j=1\\) and if it is tails, we set \\(Y_j=-1\\). In this way, we can reason that \\[X_n=(\\# \\text{ heads})-(\\# \\text{ tails})=H-T=H-(n-H)=2H-n.\\] Since we know that \\(H\\sim\\mathsf{binom}(n,\\frac12)\\) (\\(H\\) is governed by the binomial distribution with \\(n\\) trials and \\(p=\\frac12\\) probability of success), we can use this to calculate probabilities for \\(X_n\\): Distribution of \\(X_n\\) for SSRW. \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)={n\\choose \\frac{n+j}{2}}\\frac1{2^n}.\\] Now we refresh the normal approximation to the binomial. Normal approximation to binomial. Let \\(X\\sim\\mathsf{binom}(n,p)\\), then for \\(n\\) large (usually \\(n\\geq 30\\) with \\(np\\geq5\\) and \\(n(1-p)\\geq5\\) is acceptable, but it might still be a rough approximation). Then we can say that \\[X\\overset{\\small approx}{\\sim} \\mathsf{N}(\\mu=np,\\sigma^2=np(1-p)).\\] The binomial is a discrete distribution, but the normal is a continuous distribution. Any time we use a continuous distribution to approximate a discrete distribution, it might be useful to use a continuity correction. Continuity correction. If discrete random variable \\(X\\) has values \\(x_1,x_2,\\ldots\\) and we wish to approximate \\(P(X=x_j)\\) by continuous random variable \\(Y\\), then we can integrate the probability density function of \\(Y\\) from halfway to the next \\(x\\)-values on the left and right: \\[P(X=x_j)\\approx P(x_j-(x_j-x_{j-1})/2 &lt; Y \\leq x_j+(x_j-x_{j-1})/2).\\] For the normal approximation to the binomial random variable \\(X\\sim binom(n,p)\\), this translates to using \\(Y\\sim N(np,np(1-p))\\) and \\[P(X=k)\\approx P\\left(k-\\frac12 &lt; Y \\leq k+\\frac12\\right).\\] Normal approximation to distribution of \\(X_n\\) for SSRW. We have that \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)\\] and that \\(H\\) is binomial distributed with parameters \\(n,p\\) and hence is approximately normally distributed with mean \\(\\mu=np\\) and variance \\(\\sigma^2=np(1-p)\\). Now we can then write \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)\\approx P\\left(\\frac{n+j}{2}-\\frac12&lt;Y\\leq \\frac{n+j}{2}+\\frac12\\right)\\] where \\(Y\\sim\\mathsf N(\\mu=np,\\sigma^2=np(1-p))\\). In R we can calculate normal cumulative probabilities using pnorm(), so the above probability for \\(P(X_n=j)\\) is given by the R code (with the continuity correction) pnorm((n+j)/2+1/2,mean=n*p,sd=sqrt(n*p*(1-p)))-pnorm((n+j)/2-1/2,mean=n*p,sd=sqrt(n*p*(1-p))) Example. Let’s calculate \\(P(X_7=-3)\\). We have \\(n=7\\), \\(p=0.5\\), and \\(j=-3\\). The exact calculation using the distribution we derived from the bionomial is: \\[P(X_7=-3)={7\\choose\\frac{7-3}{2}}\\frac1{2^7}={7\\choose2}\\frac1{2^7}=\\frac{7\\cdot 3}{2^7}\\approx0.1640625.\\] And using the normal approximation (with continuity correction) we get: \\(P(X_7=-3)\\approx\\)pnorm(2.5,7/2,sqrt(7)/2)-pnorm(1.5,7/2,sqrt(7)/2)\\(\\approx0.1595609\\) which is a reasonable approximation. We can make the R code a bit simpler though. If \\(X\\sim N(\\mu\\sigma^2)\\) then \\(aX+b\\sim N(a\\mu+b,a^2\\sigma^2)\\). This means that \\(aX+b\\) is a normal random variable as well with \\(E(aX+b)=a\\mu+b\\) and \\(Var(aX+b=a^2\\sigma^2)\\). Since we are approximating \\(H\\), the number of up steps, as a normal random variable, then \\(2H-n\\) is also approximately normally distributed. \\[X_n=2H-n\\overset{\\small approx}{\\sim}\\mathsf{N}(\\mu=2np-n,\\sigma^2=4np(1-p)).\\] And for the SSRW this means \\[X_n=2H-n\\overset{\\small approx}{\\sim}\\mathsf{N}(\\mu=0,\\sigma^2=n).\\] Now to apply the continuity correction is a bit trickier though, because \\(X_n\\) only takes on values \\(-n,-n+2,\\ldots,n-2,n\\). Instead of adding and subtracting \\(\\frac12\\), we must add and subtract \\(1\\) and \\(P(X_n=j)\\) is approximated by pnorm(j+1,0,sqrt(n))-pnorm(j-1,0,sqrt(n)). Summary For \\(X_n\\) the simple 1D random walk with \\(p\\) probability of an up step: \\(P(X_n=j)={n\\choose (n+j)/2}p^{(n+j)/2}(1-p)^{(n-j)/2}\\) \\(P(X_n=j)\\approx\\)pnorm(j+1,2*n*p-n,sqrt(4*n*p*(1-p)))-pnorm(j-1,2*n*p-n,sqrt(4*n*p*(1-p))) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
