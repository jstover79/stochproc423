[["index.html", "Math 423 Stochastic Processes Course Notes Introduction", " Math 423 Stochastic Processes Course Notes Joseph Stover 2023-01-31 Introduction Stochastic processes is the mathematical theory of random phenomena. Our working definition of a random phenomenon or process, is one that we cannot predict accurately. Physical processes are often not predictable for a variety of reasons. Typically, we quantify a physical process somehow, e.g. by taking measurement at specific times. If each measurement is unpredicatable (random), then our sequence of measurements is a stochastic process! You have seen random variables in previous probability or statistics courses. A random variable \\(X\\) takes on real number values, but we cannot predict what precise value it will take perfectly it is random. One can think of performing a random experiment such as rolling a die and letting \\(X\\) be the number of dots on the upper face or observing some physical process like drilling an oil well with \\(X\\) being the amount of oil produced on the first day or growing a plant and letting \\(X\\) be the height of the plant after one month of growth. In all of the examples \\(X\\) just takes on a single numerical value. A stochastic process tracks these processes over time. Let \\(X_n\\) be the outcome of the \\(n^{th}\\) die roll, the height of the plant after month \\(n\\), or the amount of oil produced during day \\(n\\). In this way a stochastic process can initially be thought of as a sequence of random variables. Here are some examples of how a stochastic process might model a physical process. Modeling the daily closing price of a stock for one year. Modeling the number of insurance claims in each month over a year. The number of new infections each day for a particular disease. Tracking radioactive decays over time. The location of an animal as it moves through its habitat, e.g. the distance from a bird to its nest as a funciton of time. Each of these physical phenomena are highly unpredictable, and so we generally treat them as random. "],["introduction-to-r-and-rstudio.html", "Chapter 1 Introduction to R and RStudio 1.1 Getting access to R and RStudio 1.2 Installing and using packages in R 1.3 Random variables 1.4 Basics of programming, R scripts 1.5 Importing datasets Summary", " Chapter 1 Introduction to R and RStudio R is a statistical software package and a computer programming language. It is widely used in both industry (e.g. by data scientists) and academic research. RStudio is a graphical interface for R. Here I will give a brief introduction to R and RStudio. 1.1 Getting access to R and RStudio There are two main ways to use R: install R and RStudio locally on your computer, or use Posit cloud. (Posit is the company that makes RStudio) Posit Cloud: I strongly suggest getting an account on Posit Cloud (this is the company that makes RStudio). Then you have access to a fully-capable and up-to-date version of R and RStudio form any web browser on any device. Go to: https://posit.cloud/, and sign up. Their free account simply has computation time limitations which should be no problem for most casual users. Alternatively, you can download and install R and RStudio Desktop locally on your computer. I recommend doing this, especially if you are more serious about learning R or running programs that require more computation time. Downloading and installing R statistical software: I recommend two things: Install R. This is the actual statistical software. Install RStudio Desktop. This is a nice user interface for R. *Note that the actual software version numbers change frequently, and they are, as of writing, R 4.2.2 and RStudio Desktop 2022.12.0+353. Getting R: First, download the appropriate version (Windows, Mac, etc.) of R from here: https://cloud.r-project.org/ For Windows: Click on Download R for Windows, then click on install R for the first time, then click on Download R-4.2.2 for Windows. Then install the software. For Mac OS: Click on Download R for macOS, then click on either R-4.2.2-arm64.pkg or R-4.2.2.pkg (depending on macOS version and processor type). Then install the software. I am more proficient at Windows than Mac, but if you have trouble installing it, come see me and I should be able to help you get it figured out. There are also Linux/Unix optionsI am familiar with Ubuntu and so should be able to help on those platforms as well. Getting RStudio Desktop: After you have R installed, I recommend installing RStudio Desktop in order to have access to a more friendly user interface. I will always be using RStudio when I show demonstrations in class. Simply go here: https://posit.co/download/rstudio-desktop/#download and choose your desired version. The webpage should automatically detect your operating system and provide you with a link to the correct version of RStudio. You can scroll down the page and see links to various versions though. For Windows, the first link should work: Windows 10/11 RSTUDIO-2022.12.0-353.EXE. For MacOS the second link should work: macOS 11+ RSTUDIO-2022.12.0-353.DMG. Install the software. Done! There is also a link for older versions of RStudio in case you have an older version of Windows, MacOS, or Linux, etc. Brief test of R &amp; RStudio: Launch RStudio Desktop or open a Posit Cloud Workspace/Project. Locate the Console subwindow. This is where we will type our commands. Type x &lt;- 3 in the console next to the &gt; (which is a command prompt that you will always type command next to). Then press the enter or return key on your keyboard. This saves the value of 3 for the variable x. Then type x+5 and hit enter. You should see the output [1] 8. This indicates the result of the computation. The [1] indicates that the output is a single number. Later on we will learn many interesting commands that are useful. Now you know how to open RStudio and use it as a calculator! The RStudio user interface is shown below. The most important parts are highlighted and labeled wtih brief descriptions. The RStudio user interface. Using R online through other sources: Another option for using R statistical software is to use one of the many places online where you can use it through a web browser. There are many such websites. Here is one website where you can conveniently evaluate R code online from a web browser in any device: https://rdrr.io/snippets/ Another option for having quick access to R (and this is useful for a smartphone) is SageCell at: https://sagecell.sagemath.org/. This website can be used to evaluate commands from a variety of programming languages (including MATLAB and Python). Just select R from the language tab at the lower right of the textbox. If you are familiar with MATLAB, choose the option Octave. Octave is basically an open source version of MATLAB and you can run MATLAB code using the Octave language option on SageCell. 1.2 Installing and using packages in R It is common for software developers to develop libraries or packages which contain functions and methods. The purpose is the same as a mathematical function. Rather than you rewriting the equation each time, you can program the function and simply call that computer function with a single letter rather than a complicated formula. As an example, R has some base functionality for matrix computations, but in order to raise matrices to exponents, you need to expm package. Generally to install a package named packagename we execute the command install.packages(\"packagename\"). Once a package is installed, in order to use the methods and functions it includes, they must be loaded into Rs active workspace and can be done by executing the command library(packagename). In order to run the stock simulation code we need to install the packages quantmod and RQuantLib. To do this, execute the commands: install.packages(\"quantmod\") and install.packages(\"RQuantLib\"). Youll see some output indicating what R is doing, downloading some files, unpacking them, and installing them. Sometimes it may even be compiling some code in the background. Usually it takes a few seconds to minutes to install a new package. Once a package is installed, in order to use the methods and functions it includes, execute the command library(packagename), e.g. library(quantmod). Notice that installing a package require quotation marks around the package name, but calling it into Rs workspace does not. 1.3 Random variables R has built in methods for many different random variables. Generally for each random variable there are four methods: dname() (pmf or pdf), pname() (cdf), qname() (quantiles), and rname() (random simulation) where you replace name by the name of a particular distribution. Here are the R names for some common distributions: Binomial | binom | |Exponential | exp | |Normal | norm | |Poisson | pois | 1.4 Basics of programming, R scripts under construction 1.5 Importing datasets under construction Summary Summary of notation, formulas, and terminology under construction "],["counting-sets-and-probability-basics.html", "Chapter 2 Counting, sets, and probability basics 2.1 Ticket-in-a-box model of probability 2.2 Relative area model of probability 2.3 Sample Spaces and Events 2.4 Set Operations 2.5 Venn Diagrams 2.6 Counting, permutations, and combinations 2.7 Probability", " Chapter 2 Counting, sets, and probability basics Now we review basic introductory probability theory. An experiment with observable outcomes that has some level of unpredictability to them is often called random. You may have an intuitive understanding of what random means and what it means for something to have a probability, chance, or likelihood of happening. We want to mathematically formalize the concept of probability. An experiment here could be as simple as selecting one or more individuals from a fixed population. It could be a process such as an industrial machine producing some item. We will investigate the probability of different individuals being selected in the former example and the probability of the produced item having certain properties in the latter example. 2.1 Ticket-in-a-box model of probability Here is a what I hope will be an intuitive model of probability and random experiments. Assume we have a box full of tickets. We are to shake the box up and draw one or more tickets out. It should be intuitively clear that we have little (if any) control over what ticket we draw out (assuming we arent looking and sorting through the tickets until we find the one we want). Now, let the tickets be labeled with letters, numbers, colors, names, or any label you can imagine. The tickets could contain the names of all students in a class, 1 per student, or they could have the sides of a die written on them. We could even account for an experiment that is biased towards a certain outcome by having more tickets with one label and less of another label. For example, if we want to simulate a coin that has a 75% chance of flipping heads and a 25% chance for tails, then we could put in 75 H tickets and 25 T tickets. Now if you were to draw a ticket, replace it, shake the box up and draw again, you should intuitively feel that out of 10 draws, we expect to get 7 or 8 Hs and the rest Ts. The result is unpredictable, but if you drew a very large number of tickets (replacing each as we go), then if you drew only Hs, you would probably agree that you might get suspicious, say, that the T tickets were stuck to the walls or missing. Keep this model of probability in mind as we go through this course. We will come back to this idea several times. 2.1.1 Sampling from a box of tickets If we have a box of tickets with \\(k\\) different ticket labels, and \\(n_i\\) of tickets with label \\(L_i\\), then our box looks like this: \\[\\{L_1,L_1,\\ldots,L_1, L_2, L_2,\\ldots, L_2, \\ldots, L_k, L_k\\ldots, L_k\\}.\\] We wish to shuffle these up randomly and draw out \\(n\\) total tickets. This can be accomplished in R as follows: S=c(rep(L1,n1),rep(L2,n2),...,rep(Lk,nk)) sample(S,size=n,replace=T/F) Examples: Flip a fair coin once: sample(c(\"H\",\"T\"),size=1,replace=T) Flip a fair coin 10 times: sample(c(\"H\",\"T\"),size=10,replace=T) Roll a fair die 20 times: sample(1:6,size=20,replace=T) Draw without replacement until all tickets are gone with 3 blue tickets, 2 red tickets, and 1 green ticket: S=c(rep(&quot;blue&quot;,3),rep(&quot;red&quot;,2),rep(&quot;green&quot;,1)) sample(S,size=length(S),replace=F) ## [1] &quot;blue&quot; &quot;blue&quot; &quot;blue&quot; &quot;red&quot; &quot;green&quot; &quot;red&quot; 2.2 Relative area model of probability First consider tossing a tossing a dart at a dartboard. Consider a dartboard that is a disc with a small circle in the center of the dartboard (the bulls-eye). Having a dart land in the bulls-eye is normally a higher point value than another other location on the board. Why is this? We can intuitively reason that the bulls-eye is small, therefor the dart can land in the bulls-eye in fewer ways than the rest of the board which has many more places for he dart to land. This is actually a continuous version of the ticket-in-a-box model. 2.2.1 One dimension Consider that we have \\(n\\) tickets that indicate sub-intervals of the interval \\([0,1]\\) so that ticket \\(1\\) indicates the interval \\([0,\\frac1n]\\), ticket \\(2\\) indicates the interval \\((\\frac1n,\\frac2n]\\), , and ticket \\(n\\) indicates interval \\((\\frac{n-1}{n},1]\\). So we can put the tickets in a box, shake it up and draw one out to randomly select a sub-interval of \\([0,1]\\). \\[\\text{Tickets: } \\quad ~\\quad \\fbox{$1: \\left[0,\\frac1n\\right]$}, ~\\fbox{$2: \\left(\\frac1n,\\frac2n\\right]$}, ...,~\\fbox{$n: \\left(\\frac{n-1}{n},1\\right]$}\\] Now imagine increasing the number of tickets, \\(n\\). We can imagine laying the tickets in a line that is one unit long and just sequentially cutting the tickets into smaller and smaller pieces while preserving the total length of the interval. For a very large number of tickets, the sub-intervals will be very short. Randomly choosing a sub-interval from \\([\\frac12,\\frac34]\\), for example, will depend on how many sub-intervals it is divided into, i.e. the number of tickets that that region was cut into. The number of tickets that any interval is cut into is proportional to the length of that interval. In the limit as \\(n\\rightarrow\\infty\\), the tickets will effectively indicate every point on the interval \\([0,1]\\). And we can imagine tossing a dart onto a line, and assuming that every location is equally likely, the probability of any sub-interval is equivalent to its length (relative to the length of the entire landing strip). We can think of this as a way to model selecting a number at random from the interval \\([0,1]\\). If we require any number of decimals of precision, e.g. 8 decimal places, then we can put \\(10^8\\) tickets in the box to indicate all numbers at that precision level. 2.2.2 Two or more dimensions We can generalize the same ideas to two dimensions. Take any region and cut it up into equal area tickets. The probability of selecting a ticket from sub-region \\(A\\) will be the number of tickets that \\(A\\) is cut into. This is equal to the area of \\(A\\) relative to the area of the entire region. Back to the dartboard example. The probability of the dart landing in the bulls-eye is the area of the bulls-eye divided by the area of the entire dartboard. This is an intuitive way to extend the idea of equally likely from a finite number of tickets to a continuous interval or a continuous area. We can even extend this idea to selecting randomly from a three dimensional volume. For example, if a molecule is randomly moving around in space, with the assumption that every location is equally likely, the probability of finding the molecule in any region is equal to the volume of that region divided by the entire volume of the whole space. It is important here that we start with a finite region of all possible locations. Now: what if we dont want all locations to be equally likely? This requires us to develop the mathematical theory of probability. That is what follows. 2.3 Sample Spaces and Events 2.3.1 Sample space The set of all possible outcomes of a random process or experiment is called the sample space and is denoted by \\(S\\). Examples: \\(S=\\{H,T\\}\\) for flipping a coin. \\(S=\\{1,2,3,4,5,6\\}\\) for rolling a 6-sided die. \\(S=\\{(1,1),(1,2),\\ldots,(6,5),(6,6)\\}\\) for rolling two 6-sided dice. \\(S=\\{(H,1),(H,2),\\ldots,(H,6),(T,1),(T,2),\\ldots,(T,6)\\}\\) for rolling a 6-sided die and flipping a coin. To list out a sample space in R, you can do the following. Here is an example of flipping a coin and rolling a die: coinflip=c(&quot;H&quot;,&quot;T&quot;) dieroll=1:6 S = expand.grid(coin=coinflip, die=dieroll) #&#39;die&#39; is the name of the column listing the outcomes of the die roll, # and &#39;coin&#39; is the name of the column listing the outcomes of the coin flip S ## coin die ## 1 H 1 ## 2 T 1 ## 3 H 2 ## 4 T 2 ## 5 H 3 ## 6 T 3 ## 7 H 4 ## 8 T 4 ## 9 H 5 ## 10 T 5 ## 11 H 6 ## 12 T 6 Example: flipping 3 coins: coinflip=c(&quot;H&quot;,&quot;T&quot;) S = expand.grid(coin1=coinflip, coin2=coinflip, coin3=coinflip) S ## coin1 coin2 coin3 ## 1 H H H ## 2 T H H ## 3 H T H ## 4 T T H ## 5 H H T ## 6 T H T ## 7 H T T ## 8 T T T Example: list of all 2-letter syllables with a consonant followed by a vowel. Note that many of these may not actually be valid syllables in the English language. # &#39;letters&#39; is a built-in list of all lower-case letters # &#39;LETTERS&#39; is a built-in list of all upper-case letters vowels=c(&quot;a&quot;,&quot;e&quot;,&quot;i&quot;,&quot;o&quot;,&quot;u&quot;) consonants=setdiff(letters,vowels) S = expand.grid(letter1_c=consonants, letter2_v=vowels) S ## letter1_c letter2_v ## 1 b a ## 2 c a ## 3 d a ## 4 f a ## 5 g a ## 6 h a ## 7 j a ## 8 k a ## 9 l a ## 10 m a ## 11 n a ## 12 p a ## 13 q a ## 14 r a ## 15 s a ## 16 t a ## 17 v a ## 18 w a ## 19 x a ## 20 y a ## 21 z a ## 22 b e ## 23 c e ## 24 d e ## 25 f e ## 26 g e ## 27 h e ## 28 j e ## 29 k e ## 30 l e ## 31 m e ## 32 n e ## 33 p e ## 34 q e ## 35 r e ## 36 s e ## 37 t e ## 38 v e ## 39 w e ## 40 x e ## 41 y e ## 42 z e ## 43 b i ## 44 c i ## 45 d i ## 46 f i ## 47 g i ## 48 h i ## 49 j i ## 50 k i ## 51 l i ## 52 m i ## 53 n i ## 54 p i ## 55 q i ## 56 r i ## 57 s i ## 58 t i ## 59 v i ## 60 w i ## 61 x i ## 62 y i ## 63 z i ## 64 b o ## 65 c o ## 66 d o ## 67 f o ## 68 g o ## 69 h o ## 70 j o ## 71 k o ## 72 l o ## 73 m o ## 74 n o ## 75 p o ## 76 q o ## 77 r o ## 78 s o ## 79 t o ## 80 v o ## 81 w o ## 82 x o ## 83 y o ## 84 z o ## 85 b u ## 86 c u ## 87 d u ## 88 f u ## 89 g u ## 90 h u ## 91 j u ## 92 k u ## 93 l u ## 94 m u ## 95 n u ## 96 p u ## 97 q u ## 98 r u ## 99 s u ## 100 t u ## 101 v u ## 102 w u ## 103 x u ## 104 y u ## 105 z u 2.3.2 Events An event is a set of outcomes. Events are usually denoted by capital letters, e.g. \\(A\\), \\(B\\), \\(C\\), etc. They can be described in words or with the outcomes listed as a set in {} curly brackets. Examples: Flipping a coin. Event \\(A=\\) {heads}. Event \\(B=\\{T\\}\\). Flipping two coins. Event \\(A=\\) no heads, Event \\(B=\\) {1 head and 1 tail}. Event \\(C=\\) {TT,TH} = {first coin is tails}. Rolling a 6-sided die. Event \\(A=\\) {even}. Event \\(B=\\){greater than 4}={5,6}. 2.4 Set Operations Here is a review of the primary operations we will use with sets. Union: all outcomes that are in the events, \\(A\\cup B\\) Intersection: all outcomes common to the events being intersected, \\(A\\cap B\\) Complement: all outcomes not in the given event, \\(A^c\\) Set Difference: all outcomes in one event that are not in the other, \\(A-B\\), note that \\(A-B=A\\cap B^c\\) Example: Let \\(A=\\{1,2,3,4\\}\\), and \\(B=\\{2,4,6\\}\\) be events from sample space \\(S=\\{1,2,3,4,5,6\\}\\). \\(A\\cup B=\\{1,2,3,4,6\\}\\), R command: union(A,B) \\(A\\cap B=\\{2,4\\}\\), R command: intersect(A,B) \\(A^c=\\{5,6\\}\\) \\(A-B=\\{1,3\\}\\) Note that \\(A^c=S-A\\). R command: setdiff(A,B) Two sets are called disjoint if they have empty intersection \\(A\\cap B=\\emptyset\\). When sets represent events for a random experiment and are disjoint, we call them mutually exclusive. In order to do a set complement in R, we will need to specify the sample space and to a set difference: \\(A^c=S-A=\\)setdiff(S,A). Example with rolling a 6-sided die: S=1:6 # sample space is {1,2,3,4,5,6} A=c(2,4,6) B=c(1,2,3,4) union(A,B) ## [1] 2 4 6 1 3 intersect(A,B) ## [1] 2 4 setdiff(A,B) # A-B ## [1] 6 setdiff(S,A) # A complement ## [1] 1 3 5 We can take unions and intersections of more than two sets also: \\[\\bigcup_{k=1}^n A_k=A_1\\cup A_2\\cup\\cdots \\cup A_n\\] \\[\\bigcap_{k=1}^n A_k=A_1\\cap A_2\\cap\\cdots \\cap A_n\\] If we have a countably infinite number of events, \\(A_1,A_2,\\ldots\\) where there is no end to the list of events, so-to-speak, we can still take their union and intersection: \\[\\bigcup_{k=1}^\\infty A_k=A_1\\cup A_2\\cup\\cdots\\] \\[\\bigcap_{k=1}^\\infty A_k=A_1\\cap A_2\\cap\\cdots \\] It may be difficult to imagine what an infinite list of events looks like or how it could be used. Usually infinite unions and intersections are only encountered in more advanced probability and statistics courses, but at this level, you just need to be exposed to the idea. The most important thing is to understand the union and intersection notation for a finite list of events. Associative Laws: \\((A\\cup B)\\cup C = A\\cup (B\\cup C)\\) \\((A\\cap B)\\cap C = A\\cap (B\\cap C)\\) Distributive Laws: \\((A\\cup B)\\cap C = (A\\cap C)\\cup (B\\cap C)\\) \\((A\\cap B)\\cup C = (A\\cup C)\\cap (B\\cup C)\\) DeMorgans Laws: \\((A\\cup B)^c=A^c \\cap B^c\\) \\((A\\cap B)^c=A^c \\cup B^c\\) Inclusion/exclusion rules (for size of sets): \\(|A\\cup B| =|A|+|B|-|A\\cap B|\\) \\(\\begin{aligned} |A\\cup B\\cup C| =&amp;|A|+|B|+|C|\\\\ &amp;-|A\\cap B|-|A\\cap C|-|B\\cap C|\\\\ &amp;+|A\\cap B\\cap C| \\end{aligned}\\) Note that \\(|A|\\) denotes the size of set \\(A\\), which is the number of outcomes in the set. In R, we can accomplish this for a simple list/vector with length(A), e.g. A=c(2,4,6); length(A). If \\(A\\) is not merely a set, list, or vector but has a table-like structure, then instead of length(A), we might want to use nrow(A) to get the number of rows or ncol(A) to get the number of columns. 2.5 Venn Diagrams Graphing the Venn diagrams in R will require package call VennDiagram. To install that package, issue the command: install.packages(\"VennDiagram\") After the package is installed, well have to load it into R using require(VennDiagram) or library(VennDiagram). You will likely see some output on the screen in red colored text showing you what functions or packages have been loaded and possibly giving some warning messages. You can mostly ignore this text unless it explicitly gives an error saying the package is not found or was not loaded. Usually, it will be clear if that is the case. # note that before issuing this command, # you need to have the &quot;VennDiagram&quot;&quot; package installed&quot; # you caninstall it with `install.packages(&quot;VennDiagram&quot;)` library(VennDiagram) Now that the Venn diagram package and its associated commands are loaded, we can draw a Venn diagram: grid.newpage() draw.pairwise.venn(area1 = 25, area2 = 30, cross.area = 12, category = c(&quot;A&quot;,&quot;B&quot;), fill=c(rgb(1,0,0),rgb(0,1,0)), alpha=c(0.25,0.25)) Youll notice that R prints to the screen some information about the polygons that have been drawn. You dont need to pay attention to this information about the polygons. From the figure above, we can see that \\(|A|\\)=25, \\(|B|\\)=30, and \\(|A\\cap B|\\)=12. Venn diagrams can also be drawn with three sets: grid.newpage() draw.triple.venn(area1 = 22, area2 = 20, area3 = 13, n12 = 11, n23 = 4, n13 = 5, n123 = 1, category = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), fill = c(&quot;skyblue&quot;, &quot;pink1&quot;, &quot;mediumorchid&quot;)) 2.6 Counting, permutations, and combinations In order to calculate probabilities, we will often need to be able to count the number of outcomes in the sample space and in particular events. 2.6.1 Multiplication rule If we perform an experiment where the outcome has two different parts (e.g. a coin flip and a die roll) then the total number of possibilities is the product of the number of possibilities for each part: \\(n=n_1\\cdot n_2\\). If there are many parts, e.g. roll several dice with different numbers of sides, then we multiply the number of possibilities for each: \\[n=n_1\\cdot n_2\\cdot \\cdots n_k.\\] Example: If we roll a 6-sided die, flip a coin, roll a 20-sided die, and roll two 4-sided dice, then the total number of outcomes is \\(n=6\\cdot 2 \\cdot 20 \\cdot4\\cdot4\\). This rule can also work, if instead of having multiple distinct parts (like several physical objects), the outcome of an experiment could have multiple observable characteristics that need to be determined. Assume we have a box that contains tokens, and each token is painted a specific color (green, blue, or red), and labeled with a number (1,2,3,4,or 5) and a letter (A or B). Assume that there are 10 tokens of each color so that every combination has exactly one token. Lets list out the sample space using R. token_colors=c(&quot;green&quot;,&quot;blue&quot;,&quot;red&quot;) token_numbers=1:5 token_letters=c(&quot;A&quot;,&quot;B&quot;) S = expand.grid(color=token_colors, number=token_numbers, letter=token_letters) nrow(S) ## [1] 30 Now we can see that the size of the sample space is \\[ \\begin{aligned} |S|&amp;=\\{\\text{# of colors}\\}\\cdot\\{\\text{# of numbers}\\}\\cdot\\{\\text{# of letters}\\}\\\\ &amp;=3\\cdot5\\cdot2=30. \\end{aligned} \\] It is important here that we have the token attributes are evenly distributed so-to-speak, i.e. if each color had a different list of labels such as 3 numerical labels for green tokens and 5 numerical labels for red tokens, then this technique would not work exactly as stated. Each specific attribute must have the same number of repetitions of the other attributes. 2.6.2 \\(n^k\\) Assume we have \\(n\\) distinct objects to choose from. These \\(n\\) objects could be the numbers 1 to 10, 5 types of drinks, or 20 students in a class. We will select \\(k\\) of these objects in a variety of different ways. If we select the \\(k\\) objects one at a time, replacing each as we go, then the total number of possibilities is \\(n^k\\). Here we are allowing for the same object selected multiple times (repetition), and we are concerned with the order of the selection. This is an application of the multiplication rule. Now let us assume we have \\(n\\) objects to arrange in order. Well make \\(k\\) spaces which we will fill with the objects. \\[ \\underset{\\text{obj. $1$}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. 2}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. 3}}{\\underbrace{\\qquad\\quad}} \\ \\cdots \\ \\underset{\\text{obj. $k-1$}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. $k$}}{\\underbrace{\\qquad\\quad}} \\] For each space, we have all \\(n\\) objects to choose from since we will draw an object, record which we have drawn, then replace that object and draw for the next space. \\[ \\overset{n}{\\underset{\\text{obj. $1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n}{\\underset{\\text{obj. 2}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n}{\\underset{\\text{obj. 3}}{\\underbrace{\\qquad\\quad}}} \\ \\cdots \\ \\overset{n}{\\underset{\\text{obj. $k-1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n}{\\underset{\\text{obj. $k$}}{\\underbrace{\\qquad\\quad}}} \\] 2.6.3 Factorials Now let us assume we have \\(n\\) objects to arrange in order. The difference is that now, each time we select an object to fill a space, we will not replace it, thus will reduce our total number of options for the next space. This will result in an ordered arrangement of \\(n\\) objects. This is often called a permutation of \\(n\\) distinguishable objects. They are called distinguishable since swapping any two results in a distinct ordering or permutation. Again well make \\(n\\) spaces which we will fill with the objects. \\[ \\underset{\\text{obj. $1$}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. 2}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. 3}}{\\underbrace{\\qquad\\quad}} \\ \\cdots \\ \\underset{\\text{obj. $n-1$}}{\\underbrace{\\qquad\\quad}} \\ \\underset{\\text{obj. $n$}}{\\underbrace{\\qquad\\quad}} \\] We will count how many choices we have to fill each space. The first space has \\(n\\) total choices. After putting an object in the first space, we only have \\(n-1\\) objects left to select from, since we are drawing without replacement. Our available choices decrease by one each time we select an object to put in a space. The result is as follows. \\[ \\overset{n}{\\underset{\\text{obj. $1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n-1}{\\underset{\\text{obj. 2}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n-2}{\\underset{\\text{obj. 3}}{\\underbrace{\\qquad\\quad}}} \\ \\cdots \\ \\overset{2}{\\underset{\\text{obj. $n-1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{1}{\\underset{\\text{obj. $n$}}{\\underbrace{\\qquad\\quad}}} \\] Then we use the multiplication rule. So the total number of ways to arrange them is the product \\(n(n-1)(n-2)\\cdots3\\cdot2\\cdot1\\). This is denoted by a factorial: \\[n!=n\\cdot(n-1)\\cdot(n-2)\\cdots3\\cdot2\\cdot1\\] Note that by definition, \\(0!=1\\). A factorial in R can be evaluated as factorial(n). factorial(0) ## [1] 1 factorial(1) ## [1] 1 factorial(2) ## [1] 2 factorial(c(0,1,2,3,4)) ## [1] 1 1 2 6 24 factorial(10) ## [1] 3628800 2.6.4 Permutation Now we are still starting with \\(n\\) total objects to choose from. If we select \\(k\\) objects one at a time, but do not replace them as we go and we are concerned with the order we draw them in, then a permutation results, and there are \\(\\frac{n!}{(n-k)!}\\) possibilities. This is denoted differently in different texts as \\(_nP_k\\), \\(P_{n,k}\\), or \\(P_{k,n}\\) for \\(k\\le n\\). I recommend always writing it out as factorials. Here it is important that \\(0\\le k\\le n\\). The best way to evaluate a permutation in R is with factorials # permute 3 out of 10 factorial(10)/factorial(10-3) ## [1] 720 A permutation can be illustrated just as above, by listing out \\(k\\) spaces and writing in the number of possibilities for each space, but the last space will not have only 1 possibility. \\[ \\overset{n}{\\underset{\\text{obj. $1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n-1}{\\underset{\\text{obj. 2}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n-2}{\\underset{\\text{obj. 3}}{\\underbrace{\\qquad\\quad}}} \\ \\cdots \\ \\overset{n-(k-2)}{\\underset{\\text{obj. $k-1$}}{\\underbrace{\\qquad\\quad}}} \\ \\overset{n-(k-1)}{\\underset{\\text{obj. $k$}}{\\underbrace{\\qquad\\quad}}} \\] The result is identical to multiplying from \\(n\\) all the way down to 1 but then dividing by \\((n-k)!\\) as is done in the factorial formula for a permutation. 2.6.5 Combination If we select \\(k\\) objects out of \\(n\\) choices (again with \\(0\\le k\\le n\\)) either one at a time without replacement and do not care about the order they are drawn in, or if we just drew all \\(k\\) at once, then a combination results. The total number of possibilities is \\({n\\choose k} = \\frac{n!}{k!(n-k)!}\\) for \\(k\\le n\\). Again, this is variously denoted as \\(_nC_k\\), \\(C_{n,k}\\), or \\(C_{k,n}\\). I recommend the parentheses notation or just writing it out as factorials. The best way to evaluate a combination in R is with factorials # choose 3 out of 10 factorial(10)/factorial(10-3)/factorial(3) ## [1] 120 Alternatively, we can use the choose(n,k) R command: # choose 3 out of 10 choose(10,3) ## [1] 120 2.6.6 Summary of counting Examples: Suppose we have a combination lock with a turn dial that has numbers 1 to 36 on it. A combination consists of three numbers in sequence.Assume that we can have all three numbers the same as you still have to make a complete 360 degree rotation between numbers. Then the total number of allowable combinations is \\(36^3\\). Suppose 150 people are running a race where first, second, and third place will be awarded. How many possible outcomes are there? Here is a situation where order clearly matters, and beyond third place, we will not concern ourselves with the order of the contestants. This is a permutation, permute 3 out of 100, so there are \\(\\frac{150!}{(150-3)!}=150\\cdot 149\\cdot 148\\) possible outcomes. Suppose we have a class of 35 students, and 5 of them will be selected to form a group for a project. Here we are not concerned with the order they are selected in, we just want to know which students will be chosen for the group. We are creating a subset of the total class of students. This is a combination so there are \\({35\\choose5}\\) total possibilities. Consider the last example above. If we were instead going to assign the 5 students distinct roles in the group, e.g. group leader, note taker, researcher, materials gatherer, and data analyzer, then we would be forming different groups even if we had the same 5 students but assigned the roles differently among them. So this becomes a permutation, and there would be \\(\\frac{35!}{(35-5)!}=\\frac{35!}{30!}=35\\cdot34\\cdot33\\cdot32\\cdot31\\) total possible groups (different assignment of group roles results in a different group here). Summary table for the counting methods discussed above: without replacement with replacement order matters permutation: \\(\\frac{n!}{(n-k)!}\\) \\(n^k\\) order doesnt matter combination: \\({n\\choose k}=\\frac{n!}{k!(n-k)!}\\) (special case) 2.6.7 Special case: with replacement, order doesnt matter: the multiset Choosing with replacement, but order does not matter is the most complicated case. Consider throwing \\(k\\) balls into \\(n\\) boxes. If we have the boxes labeled and want to know how many balls are in each box, e.g. 5 in the first box, none in the second box, 2 is the third box, etc., then the number of outcomes is given by \\({n-1+k\\choose k}\\). In this case \\(k\\) and \\(n\\) can be any numbers and \\(k\\le n\\) is not required. Here is an example of tossing 10 balls into 7 boxes. We will pretend the boxes are all adjacent so that among the 7 boxes, there are actually only 8 dividers or walls since adjacent boxes share a wall. We need to arrange the inner 6 dividers between the boxes and the 10 balls. We only need the inner 6 dividers between the boxes because the locations of the outermost left and right walls do not need to be determined. \\[ \\underset{\\text{box 1}}{\\underbrace{\\qquad}}| \\underset{\\text{box 2}}{\\underbrace{\\qquad}}| \\underset{\\text{box 3}}{\\underbrace{\\qquad}}| \\underset{\\text{box 4}}{\\underbrace{\\qquad}}| \\underset{\\text{box 5}}{\\underbrace{\\qquad}}| \\underset{\\text{box 6}}{\\underbrace{\\qquad}}| \\underset{\\text{box 7}}{\\underbrace{\\qquad}} \\] Now we toss the balls in either all at once or one-by-one, it doesnt matter because we dont care for the order of the balls. Assume they land like this: \\[ \\underset{\\text{box 1}}{\\underbrace{\\ \\bullet\\bullet \\ }}| \\underset{\\text{box 2}}{\\underbrace{\\bullet\\bullet\\bullet}}| \\underset{\\text{box 3}}{\\underbrace{\\qquad}}| \\underset{\\text{box 4}}{\\underbrace{\\ \\ \\bullet \\ \\ }}| \\underset{\\text{box 5}}{\\underbrace{\\bullet\\bullet\\bullet\\bullet}}| \\underset{\\text{box 6}}{\\underbrace{\\qquad}}| \\underset{\\text{box 7}}{\\underbrace{\\qquad}} \\] Now we will drop the box labels, and this particular outcome will look as follows. \\[\\cdot\\cdot|\\cdot\\cdot\\cdot||\\cdot|\\cdot\\cdot\\cdot\\cdot||\\] In order to determine all possible outcomes here, we just need to figure out how many ways we can shuffle around the balls and inner dividers. If there are \\(n\\) boxes, then there are \\(n-1\\) inner dividers. So we have \\(n-1\\) dividers and \\(k\\) balls. This is a total of \\(n-1+k\\) symbols to rearrange. We dont care what order they are arranged in though, since the balls are all identical as are the dividers. So we will use a combination. There are a total of \\(n-1+k\\) slots to fill with a symbol, and we will just choose the \\(k\\) slots to put the balls. Then the divider symbols automatically go in the remaining \\(n-1\\) spaces. Here is is illustrated for a simple case, 4 balls and 3 boxes. Here are the boxes with inner dividers: \\[ \\underset{\\text{box 1}}{\\underbrace{\\qquad}}| \\underset{\\text{box 2}}{\\underbrace{\\qquad}}| \\underset{\\text{box 3}}{\\underbrace{\\qquad}} \\] Here are the spaces that we will fill with balls and inner dividers: \\[ \\underset{\\text{space 1}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 2}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 3}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 4}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 5}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 6}}{\\underbrace{\\qquad}} \\] Here is a possible outcome. Lets just drop the 4 balls in some spaces: \\[ \\underset{\\text{space 1}}{\\underbrace{ \\ \\ \\bullet \\ \\ }} \\ \\ \\underset{\\text{space 2}}{\\underbrace{\\qquad}} \\ \\ \\underset{\\text{space 3}}{\\underbrace{ \\ \\ \\bullet \\ \\ }} \\ \\ \\underset{\\text{space 4}}{\\underbrace{ \\ \\ \\bullet \\ \\ }} \\ \\ \\underset{\\text{space 5}}{\\underbrace{ \\ \\ \\bullet \\ \\ }} \\ \\ \\underset{\\text{space 6}}{\\underbrace{\\qquad}} \\] Now the remaining 2 spaces will be filled with the 2 inner dividers: \\[ \\underbrace{ \\ \\ \\bullet \\ \\ }_\\text{space 1} \\ \\ \\underbrace{\\ \\ \\ | \\ \\ \\ }_\\text{space 2} \\ \\ \\underbrace{ \\ \\ \\bullet \\ \\ }_\\text{space 3} \\ \\ \\underbrace{ \\ \\ \\bullet \\ \\ }_\\text{space 4} \\ \\ \\underbrace{ \\ \\ \\bullet \\ \\ }_\\text{space 5} \\ \\ \\underbrace{ \\ \\ \\ | \\ \\ \\ }_\\text{space 6} \\] \\[ \\underbrace{ \\qquad\\qquad\\qquad \\ }_\\text{box 1} \\ \\underbrace{ \\qquad\\qquad\\qquad\\qquad\\qquad\\qquad \\ \\ }_\\text{box 2} \\ \\underbrace{ \\qquad\\quad \\ }_\\text{box 3} \\] So that box one has 1 ball, box two has 3 balls, and box three has 0 balls. 2.7 Probability 2.7.1 Equally likely outcomes Many sample spaces contain a finite number of outcomes that are equally likely. This means that the probability of an event is defined as the number of outcomes in that event divided by the total number of outcomes in the sample space. \\[P(A)=\\frac{|A|}{|S|}\\] Examples: Flipping 3 fair coins: \\(|S|=2^3=8\\). Let event \\(A=\\){at least 2 heads}. So we can list all outcomes in \\(A=\\{HHH,HHT,HTH,THH\\}\\) thus \\(|A|=4\\) so that \\(P(A)=\\frac48=50\\%\\). Rolling a fair 6-sided die: \\(|S|=6\\). Let \\(A=\\){odd}\\(=\\{1,3,5\\}\\) and \\(B=\\){greater than 5}\\(=\\{6\\}\\). Then \\(|A|=3\\) and \\(|B|=1\\) so that \\(P(A)=3/6\\) and \\(P(B)=1/6\\). 2.7.2 General probability theory Axioms of probability: \\(0\\leq P(A)\\) for any event \\(A\\). \\(P(S)=1\\) for sample space \\(S\\). If \\(A_1,A_2,\\ldots\\) are mutually exclusive events (all intersections are empty), then \\(P(A_1\\cup A_2\\cup \\cdots)=P(A_i)+P(A_2)+\\cdots\\). Note that the last axiom can involve a finite number of events or even an infinite number of events. Some consequences of the above axioms: \\(P(\\emptyset)=0\\) \\(0\\leq P(A)\\le 1\\) for any event \\(A\\). If \\(A\\subset B\\), then \\(P(A)\\le P(B)\\). \\(P(A^c)=1-P(A)\\). \\(P(A-B)=P(A \\cap B^c)=P(A)-P(A\\cap B)\\) Inclusion/exclusion rules: \\(P(A\\cup B) =P(A)+P(B)-P(A\\cap B)\\) \\(\\begin{aligned}P(A\\cup B\\cup C) =&amp;P(A)+P(B)+P(C)\\\\ &amp;-P(A\\cap B)-P(A\\cap C)-P(B\\cap C)\\\\ &amp;+P(A\\cap B\\cap C)\\end{aligned}\\) Example: Assume that \\(P(A)=0.6\\), \\(P(B)=0.5\\) and \\(P(A\\cap B)=0.2\\), then we can calculate: \\(P(A\\cup B)=0.6+0.5-0.2=0.9\\) \\(P(A^c)=1-0.6=0.4\\). \\(\\begin{aligned}P(A-B)&amp;=P(A \\cap B^c)\\\\ &amp;=P(A)-P(A\\cap B)=0.6-0.2=0.4. \\end{aligned}\\) \\(\\begin{aligned}P(A^c \\cap B^c)&amp;=P((A\\cup B)^c) \\\\ &amp;=1-P(A\\cup B)=1-0.9=0.1.\\end{aligned}\\) Lets draw a Venn diagram with the probabilities: grid.newpage() draw.pairwise.venn(area1 = 0.6, area2 = 0.5, cross.area = 0.2, category = c(&quot;A&quot;,&quot;B&quot;), fill=c(rgb(1,0,0),rgb(0,1,0)), alpha=c(0.25,0.25)) 2.7.3 Independence Events \\(A\\) and \\(B\\) are called independent if \\[P(A\\cap B)=P(A)\\cdot P(B).\\] This is not to be confused with being disjoint (mutually exclusive), which means that \\(P(A\\cap B)=0\\). Independence is a completely new unrelated concept. One way to understand independence is that the probability of either events occurring does not depend on whether or not the other event has occurred. Example: Rolling a fair 6-sided die: Let \\(A=\\){even}\\(=\\{2,4,6\\}\\) and \\(B=\\){less than five}\\(=\\{1,2,3,4\\}\\). Then we have that \\(A\\cap B=\\{2,4\\}\\), \\(P(A)=\\frac12\\), \\(P(B)=\\frac23\\), and \\(P(A\\cap B)=\\frac13=\\frac12\\cdot\\frac23\\) thus \\(A\\) and \\(B\\) are independent. Here is a way to understand this. If we just roll the die, the probability of it being even (event \\(A\\)) is \\(\\frac12\\). This is if the entire sample space is the set of possibilities, but if instead \\(B\\) was our entire set of possible outcomes, then the probability of $A, being even, is still \\(\\frac12\\). We can rearrange the formula like this: \\[P(A)=\\frac{P(A\\cap B)}{P(B)}.\\] So for equally likely events, \\(A\\) and \\(B\\) are independent if \\[P(A)=\\frac{|A|}{|S|}=\\frac{|A\\cap B|}{|B|}.\\] 2.7.4 Conditional probability When conducting a random experiment, sometimes we may have some information about the outcome but not know it completely. Imagine rolling a die behind a barrier so you cannot see the result, but another person can. Under normal circumstances, \\(P(2)=\\frac16\\). If the person who can see the result tells you it is an even number (assume they are truthful), then 2 is one out of only three possibilities now. So, in this sense \\(P(\\{2 \\text{ given that we know it is even}\\})=\\frac13\\). This is a conditional probability. We are conditioning our calculation of the probability on some given information. The conditional probability of \\(A\\) given \\(B\\) is given by: \\[P(A\\mid B)=\\frac{P(A\\cap B)}{P(B)}.\\] Event \\(B\\) is the condition, and we can think of it as meaning that we know that event \\(B\\) has occurred, but we dont yet have enough information to determine whether or not \\(A\\) has occurred. \\(P(A\\mid B)\\) is the probability of \\(A\\) occurring given that we know \\(B\\) has occurred. An intuitive way to understand conditional probability is the following. Think of events \\(A\\) and \\(B\\) indicating areas for a dart to land. Also assume that they are drawn proportional to their respective probabilities. You can envision a Venn diagram where the area of each region divided by the area of the entire diagram is equal to the probability of that region (as discussed in the beginning of this chapter). The probability of the dart landing in \\(A\\) is exactly the area of \\(A\\) relative to the entire region of possible landing zones. Conditioning on event \\(B\\) means that we know that the dart lands in region \\(B\\). So the probability that it also lands in region \\(A\\) is going to be the area of the intersection of \\(A\\) and \\(B\\) divided by the area of all possible landing zones, which is now just \\(B\\). So \\(P(A\\cap B)/P(B)\\). Example: Consider our opening example in this section with events \\(A=\\{2\\}\\) and \\(B=\\){even}. \\[ P(A\\mid B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{\\frac16}{\\frac36}=\\frac13 \\] 2.7.4.1 Conditional probability and independence Note that if events are independent, then conditioning on one or the other does not change probabilities of either occurring: \\[A,B \\text{ are independent if and only if } \\\\ P(A\\mid B)=P(A) \\text{ and } P(B\\mid A)=P(B) \\] Conditional probability can be used to rewrite the probability of an intersection in two ways: \\[P(A\\cap B)=P(A\\mid B)\\cdot P(B)=P(B\\mid A)\\cdot P(A).\\] This is a very useful thing to understand. It will be used when we discuss Bayes theorem. 2.7.4.2 Set operations and probability axioms with conditional probability Conditional probability behaves just like regular probability. All the set operations, rules, and axioms of probability apply to conditional probability as well. \\(P(\\emptyset\\mid B)=0\\) \\(0\\leq P(A\\mid B)\\le 1\\) for any event \\(A\\). If \\(A\\subset B\\), then \\(P(A\\mid C)\\le P(B\\mid C)\\). \\(P(A^c\\mid B)=1-P(A\\mid B)\\). \\(P(A-B\\mid C)=P(A \\cap B^c\\mid C)=P(A\\mid C)-P(A\\cap B\\mid C)\\) Inclusion/exclusion rules: \\(P(A\\cup B\\mid C) =P(A\\mid C)+P(B\\mid C)-P(A\\cap B\\mid C)\\) Example: Rolling a fair 6-sided die: Let \\(A=\\){even}\\(=\\{2,4,6\\}\\) and \\(B=\\){one}\\(=\\{1\\}\\). Then we have that \\(A\\cap B=\\emptyset\\), \\(P(A)=\\frac12\\), \\(P(B)=\\frac16\\), and \\(P(A\\cap B)=0\\). If we know that \\(B\\) has occurred, what is the probability that \\(A\\) has also occurred? Zero! They are mutually exclusive! Example: Rolling a fair 6-sided die: Let \\(A=\\){odd}\\(=\\{1,3,5\\}\\) and \\(B=\\){less than four}\\(=\\{1,2,3\\}\\). Then we have that \\(A\\cap B=\\{1,3\\}\\), \\(P(A)=\\frac12\\), \\(P(B)=\\frac12\\), and \\(P(A\\cap B)=\\frac13\\). If we know that \\(B\\) has occurred, what is the probability that \\(A\\) has also occurred? \\[P(A\\mid B)=\\frac23=\\frac{\\text{# of outcomes in $A$ and $B$}}{\\text{# of outcomes in $B$}}.\\] In both of the examples above, \\(A\\) and \\(B\\) are not independent. Here is an example with independent events: Example: Rolling a fair 6-sided die: Let \\(A=\\){even}\\(=\\{2,4,6\\}\\) and \\(B=\\){less than five}\\(=\\{1,2,3,4\\}\\). Then we have that \\(A\\cap B=\\{2,4\\}\\), \\(P(A)=\\frac12\\), \\(P(B)=\\frac23\\), and \\(P(A\\cap B)=\\frac13=\\frac12\\cdot\\frac23\\) thus \\(A\\) and \\(B\\) are independent. Lets calculate the conditional probability: \\(P(A\\mid B)=\\frac{|A\\cap B|}{|B|}=\\frac{2}{4}=\\frac12=P(A)\\). 2.7.5 Partitions Now we will divide up the sample space into a number of disjoint sets (mutually exclusive events). The collection of sets that the sample space is broken up into is called a partition. It is important that this partition of sets collectively covers the entire sample space (that is the nature of a partition). The simplest partition is \\(S=A\\cup A^c\\). A partition of a sample space is a collection of events \\(A_1,A_2,A_3,\\ldots,A_n\\) such that \\(A_i\\cap A_j=\\emptyset\\) for any \\(i,j\\) and \\(S=\\bigcup_{i=1}^n A_i=A_1 \\cup A_2 \\cup A_3 \\cup \\cdots \\cup A_n\\). Example: rolling a 6-sided die. Let \\(A=\\{2,4,6\\}, B=\\{1,3\\}, C=\\{5\\}\\). Then \\(A,B,C\\) form a partition of the sample space \\(S=\\{1,2,3,4,5,6\\}\\). Example: If our random experiment is producing an item on some industrial production line, then we might be interested in whether the object passes a quality control check or not. This forms a partition of all possible outcomes: \\(Q=\\){passes quality check}, and \\(Q^c=\\){fails quality control check}. If we have a partition \\(A_1,A_2,A_3,\\ldots,A_n\\) and any event \\(B\\), then we can break \\(B\\) up into pieces over the partition: \\[B=\\bigcup_{i=1}^n (B\\cap A_i).\\] Notice that the \\(B\\cap A_i\\) are all disjoint. This is true because \\(B\\cap A_i \\subset A_i\\) and the \\(A_i\\) are all disjoint. We can thus calculate the probability of \\(B\\) as \\[P(B)=P\\left(\\bigcup_{i=1}^n (B\\cap A_i)\\right)=\\sum_{i=1}^n P(B\\cap A_i).\\] Example: Rolling a 6-sided die. Let \\(A_1=\\{1,2,3\\}, A_2=\\{4,5\\}, A_3=\\{6\\}\\). Then \\(A_1,A_2,A_3\\) form a partition of the sample space \\(S=\\{1,2,3,4,5,6\\}\\). Consider event \\(B=\\{\\text{odd}\\}=\\{1,3,5\\}\\). We then have that \\(B\\cap A_1=\\{1,3\\}\\), \\(B\\cap A_2=\\{5\\}\\), \\(B\\cap A_3=\\{\\}=\\emptyset\\). Thus \\(P(B)=\\frac36=P(B\\cap A_1)+P(B\\cap A_2)+P(B\\cap A_3)=\\frac26+\\frac16+0\\). 2.7.6 Bayes Theorem Bayes theorem uses the ideas of partitioning the sample space and conditional probability. Suppose we have an industrial production line machine. A certain number of items produced will be defective and the rest will be non-defective. Additionally sometimes a quality control inspection will not catch that a particular item is defective, or a non-defective item will be incorrectly identified as defective. Assume that: Out of every 1,000 items produced, 20 will be defective. Out of every 20 defective items, quality control will correctly identify 19 of them. Out of every 980 non-defective items, quality control will incorrectly determine 50 of them to be defective. Here is what we want to determine: If an item fails the quality control inspection (i.e. it was determined by quality control to be defective), what is the probability that it is actually defective? Recall that quality control misclassifies items sometimes. We create events: \\(D=\\) {item is defective}, thus \\(D^c=\\) {item is non-defective}. \\(F=\\) quality control control determines item to be defective (fail quality control inspection). The question is to calculate the conditional probability \\(P(D\\mid F)\\). We know the reverse conditional probability \\(P(F\\mid D)=\\frac{19}{20}\\) (probability of failing the quality control inspection given that the item is defective). We also know that \\(P(D)=\\frac{20}{1000}\\) (probability of defective), and \\(P(F\\mid D^c)=\\frac{50}{980}\\) (probability a non-defective item fails quality control inspection  a quality control error). First we use the conditional probability formula: \\[P(D\\mid F)=\\frac{P(D\\cap F)}{P(F)}.\\] Then we write the intersection in the numerator as the reverse conditional probability: \\[P(D\\mid F)=\\frac{P(F\\mid D) P(D)}{P(F)}.\\] Notice that this is useful since we know the value for \\(P(F\\mid D)\\) but do not know \\(P(D\\mid F)\\). Then we write the denominator \\(P(F)\\) in terms of the partition \\(D,D^c\\). \\[P(D\\mid F)=\\frac{P(F\\mid D) P(D)}{P(F\\cap D)+P(F\\cap D^c)}.\\] Then we rewrite the intersections in the denominator as conditional probabilities with the partition \\(D,D^c\\). \\[P(D\\mid F)=\\frac{P(F\\mid D) P(D)}{P(F\\mid D)P(D)+P(F\\mid D^c)P(D^c)}.\\] Now we know the values for all of the probabilities in the formula on the right! \\[ \\begin{aligned} P(D\\mid F)&amp;=\\frac{P(F\\mid D) P(D)}{P(F\\mid D)P(D)+P(F\\mid D^c)P(D^c)}\\\\ &amp;=\\frac{\\frac{19}{20} \\cdot \\frac{20}{1000}}{\\frac{19}{20} \\cdot\\frac{20}{1000}+\\frac{50}{980} \\cdot \\left(1-\\frac{20}{1000}\\right)}. \\end{aligned} \\] Lets take a second look at this problem. Here are the initial numbers given again: Out of every 1,000 items produced, 20 will be defective. Out of every 20 defective items, quality control will correctly identify 19 of them. Out of every 980 non-defective items, quality control will incorrectly determine 50 of them to be defective. We can actually determine \\(P(D\\mid F)\\) directly without much effort. Out of the 1,000 items, there will be a total of \\(19+50=69\\) that will fail the quality control check, and 19 of these are actually defective. Thus the probability of an item being defective given that it failed the quality control check is \\(\\frac{19}{69}\\approx 27.5\\%\\). Notice that in this situation, a majority of items that fail quality control check are actually non-defective! Interesting! The general form of Bayes theorem is given for event \\(B\\) and partition \\(A_1,A_2,\\ldots,A_n\\). \\[ \\begin{aligned} P(A_k\\mid B)&amp;=\\frac{P(B\\cap A_k)}{P(B)}\\\\ &amp;=\\frac{P(B\\cap A_k)}{\\sum_{i=1}^n P(B\\cap A_i)}\\\\ &amp;=\\frac{P(B\\mid A_k)P(A_k)}{\\sum_{i=1}^n P(B\\mid A_i)P(A_i)}. \\end{aligned} \\] A very common form of Bayes theorem is when the partition is \\(A,A^c\\). \\[ P(A\\mid B)=\\frac{P(B\\mid A)P(A)}{P(B\\mid A)P(A)+P(B\\mid A^c)P(A^c)}. \\] 2.7.6.1 Alternative Bayes example If instead of being given the information in terms of whole number ratios as above, sometimes Bayes theorem problems are given with fraction, decimal, or percentage probabilities. Here is a similar problem with information given as percentages: The probability of an item being defective is \\(3\\%\\) If an item is defective, it will fail a quality control check \\(96\\%\\) of the time. If an item is non-defective, it will fail a quality control check \\(2\\%\\) of the time. So now we have \\(P(D)=0.03\\), \\(P(D^c)=0.97\\), \\(P(F\\mid D)=0.96\\), and \\(P(F\\mid D^c)=0.02\\). (Note that these are different from the previous example.) We can calculate similarly: \\[ \\begin{aligned} P(D\\mid F)&amp;=\\frac{P(F\\mid D) P(D)}{P(F\\mid D)P(D)+P(F\\mid D^c)P(D^c)}\\\\ &amp;=\\frac{(0.96) \\cdot (0.03)}{(0.96) \\cdot (0.03)+(0.02) \\cdot (0.97)} \\\\ &amp;\\approx 0.5975. \\end{aligned} \\] 2.7.6.2 A trick for solving Bayes problems It is common for students to find it more difficult to work out Bayes theorem problems when given probabilities instead of whole numbers. Here is a trick: turn all the probabilities into ratios of whole numbers! First take the probability with the most significant figures (which is just decimal places for probabilities written as a decimal). Double this result and raise ten to that as a power. This will be our total sample size. All probabilities in our example have two decimal places, thus multiplying by \\(10^{2+2}=\\) 10,000 will give us whole numbers. Out of 10,000 items, \\(10000\\cdot 0.03=300\\) will be defective Out of 300 defective items, \\(300\\cdot 0.96=288\\) will fail the quality control check (correctly be identified as defective). Out of \\(10000-300=9,\\!700\\) non-defective items, \\(9700\\cdot 0.02=194\\) will fail a quality control check (and be erroneously identified as defective). Thus, now we can see that there will be a total of \\(288+194=482\\) items that fail a quality control check, and \\(288\\) of them will actually be defective. Thus \\(P(D\\mid F)=\\frac{288}{482}\\approx 0.5975\\). \\[ \\diamond \\S \\diamond \\] "],["random-variables-and-distributions.html", "Chapter 3 Random variables and distributions 3.1 Expectation and variance 3.2 Joint distributions 3.3 Independence of random variables 3.4 Discrete: Bernoulli, binomial, geometric, Poisson 3.5 Continuous: Uniform, exponential, normal Summary", " Chapter 3 Random variables and distributions Definition. A random variable \\(X\\) is a variable where you must perform a random experiment to determine its value. The sample space \\(S\\) is the set of numerical values that the random variable can take. An event is a subset of the sample space. A random variable can be either discrete (if it takes values in a discrete set such as \\(\\mathbb N\\)) or continuous (if it can take on any value in some intveral). Examples. Let \\(X\\) be the number of dots on the upper face of a dice roll. Let \\(X\\) be the mass of a randomly selected person form a specific population. Let \\(X\\) be the number of cars that pass by a given intersection druing a particular day. Let \\(X\\) be the number of radioactive decays in one hour of some particular material. Definition. A probability function allows us to calculate the probabilities of observing specific numerical values or ranges of values for random variable \\(X\\). A discrete random variable has a probability mass function (pmf) \\(f_X(x)=P(X=x)\\), and a continuous random variable has a probability density function (pdf) \\(f_X(x)\\) which we must integrate to get probabilities \\(P(a&lt;X&lt;b)=\\int_a^b f_X(x)dx\\). The cumulative distribution function (cdf) gives cumulative probabilities \\(F_X(x)=P(X\\leq x)\\). 3.1 Expectation and variance The expected value of a random variable is also called its mean or average value, and denoted \\(E(X)\\). Expected value. Discrete:   \\(E(X)=\\sum_x x f_X(x)\\)   \\(E[g(X)]=\\sum_x g(x) f_X(x)\\) Continuous:   \\(E(X)=\\int_{-\\infty}^\\infty x f_X(x)~dx\\)   \\(E[g(X)]=\\int_{-\\infty}^\\infty g(x) f_X(x)~dx\\) Variance. \\(\\mathsf{Var}(X)=E[(X-E(X))^2]=E(X^2)-E(X)^2\\) Let \\(X\\) have pmf given below. \\[ f_X(x)=\\begin{cases} 0.5 &amp;\\text{ if } x=0\\\\ 0.3 &amp;\\text{ if } x=1\\\\ 0.2 &amp;\\text{ if } x=2\\\\ \\end{cases} \\] Then \\(E(X)=0.5\\cdot 0+0.3\\cdot 1+0.2\\cdot 2=0.7\\). If we repeatedly and independently performed the random experiment that led us to observe random variable \\(X\\), then we would observe a sequence of \\(0\\)s, \\(1\\)s, and \\(2\\)s, and the average observed \\(X\\)-value should be close to \\(0.7\\). The law of large numbers says that if we observe more and more \\(X\\)-values, the average will actually get closer and closer to \\(0.7.\\) The variance is \\(Var(X)=E(X^2)-E(X)^2\\) so we need to calculate the expected value of the function \\(X^2\\) which is \\(E(X^2)=0.5\\cdot0^2+0.3\\cdot1^2+0.2\\cdot2^2=1.1\\). Thus \\(Var(X)=1.1-0.7^2=1.1-0.49=0.61.\\) 3.2 Joint distributions Sometimes a random experiment yields more than one measurement. As an example, we might drill a water well and record several things such as the depth, width, flow rate, and density of the material drilled through. There could be dependencies such as a deeper well having a higher flow rate. Or maybe flow rate is completely independent of depth of the well. We can think of flow rate as one random variable, \\(X\\), and depth as another random variable, \\(Y\\). We could ask for the probabilities for \\(X\\) or \\(Y\\) alone, e.g. \\(P(X=1.3)\\) or \\(P(Y&gt;1000)\\) (these are called marginal probabilities), or we could ask for their joint probabilities, e.g. \\(P(X=1.3 \\text{ and } Y&gt;1000)\\). Normally we can list joint probabilities for two random variables, \\(X\\) and \\(Y\\), in a tabular format. We can list the \\(X\\)-values along the first row \\((x_1,x_2,...)\\), the \\(Y\\)-values along the first column \\((y_1,y_2,...)\\), and in the box for the \\(i^{th}\\) column and \\(j^{th}\\) row, we write the joint probability \\(P(X=x_i,Y=y_j)\\). See the example below. X 10 20 Y 5 0.5 0.2 500 0.1 0.2 Here we have \\(P(X=10,Y=500)=0.1\\) for example. If we wish to calculate a marginal probability, then we must sum over the appropriate row or column, e.g. \\(P(X=10)=P(X=10,Y=5)+P(X=10,Y=500)=0.5+0.1=0.6.\\) We can calculate the marginal pmf for \\(X\\) by summing each column and the marginal pmf for \\(Y\\) by summing each row. In general the marginal probabilities are given by: \\[f_X(x)=P(X=x)=\\sum_y P(X=x,Y=y)=\\sum_y f_{X,Y}(x,y)\\] \\[f_Y(y)=P(Y=y)=\\sum_x P(X=x,Y=y)=\\sum_x f_{X,Y}(x,y).\\] The above is using an example of partitioning the entire (joint) sample space. If we are interested in the even \\(\\{X=x\\}\\) but we only know joint probabilities \\(\\{X=x,Y=y_j\\}\\) for \\(j=1,2,...,m\\) (assume there are \\(m\\) total \\(y\\)-values. Then we have a partition \\(\\{Y=y_1\\},\\ldots,\\{Y=y_m\\}\\), and we can intersect \\(\\{X=x\\}\\) with each of these to create a list of pairwise mutually exclusive events: \\(\\{X=x\\}\\cap\\{Y=y_1\\},\\ldots,\\{X=x\\}\\cap\\{Y=y_m\\}\\). Now we calculate \\[ \\begin{aligned} P(X=x)&amp;=P(\\{X=x\\}\\cap\\{Y=y_1\\})+\\cdots P(\\{X=x\\}\\cap\\{Y=y_m\\})\\\\ &amp;=P(X=x,Y=y_1)+\\cdots P(X=x,Y=y_m)\\\\ &amp;=\\sum_{j=1}^m P(X=x,Y=y_j). \\end{aligned} \\] 3.3 Independence of random variables When working with introductory probability the idea of independent events was covered. Events \\(A\\) and \\(B\\) are independent if and only if \\(P(A\\cap B)=P(A)P(B)\\). Independence for random variables works similarly. Definition. Random variables \\(X\\) and \\(Y\\) are independent if and only if every \\(X\\)-event is independent of every \\(Y\\)-event. That is for every subset of possible \\(X\\)-values \\(A\\) and every subset of possible \\(Y\\)-values \\(B\\) we have \\[P(\\{X\\in A\\}\\cap \\{Y\\in B\\})=P(X\\in A)P(Y\\in B).\\] For discrete random variables \\(X\\) and \\(Y\\), they are independent if and only if \\(P(X=x,Y=y)=P(X=x)P(Y=y)\\) for all \\(x\\) and \\(y\\). That is the joint pmf must be exactly the product of the marginal pmfs. For continuous random variables \\(X\\) and \\(Y\\), they are independent if and only if their joint pdf is exactly the product of the marginal pdfs: \\(f_{X,Y}(x,y)=f_X(x)f_Y(y)\\). Note that for independent random variables, independence requires that the allowable values for one variable must not be affected by the other variable, e.g. the set of possible \\(X\\)-values must not depend on \\(Y\\) in any way. Example. Let \\(X\\) be the outcome of a fair 6-sided die and \\(Y\\) be the outcome of a fair coin flip (\\(0=~\\)tails,\\(1=~\\)heads). Then we naturally think of them as independent, and they are in the technical sense of the term. It makes physical sense that the coin flip shouldnt impact the die roll at all unless we are to use some contrived mechanism to force them to interact, e.g. if a machine were to control the force of the coin flip and die roll is some specific way so that the coin tended to be heads when the die tended to be even. Here the marginal pmfs are \\(f_X(x)=\\frac16\\) for \\(x=1,2,3,4,5,6\\) (and zero otherwise), and the pmf for \\(Y\\) is \\(f_Y(y)=\\frac12\\) for \\(y=0,1\\). Their joint pmf is \\(f_{X,Y}(x,y)=\\frac1{12}\\) for \\((x,y)=(1,0),\\ldots,(6,0),(1,1),\\ldots,(6,1)\\). Example. Let \\(X\\) and \\(Y\\) have joint probabilities given by the table below. X 10 20 Y 5 0.5 0.2 500 0.1 0.2 You can actually look at the table and see that \\(X\\) and \\(Y\\) are not independent by seeing the \\(Y\\)-values of 5 and 500 have equal probability mass under the \\(X=20\\) column but unequal probability mass under the \\(X=10\\) column. It isnt always that simple though. Here is a joint pmf for an independent \\(X,Y\\) pair, and it isnt obvious they are independent. X 10 20 30 Y 5 0.36 0.18 0.06 500 0.24 0.12 0.04 3.4 Discrete: Bernoulli, binomial, geometric, Poisson 3.4.1 Bernoulli Situation/explanation: We perform a single random experiment that has only two outcomes: success and failure. Success and failure can mean almost anything. Success can mean a no vote on a particular election item, or it can mean we find a defective item, or it can mean a die roll has a particular value. \\(X=0\\) for failure, \\(X=1\\) for success, \\(p=\\) probability of success. \\[X\\sim \\text{Bernoulli($p$)}\\] \\[X=0,1\\] \\[f_X(x)= \\begin{cases} 1-p &amp;\\text{ if } x=0\\\\ p &amp;\\text{ if } x=1 \\end{cases}\\] \\[E(X)=p\\] \\[\\text{Var}(X)=p(1-p)\\] In R: \\[f(x) = P(X=x) = \\texttt{dbinom($x$,size=$1$,prob=$p$)}.\\] \\[F(x) = P(X\\leq x) =\\texttt{pbinom($x$,size=$1$,prob=$p$)}.\\] 3.4.2 Binomial Situation/explanation: We perform a fixed number of Bernoulli trials. Count the total number of successes. \\(X=\\) number of successes out of \\(n\\) Bernoulli trials with \\(p=\\) probability of success. \\[X\\sim \\text{Bin($n$,$p$)}\\] \\[X=0,1,2,3,\\ldots,n\\] \\[f_X(x)={n\\choose x}p^x(1-p)^{n-x}\\] \\[E(X)=np\\] \\[\\text{Var}(X)=np(1-p)\\] In R: \\[f(x) = P(X=x) = \\texttt{dbinom($x$,size=$n$,prob=$p$)}. \\quad \\text{ (pmf)}\\] \\[F(x) = P(X\\leq x) =\\texttt{pbinom($x$,size=$n$,prob=$p$)}. \\quad \\text{ (cdf)}\\] \\[\\tilde{x}_q=F^{-1}(q) =\\texttt{qbinom($q$,size=$n$,prob=$p$)}. \\quad \\text{ ($q$100$^{th}$ percentile, inverse cdf)}\\] 3.4.3 Geometric Situation/explanation: We perform Bernoulli trials until we get our first success. Count the total number of trials (a bunch of failures, and one success). \\(X=\\) total number of trials required to get a single success with \\(p=\\) probability of success. (the count includes the success also) Note that there is no fixed total number of trials here. Note: there is a single success, the last trial, the first \\(x-1\\) trials are all failures. \\[X\\sim \\text{Geom($p$)}\\] \\[X=0,1,2,3,\\ldots\\] \\[f(x)=p(1-p)^{x-1}\\] \\[F(x)=1-(1-p)^{x}\\] \\[E(X)=\\frac1p\\] \\[\\text{Var}(X)=\\frac{(1-p)}{p^2}\\] (Note that in R, the definition of \\(X\\) varies from this. In R, \\(X\\) is the number of failures. So when calculating in R for the Geometric random variable, we must either subtract 1 from the \\(x\\) values in R for the pmf and cdf, but add 1 to the output from an R quantile.) In R: \\[f(x) = P(X=x) = \\texttt{dgeom($x$-1,prob=$p$)}.\\quad \\text{ (pmf)}\\] \\[F(x) = P(X\\leq x) =\\texttt{pgeom($x$-1,prob=$p$)}.\\quad \\text{ (cdf)}\\] \\[\\tilde{x}_q=F^{-1}(q) =\\texttt{qgeom($q$,prob=$p$)+1}. \\quad \\text{ ($q$100$^{th}$ percentile, inverse cdf)}\\] 3.4.4 Poisson Situation/explanation: (1) Events arrive over time. Count the number of events in a given time interval. (2) Events are distributed over a spatial region randomly. Count the number of events in a given region. \\(X=\\) number of events that occur at rate \\(\\lambda\\). The rate can be thought of as the number of events per unit time or more generally, number of events per unit. Often it is the number of events per unit length or per unit time. \\[X\\sim \\text{Pois($\\lambda$)}\\] \\[X=0,1,2,\\ldots\\] \\[f_X(x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}\\] \\[E(X)=\\lambda\\] \\[Var(X)=\\lambda\\] In R: \\[f(x) = P(X=x) = \\texttt{dpois($x$,lambda=$\\lambda$)}. \\quad \\text{ (pmf)}\\] \\[F(x) = P(X\\leq x) =\\texttt{ppois($x$,lambda=$\\lambda$)}. \\quad \\text{ (cdf)}\\] \\[\\tilde{x}_q=F^{-1}(q) =\\texttt{qpois($q$,lambda=$\\lambda$)}. \\quad \\text{ ($q$100$^{th}$ percentile, inverse cdf)}\\] 3.5 Continuous: Uniform, exponential, normal 3.5.1 Uniform The random variable is the continuous analog of ``equally likely. \\[X\\sim \\text{Unif($a,b$)}\\] \\[a \\leq X \\leq b\\] \\[f_X(x)=\\frac{1}{b-a} \\quad \\text{ for } x\\in[a,b]\\] \\[ F(x)=\\frac{x-a}{b-a}\\] \\[E(X)=\\frac{a+b}{2}\\] \\[\\text{Var}(X)=\\frac{1}{12}(b-a)^2\\] In R: \\[f(x) = \\texttt{dunif($x$,min=$a$,max=$a$)}. \\quad \\text{ (pdf, not probability mass)}\\] \\[F(x) = P(X\\leq x) =\\texttt{punif($x$,min=$a$,max=$a$)}. \\quad \\text{ (cdf)}\\] 3.5.2 Exponential Suppose events happen at random times (or at random locations along a physical length). The length of time between events can be modeled by an . \\(X=\\) wait time until an event.\\ Rate parameter \\(\\lambda\\) is the number of events per unit time. It can be number of events per unit length as well; it just depends on the context. This is very closely related to the Poisson, as well discuss later. We can refer to \\(X\\) as the inter-arrival time,''wait time, or ``inter-event time. \\[X\\sim \\text{Exp($\\lambda$)}\\] \\[0 \\leq X\\] \\[f_X(x)=\\lambda e^{-\\lambda x} \\quad \\text{ for } x\\geq 0\\] \\[ F(x)=1-e^{-\\lambda x}\\] \\[E(X)=\\frac{1}{\\lambda}\\] \\[\\text{Var}(X)=\\frac{1}{\\lambda^2}\\] In R: \\[f(x) = \\texttt{dexp($x$,rate=$\\lambda$)}. \\quad \\text{ (pdf, not probability mass)}\\] \\[F(x) = P(X\\leq x) =\\texttt{pexp($x$,rate=$\\lambda$)}. \\quad \\text{ (cdf)}\\] \\[\\tilde{x}_q=F^{-1}(q) =\\texttt{qexp($q$,rate=$\\lambda$)}. \\quad \\text{ ($q$100$^{th}$ percentile, inverse cdf)}\\] 3.5.3 Normal The normal distribution is one of the most important. Its probability density function is often called the bell curve or Gaussian. \\[X\\sim \\text{N($\\mu$,$\\sigma^2$)}\\] \\[-\\infty &lt; X &lt; \\infty\\] \\[f_X(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\quad \\text{ for } x\\in\\mathbb R\\] \\[ F(x)=\\text{Unfortunately, can&#39;t be written down in a closed fomula}\\] \\[E(X)=\\mu\\] \\[\\text{Var}(X)=\\sigma^2\\] In R: \\[f(x) = \\texttt{dnorm($x$,mean=$\\mu$,sd=$\\sigma$)}. \\quad \\text{ (pdf, not probability mass)}\\] \\[F(x) = P(X\\leq x) =\\texttt{pnorm($x$,mean=$\\mu$,sd=$\\sigma$)}. \\quad \\text{ (cdf)}\\] \\[\\tilde{x}_q=F^{-1}(q) =\\texttt{qnorm($q$,mean=$\\mu$,sd=$\\sigma$)}. \\quad \\text{ ($q$100$^{th}$ percentile, inverse cdf)}\\] 3.5.3.1 The 68-95-99.7 rule For any normally distributed random variable, we have that there is approximately a 68% chance of being within 1 standard deviation of the mean, a 95% chance of being within 2 standard deviations of the mean, and a 99.7% chance of being within 3 standard deviations of the mean, i.e. that \\[\\begin{aligned} P(\\mu-\\sigma &lt; X &lt; \\mu+\\sigma) &amp;\\approx 68\\%\\\\ P(\\mu-2\\sigma &lt; X &lt; \\mu+2\\sigma) &amp;\\approx 95\\%\\\\ P(\\mu-3\\sigma &lt; X &lt; \\mu+3\\sigma) &amp;\\approx 99.7\\% \\end{aligned}\\] Summary Summary of notation, formulas, and terminology Discrete RVs:   pmf \\(f_X(x)=P(X=x)\\)   cdf \\(F_X(x)=P(X\\leq x)=\\sum_{j\\leq x} f_X(j)\\)   \\(E(X)=\\sum_{x} x P(X=x)=\\sum_{x} x f_X(x)\\) Continuous RVs:   pdf \\(f_X(x)\\), \\(P(a&lt;X&lt;b)=\\int_a^b f_X(x)dx\\)   cdf \\(F_X(x)=P(X\\leq x)=\\int_{-\\infty}^x f_X(t)dt\\), \\(f_X(x)=\\frac{d}{dx}F_X(x)\\)   \\(E(X)=\\int_{-\\infty}^\\infty x f_X(x) dx\\) Variance: \\(\\textrm{Var}(X)=E[(X-E(X))^2]=E(X^2)-E(X)^2\\) Expected value of function of RV: \\(E(h(X))=\\sum_x h(x) f_X(x)\\) (discrete)   \\(E(h(X))=\\int_{-\\infty}^\\infty h(x) f_X(x) dx\\) (continuous) Jointly distributed RVs:   \\(f_{X,Y}(x,y)=P(X=x,Y=y)=P(\\{X=x\\}\\cap\\{Y=y\\})\\) Independence of RVs:   \\(X,Y\\) independent if and only if \\(f_{X,Y}(x,y)=f_X(x) f_Y(y)\\),   i.e. \\(P(X=x,Y=y)=P(X=x)P(Y=y)\\), for all \\(x,y\\) Discrete RVs Bernoulli: models a process with only two outcomes   \\(X\\sim\\mathsf{Bernoulli}(p)\\)   \\(f_X(x)=\\begin{cases}p &amp;\\text{ for } x=1\\\\ 1-p &amp;\\text{ for } x=0\\end{cases}\\)   \\(E(X)=p\\), \\(Var(X)=p(1-p)\\)   R: \\(P(X=x)=~\\)dbinom(x,size=1,prob=p) Binomial: models number of successes in \\(n\\) independent trials with \\(p\\) the probability of success for each trial   \\(X\\sim\\mathsf{Binom}(n,p)\\)   \\(f_X(x)={n\\choose x}p^x (1-p)^{n-x}\\), \\(x=0,1,\\ldots,n\\)   \\(E(X)=np\\), \\(Var(X)=np(1-p)\\)   R: \\(P(X=x)=~\\)dbinom(x,size=n,prob=p) Geometric: models number of trials up to and including first success   \\(X\\sim\\mathsf{Geom}(p)\\)   \\(f_X(x)=p(1-p)^{x-1}\\), \\(x\\in\\{1,2,\\ldots\\}=\\mathbb N\\)   \\(E(X)=\\frac1p\\), \\(Var(X)=\\frac{1-p}{p^2}\\)   R: \\(P(X=x)=~\\)dgeom(x-1,prob=p) (note that R only counts the failures) Poisson: models number of events over a continuous extent   \\(X\\sim\\mathsf{Pois}(\\lambda)\\)   \\(f_X(x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}\\), \\(x\\in\\{0,1,\\ldots\\}=\\mathbb N_0\\)   \\(E(X)=\\lambda\\), \\(Var(X)=\\lambda\\)   R: \\(P(X=x)=~\\)dpois(x,lambda=) Continuous RVs Uniform: models a continuous quantity that takes any value in an interval with equal likelihood   \\(X\\sim\\mathsf{Unif}(a,b)\\)   \\(f_X(x)=\\frac1{b-a}\\), \\(x\\in(a,b)\\)   \\(E(X)=\\frac12(a+b)\\), \\(Var(X)=\\frac1{12}(b^2-a^2)\\)   R: \\(P(X\\leq x)=~\\)punif(x,min=a,max=b) Normal: models quantity that is symmetrically distributed and random variation from many small additive contributions   \\(X\\sim\\mathsf{N}(\\mu,\\sigma^2)\\)   \\(f_X(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\), \\(x\\in\\mathbb R\\)   \\(E(X)=\\mu\\), \\(Var(X)=\\sigma^2\\)   R: \\(P(X\\leq x)=~\\)pnorm(x,mean=,sd=) Exponential: models wait times between events occurring at random times   \\(X\\sim\\mathsf{Exp}(\\lambda)\\)   \\(f_X(x)=\\lambda e^{-\\lambda x}\\), \\(x&gt;0\\)   \\(E(X)=\\frac1\\lambda\\), \\(Var(X)=\\frac1{\\lambda^2}\\)   R: \\(P(X\\leq x)=~\\)pexp(x,rate=) "],["intro-stochastic-processes.html", "Chapter 4 Intro Stochastic Processes Summary", " Chapter 4 Intro Stochastic Processes Generally, a stochastic process consists of an index set \\(T\\) which can usually be thought of as time, and at each time \\(t\\in T\\) we have a (real-valued) random variable \\(X_t\\). We write this as \\((X_t)_{t\\in T}\\) or \\(\\{X_t\\}_{t\\in T}\\). We can think of \\(X_t\\) as a random function of time. You have seen functions of time like \\(x(t)\\) where you plug in a \\(t\\)-value and it outputs an exact \\(x(t)\\)-value according to some formula, but for a stochastic process \\(X_t\\), even when the \\(t\\)-value is specified, we cannot know the precise value for \\(X_t\\) since it is still random. The index set is usually a subset of the set of natural numbers \\(\\mathbb N=\\{1,2,\\ldots\\}\\) or those including zero \\(\\mathbb N_0=\\{0,1,2,\\ldots\\}\\) or a subset of the real numbers \\(\\mathbb R\\). For example, we can have \\(T=\\{1,2\\}\\), \\(T=\\mathbb N_0\\), \\(T=[0,\\infty)\\subset\\mathbb R\\), or \\(T=[0,1]\\). If the index set is discrete, we call it a discrete-time stochastic process and if the index set is continuous (an interval subset of \\(\\mathbb R\\)), we call it a continuous-time stochastic process. Normally, we use \\(X_n\\) for discrete time and \\(X_t\\) for continuous time. If \\(T=\\{1,2\\}\\), then our stochastic process is \\((X_1,X_2)\\) and is a random point in the plane \\(\\mathbb R^2\\). If \\(T=\\mathbb N_0\\), then our stochastic process is \\((X_0, X_1,X_2,\\ldots)\\) and is a random point in \\(\\mathbb R^\\infty\\) (in other words, a infinite sequence of random numbers). If the index set is a continuous interval such as \\(T=[0,1]\\) or \\(T=[0,\\infty)\\), then we can think of \\(X_t\\) as a random function of \\(t\\). The state space \\(S\\) is the set where each random variable \\(X_t\\) takes its values in. Normally, the state space is a subset of the real numbers. Often, we are counting things and the state space will be \\(\\mathbb N\\) or \\(\\mathbb N_0\\), e.g., counting the number of insurance claims that arrive each day or counting the number of radioactive decays every hour. We call such a stochastic process discrete-space. In other cases, we are measuring something like length or amount of money, and the state space is \\([0,\\infty)\\) or some other real line interval. Such stochastic processes are called continuous-space. There are two intuitive ways to think about a stochastic process. We can think of it as \\(X_t\\) where it is implied that we have several random variables, one variable for each value of \\(t\\). Alternatively, we can think of the entire random sequence or function as a single object and write \\(X=(X_t)_{t\\in T}\\). This \\(X\\) is not a random variable, it is a stochastic process. Each \\(X_t\\) is a real-valued random variable, but \\(X\\) is vector-valued, sequence-valued, or function-valued. In order to know the value of \\(X\\), we have to know the value of each \\(X_t\\) for every possible \\(t\\)-value. We can think of \\(X\\) as a random sequence of numbers, \\(X=(X_0,X_1,X_2,\\ldots)\\) where each \\(X_n\\) is a real-valued random variable. Definition. A stochastic process \\(X\\) with state space \\(S\\) and index set \\(T\\) is a collection of random variables \\(X=(X_t)_{t\\in T}\\). For each \\(t\\in T\\), \\(X_t\\) is a \\(S\\)-valued random variable, that is each \\(X_t\\) takes values in \\(S\\). Definition. For stochastic process \\(X=(X_t)_{t\\in T}\\) with state space \\(S\\) and (time) index set \\(T\\), a sample path is a particular full realization of the stochastic process. That is, we know the precise value of \\(X_t\\) for every \\(t\\). Sample paths are specific determined realizations, and we can say \\(x(t)\\) is a specific sample path, that is, it is just a (fixed) function of \\(t\\). Definition. For stochastic process \\(X=(X_t)_{t\\in T}\\) with state space \\(S\\) and (time) index set \\(T\\), the sample path space is \\(\\Omega=S^T\\), that is, if we know the precise value of \\(X_t\\) for all \\(t\\in T\\), then \\(X\\) is a function from \\(T\\) to \\(S\\). Example. Consider the stochastic process \\(X_n\\) for \\(n\\in\\mathbb N\\) and \\(X_n\\sim\\textsf{Bernoulli}(p)\\) for each \\(n\\). The state space is \\(S=\\{0,1\\}\\) since each \\(X_n\\) is a Bernoulli random variable, and the time index set is \\(\\mathbb N\\). The sample path space is \\(\\Omega=\\{0,1\\}^{\\mathbb N}\\) which can also be written as \\(\\{0,1\\}^\\infty\\) or \\(\\{0,1\\}\\times\\{0,1\\}\\times\\cdots\\). In this case \\(\\Omega\\) is just the set of all infinitely long sequences of 0s and 1s, which we call binary sequences. A particular sample path realization is a particuler fixed sequence of zeros and ones, e.g. \\((0,1,1,0,1,0,0,0,1,0,1,1,0,0,\\ldots)\\). A typical sample path should contain roughly an equal number of 1s and 0s over most of it. For example, the first 1000 states will be fairly close to equal parts 0 and 1 to high probability. We can precisely calculate the probability there are, say, less than 450 or more than 550 ones in this case using the binomial distribution. Let \\(Y\\sim\\textsf{Binom}(n=1000,p)\\) be the number of ones. Then \\(P(Y&lt;450\\text{ or }Y&gt;550)=1-P(450\\leq Y\\leq 550)=1-\\sum_{j=450}^{550}{1000\\choose j}p^j(1-p)^{1000-j}\\). If we let \\(p=\\frac12\\), then this is \\(1-\\sum_{j=450}^{550}{1000\\choose j}\\frac1{2^{1000}}\\). In \\(\\textsf{R}\\), we can compute this as 1-sum(dbinom(450:550,1000,0.5)). Since the number of trials is large, we can use the normal approximation 1-pnorm(550,500,sqrt(250))+pnorm(450,500,sqrt(250)) to see it is about 0.14% probability. Here are some examples of how a stochastic process might model a physical process. Example. Consider the following examples. A plant is growing in a pot and we want to model its total biomass over time for 1 year. Let \\(X_t\\) be the total biomass at time \\(t\\). We consider \\(X_t\\) for each \\(t\\) to be \\([0,\\infty)\\)-valued since biomass is nonnegative and we wont impose any particular upper limit on biomass. We let \\([0,365]\\) be the (time) index set and will measure time in days. The state space is thus \\([0,\\infty)\\) and the sample path space is \\(\\Omega=[0,\\infty)^{[0,365]}\\). Each physical realization of a plant growing from germination to death will give us a particular sample path realization which will be a function from \\([0,365]\\) to \\([0,\\infty)\\). This is a continuous-time stochastic process. The number of insurance claims per month for a twelve month year. We let \\(X_n\\) be the number of insurance claims in month \\(n\\) with index set \\(\\{1,2,\\ldots,12\\}\\). The state space is \\(\\mathbb N_0\\) as we could have zero claims in a month or potentially any positive number of claims without any specific upper limit. The sample path space is \\(\\Omega=\\mathbb N_0^{12}\\). A particular sample path realization will be a twelve-tuple (duodecuple) of nonnegative integers, e.g. \\(x=(10,4,0,1,0,8,12,25,37,22,13,9)\\in\\Omega\\). Note that it is important that we consider the ordering of the index set, i.e. that \\(X_1=10, X_2=4\\), etc. Try to construct the following example using the technical stochastic process notation. Practice. Write stochastic process notation for the closing price of a stock each day for one week of five trading days. What is the index set? What is the sample path space? Give a possible sample path realization. Show/hide solution. Solution. Let the index set \\(\\{1,2,\\ldots,5\\}\\) represent days one to five. For each day \\(n\\), the random variable \\(X_t\\) is the closing price of the stock on that day. We can write \\(X=(X_n)_{n=1,2,\\ldots,5}\\) or \\(X=(X_1,X_2,X_3,X_4,X_{5})\\). The sample path space is \\([0,\\infty)^{5}\\) since each full realization of the stochastic process is a sequence of five dollar amounts. Each dollar amount should be nonnegative since a stock doesnt ever have a negative price. An example sample path realization might be \\((105.27,103.52,97.21,95.13,96.83)\\) representing a possible realization of the closing prices on the five days. Summary Summary of terminology and notation. \\(\\mathbb N=\\{1,2,\\ldots\\}\\) is the set of natural numbers. \\(\\mathbb N_0=\\{0,1,2,\\ldots\\}\\) is the set of natural numbers including zero. \\(\\mathbb R=(-\\infty,\\infty)\\) is the set of real numbers. \\(t\\in T\\) means \\(t\\) is an element of the set \\(T\\), e.g. \\(3\\in [-1,5]\\) or \\(\\pi\\in\\mathbb R\\). stochastic process \\(X=(X_t)_{t\\in T}\\), for each \\(t\\), \\(X_t\\) is a random variable. state space \\(S\\) is where observations of \\(X_t\\) will take values in, e.g. \\(S=[0,\\infty)\\) or \\(S=\\mathbb N_0\\). index set \\(T\\) gives the times we observe \\(X_t\\) at. discrete-time if \\(T\\) is discrete, and continuous-time if \\(T\\) is a continuous interval. discrete-space if \\(S\\) is discrete, and continuous-space if \\(S\\) is continuous. sample path space \\(\\Omega=S^T=\\) all functions from \\(T\\) to \\(S\\). sample path or path realization \\(x(t)\\in\\Omega\\) with \\(x:T\\to S\\). Next well do some review of probability theory. "],["random-walks.html", "Chapter 5 Random walks 5.1 The simple symmetric random walk (SSRW) 5.2 Distribution of \\(X_n\\) 5.3 Reflection principle 5.4 Maximum state 5.5 Hit time for state \\(1\\) 5.6 Return time to state \\(0\\) Summary", " Chapter 5 Random walks The random walk will be one of our first official stochastic process models. It models a particle on a line jumping one unit left or right with equal probability. Variations of this can be used for modeling many physical phenomena, including: a viral particle floating in the air (a 3D random walk), an animal moving in its habitat (2D for most land animals, but 1D can work for a restricted habitat), or a stock price (1D). 5.1 The simple symmetric random walk (SSRW) We let \\(X_n\\) be the state of the process at time step \\(n\\) and fix \\(X_0=0\\) (the particle starts at the origin). The particle moves left or right with equal probability, which is given as \\[P(X_{n+1}=j-1\\mid X_n=j)=\\frac12,\\] \\[P(X_{n+1}=j+1\\mid X_n=j)=\\frac12.\\] More generally, we can let \\(P(X_{n+1}=j+1\\mid X_n=j)=p\\) and \\(P(X_{n+1}=j-1\\mid X_n=j)=1-p\\), and if \\(p\\neq\\frac12\\), then we call it a simple asymmetric random walk (SARW). We will refer to the state of the process as the level or location at times, and rather than left or right, we will usually say up and down since we normally graph time horizontally and location on \\(\\mathbb Z\\) vertically. We consider the choice at each time step to go up or down as being independent of every other time step. This model is of a special class of stochastic processes called Markov chains, but well discuss those in more detail later. We can construct this model mathematically in more detail be letting the \\(n^{th}\\) step be random variable \\(Y_n\\) which takes values \\(\\pm1\\) with equal probability and all being independent. We say that the \\(Y_n\\) are i.i.d. (independent and identically distributed) with \\(P(Y_n=1)=P(Y_n=-1)=\\frac12\\) for all \\(n\\). Independence here means that if we want to calculate probabilities for multiple \\(Y_n\\) simultaneously, we can calculate them individually and multiply: \\[P(Y_j=a,Y_k=b)=P(Y_j=a)P(Y_k=b)\\] for any \\(i,j\\in\\mathbb N\\) (with \\(i\\neq j\\)) and any \\(a,b\\in\\{-1,1\\}\\). Then we can write \\[X_n=\\sum_{j=1}^n Y_j.\\] Example. Calculate \\(P(X_3=3)\\). This is only possible if \\(Y_1=Y_2=Y_3=1\\) and so we calculate \\[P(Y_1=1,Y_2=1,Y_3=1)=P(Y_1=1)P(Y_2=1)P(Y_3=1)=\\frac12\\cdot\\frac12\\cdot\\frac12=\\frac18.\\] Example. Calculate \\(P(X_2=0)\\). This is only possible if \\(Y_1=1,Y_2=-1\\) or \\(Y_1=-1,Y_2=1\\) and so we calculate each probability and add the result. \\[P(X_2=0)=P(Y_1=1,Y_2=-1)+P(Y_1=-1,Y_2=1)=\\frac14+\\frac14=\\frac12.\\] The state space of the SSRW is thus the set of integers \\(\\mathbb Z\\) and the time index set is \\(\\mathbb N_0\\). The sample path space will be all infinitely long sequences of integers where consecutive integers only differ by \\(\\pm1\\). We could say that the sample path space is all infinite sequences of integers, but most of those will have probability zero since any sequence which jumps outside of \\(\\pm1\\) would be considered as not possible. So we have our sequence of random variables \\((X_0,X_1,X_2,\\ldots)\\). Of course, \\(X_0\\) is deterministically set to one, but we can still consider it a random variable with full probability mass on one. Now \\(X_1\\) is equally likely to be \\(\\pm1\\). If \\(X_1=1\\), then \\(X_2\\) is equally likely to be \\(0,2\\), and if \\(X_1=-1\\), then \\(X_2\\) is equally likely to be \\(0,-2\\). Definition of a random walk. Let \\(X=(X_n)_{n\\in\\mathbb N_0}\\) be a stochastic process. Then \\(X\\) is a simple random walk if \\(X_0=0\\), and \\(Y_j=X_{j}-X_{j-1}\\) are i.i.d. for \\(j=1,2,\\ldots\\) with probabilities \\(P(Y_j=1)=p\\) and \\(P(Y_j=-1)=1-p\\). What this tells us is that we can construct other random walks from a previous one. Let \\(X_n\\) be the SSRW. Then \\(-X_n\\) is also a SSRW. Lets check that it satisfies the criteria: \\(-X_0=0\\) (since \\(X_0=0\\) because \\(X_n\\) is a SSRW), and \\((-X_{j})-(-X_{j-1})=-Y_j\\) and \\(P(-Y_j=1)=P(Y_j=-1)=\\frac12\\), \\(P(-Y_j=-1)=P(Y_j=1)=\\frac12\\) (where we use \\(Y_j\\) to represent the individual steps for the original SSRW \\(X_n\\)). Hence \\(-X_n\\) is an SSRW also! One important thing to realize here is that when we write \\(X_n\\) and \\(-X_n\\) we do mean precisely that they are literally reflections of one another. In other words, if we know a particular value, say \\(X_5=3\\), then we know that the reflected process is exactly at level \\(-3\\) for time step \\(5\\). This is true because \\(X_5\\) is a random variable, and so anywhere we see \\(X_5\\), it is the same random variable whose value is determined by the same radom experiment (e.g. simulating a random walk path). Example. Let \\(X_n\\) be the SSRW. Let \\(W_n\\) be a stochastic process, and show that the following are also SSRWs. \\(W_n=-X_n\\) \\(W_n=X_{3+n}-X_3\\) \\(W_n=\\sum_{j=1}^n (X_{2j}-X_{2j-1})\\) with \\(W_0=0\\) Show/hide solution. We covered this example in the text above. This is a shifted random walk. The \\(W_n\\) sample path is identical to the \\(X_n\\) sample path but starting from \\(X_3\\) and being shifted back to starting from the origin. In other words, we can imagine a completely simulated sample path for \\(X_n\\), and we just ignore the first three time steps and take the remaining part of the sample path and shift it back to starting at the origin, preserving its exact shape. We calculate \\(W_0=X_{3+0}-X_3=0\\) and \\(W_j-W_{j-1}=(X_{3+j}-X_3)-(X_{3+j-1}-X_3)=X_{3+j}-X_{3+j-1}=Y_{3+j}\\) and know that \\(Y_4,Y_5,\\ldots\\) are i.i.d. with teh desired probabilities. The \\(n^{th}\\) step for \\(W_n\\) is the \\(2n^{th}\\) step for \\(X_n\\). In other words, \\(W_n\\) only considers the even steps. If \\(X_n=\\sum_{j=1}^n Y_j\\), then \\(W_n=\\sum_{j=1}^n Y_{2j}\\). We see that \\(W_0=0\\) is given and calculate \\(W_k-W_{k-1}=\\sum_{j=1}^k (X_{2j}-X_{2j-1})-\\sum_{j=1}^{k-1} (X_{2j}-X_{2j-1})=X_{2k}-X_{2k-1}=Y_{2k}\\). We know that \\(Y_2,Y_4,\\ldots\\) are i.i.d. with equal probability on \\(\\pm1\\). 5.2 Distribution of \\(X_n\\) Since \\(X_n\\) is a random sum of a bunch of plus and minus ones, we can relate it to a sum of Bernoulli random variables. If we think of flipping a fair coin \\(n\\) times and let \\(H\\) be the number of heads and \\(T\\) be the number of tails, then we must have \\(H+T=n\\). If the \\(j^{th}\\) coint flip is heads, we set \\(Y_j=1\\) and if it is tails, we set \\(Y_j=-1\\). In this way, we can reason that \\[X_n=(\\# \\text{ heads})-(\\# \\text{ tails})=H-T=H-(n-H)=2H-n.\\] Since we know that \\(H\\sim\\mathsf{binom}(n,\\frac12)\\) (\\(H\\) is governed by the binomial distribution with \\(n\\) trials and \\(p=\\frac12\\) probability of success), we can use this to calculate probabilities for \\(X_n\\): Distribution of \\(X_n\\) for SSRW. \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)={n\\choose \\frac{n+j}{2}}\\frac1{2^n}.\\] More generally, for the asymmetric random walk, with \\(p\\neq\\frac12\\), we have \\[P(X_n=j)={n\\choose \\frac{n+j}{2}}p^{\\frac{n+j}{2}}(1-p)^{\\frac{n-j}{2}}.\\] Now we refresh the normal approximation to the binomial. Normal approximation to binomial. Let \\(X\\sim\\mathsf{binom}(n,p)\\), then for \\(n\\) large (usually \\(n\\geq 30\\) with \\(np\\geq5\\) and \\(n(1-p)\\geq5\\) is acceptable, but it might still be a rough approximation). Then we can say that \\[X\\overset{\\small approx}{\\sim} \\mathsf{N}(\\mu=np,\\sigma^2=np(1-p)).\\] The binomial is a discrete distribution, but the normal is a continuous distribution. Any time we use a continuous distribution to approximate a discrete distribution, it might be useful to use a continuity correction. Continuity correction. If discrete random variable \\(X\\) has values \\(x_1,x_2,\\ldots\\) and we wish to approximate \\(P(X=x_j)\\) by continuous random variable \\(Y\\), then we can integrate the probability density function of \\(Y\\) from halfway to the next \\(x\\)-values on the left and right: \\[P(X=x_j)\\approx P(x_j-(x_j-x_{j-1})/2 &lt; Y \\leq x_j+(x_j-x_{j-1})/2).\\] For the normal approximation to the binomial random variable \\(X\\sim binom(n,p)\\), this translates to using \\(Y\\sim N(np,np(1-p))\\) and \\[P(X=k)\\approx P\\left(k-\\frac12 &lt; Y \\leq k+\\frac12\\right).\\] Normal approximation to distribution of \\(X_n\\) for SSRW. We have that \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)\\] and that \\(H\\) is binomial distributed with parameters \\(n,p\\) and hence is approximately normally distributed with mean \\(\\mu=np\\) and variance \\(\\sigma^2=np(1-p)\\). Now we can then write \\[P(X_n=j)=P(2H-n=j)=P\\left(H=\\frac{n+j}{2}\\right)\\approx P\\left(\\frac{n+j}{2}-\\frac12&lt;Y\\leq \\frac{n+j}{2}+\\frac12\\right)\\] where \\(Y\\sim\\mathsf N(\\mu=np,\\sigma^2=np(1-p))\\). In R we can calculate normal cumulative probabilities using pnorm(), so the above probability for \\(P(X_n=j)\\) is given by the R code (with the continuity correction) pnorm((n+j)/2+1/2,mean=n*p,sd=sqrt(n*p*(1-p)))-pnorm((n+j)/2-1/2,mean=n*p,sd=sqrt(n*p*(1-p))) Example. Lets calculate \\(P(X_7=-3)\\). We have \\(n=7\\), \\(p=0.5\\), and \\(j=-3\\). The exact calculation using the distribution we derived from the bionomial is: \\[P(X_7=-3)={7\\choose\\frac{7-3}{2}}\\frac1{2^7}={7\\choose2}\\frac1{2^7}=\\frac{7\\cdot 3}{2^7}\\approx0.1640625.\\] And using the normal approximation (with continuity correction) we get: \\(P(X_7=-3)\\approx\\)pnorm(2.5,7/2,sqrt(7)/2)-pnorm(1.5,7/2,sqrt(7)/2)\\(\\approx0.1595609\\) which is a reasonable approximation. We can make the R code a bit simpler though. If \\(X\\sim N(\\mu\\sigma^2)\\) then \\(aX+b\\sim N(a\\mu+b,a^2\\sigma^2)\\). This means that \\(aX+b\\) is a normal random variable as well with \\(E(aX+b)=a\\mu+b\\) and \\(Var(aX+b=a^2\\sigma^2)\\). Since we are approximating \\(H\\), the number of up steps, as a normal random variable, then \\(2H-n\\) is also approximately normally distributed. \\[X_n=2H-n\\overset{\\small approx}{\\sim}\\mathsf{N}(\\mu=2np-n,\\sigma^2=4np(1-p)).\\] And for the SSRW this means \\[X_n=2H-n\\overset{\\small approx}{\\sim}\\mathsf{N}(\\mu=0,\\sigma^2=n).\\] Now to apply the continuity correction is a bit trickier though, because \\(X_n\\) only takes on values \\(-n,-n+2,\\ldots,n-2,n\\). Instead of adding and subtracting \\(\\frac12\\), we must add and subtract \\(1\\) and \\(P(X_n=j)\\) is approximated by pnorm(j+1,0,sqrt(n))-pnorm(j-1,0,sqrt(n)). Partitioning. Note that when we calculate something like \\(P(X_2=0)\\), we are implicitly using the ideas of joint distributions, partitioning, and conditioning in teh following way \\[\\begin{aligned} P(X_2=0)&amp;=P(X_1=1,X_2=0)+P(X_1=-1,X_2=0)\\\\ &amp;=P(X_1=1)P(X_2=0\\mid X_1=1)+P(X_1=-1)P(X_2=0\\mid X_1=-1)\\\\ &amp;=\\frac12\\cdot\\frac12+\\frac12\\cdot\\frac12. \\end{aligned}\\] Although, one can work out such probabilities by sketching a diagram and counting paths, etc. Here is another example of the use of conditioning: \\[ \\begin{aligned} P(X_1=-1,X_2=0,X_3=1)&amp;=P(X_1=-1)P(X_2=0,X_3=1\\mid X_1=-1)\\\\ &amp;=P(X_1=-1)P(X_2=0\\mid X_1=-1)P(X_3=1\\mid X_1=-1,X_2=0). \\end{aligned}\\] In general, we can calculate probabilities about the future state of the process given information about its current and past states, so a conditional probability like \\(P(X_3=1\\mid X_1=-1,X_2=0)\\) will make sense given that we know the rules for the stochastic process \\(X_n\\). In most cases, we will only need to know the current state (this is memorylessness or the Markov propertymore on that later). The simple random walk satisfies this, and we have \\[P(X_3=1\\mid X_1=-1,X_2=0)=(X_3=1\\mid X_2=0).\\] 5.3 Reflection principle Now well look at a property of the sample path space which will help us understand a few more properties for the random walk. Consider some state \\(m\\) which we are interested in the RW hitting at some time step \\(n=0,1,2,\\ldots,k\\). Clearly we must consider \\(m\\) between \\(-k\\) and \\(k\\) since the RW can only go that far in \\(k\\) time steps. We consider a sample path and the first time it hits level \\(m\\). We create a second sample path by tracing the first one up to this point and then reflecting everything after that initial hit of level \\(m\\). In the following plot, we let \\(m=2\\). The red path is identical to the black dash-dot path up until the first hit of level \\(2\\). After that the red path is a reflection of the black dash-dot path. There is a special pattern here, that any path that ends up, in the end, above level \\(m\\) will be reflected to create a path that ends up below level \\(m\\). Note that we are only considering paths that ultimately hit level \\(m\\), otherwise the reflection acros level \\(m\\) doesnt work. We summarize this below. The number of paths that hit level \\(m\\) and end up strictly above level \\(m\\) is the same as the number of paths that hit level \\(m\\) and end up strictly below level \\(m\\). \\[\\#\\{X_j=m \\text{ for some } j\\leq n, X_n&gt;m\\}=\\#\\{X_j=m \\text{ for some } j\\leq n, X_n&lt;m\\}\\] 5.4 Maximum state Let \\(M_n=\\max\\{X_0,X_1,\\ldots,X_n\\}\\) be the maximum level hit by the process up to time step \\(n\\). \\[P(M_n=k)=P(X_n=k)+P(X_{n}=k+1)\\] We derive this using the reflection principle and the fact that \\(P(M_n=k)=P(M_n\\geq k)-P(M_n\\geq k+1)\\). \\[P(M_n\\geq k)=P(M_n\\geq k,X_n&gt;k)+P(M_n\\geq k,X_n=k)+P(M_n\\geq k,X_n&lt;k)\\] We can calculate the middle term using know methods: \\[P(M_n\\geq k,X_n=k)=P(X_n=k).\\] Using the reflection principle, we know that the events \\(\\{M_n\\geq k,X_n&gt;k\\}\\) and \\(\\{M_n\\geq k,X_n&gt;k\\}\\) have the same number of paths. For the SSRW, each of these paths is equally likely, so we get that \\(P(M_n\\geq k,X_n&gt;k)=P(M_n\\geq k,X_n&lt;k)\\) and hence only need to calculate \\(P(M_n\\geq k,X_n&gt;k)\\). But \\(P(M_n\\geq k,X_n&gt;k)=P(X_n&gt;k)\\) which we can calculate from known formulas: \\[P(M_n\\geq k,X_n&gt;k)=P(X_n&gt;k)=\\sum_{j=k+1}^n P(X_n=j).\\] Putting all this together we get (for the SSRW with \\(p=0.5\\)): \\[\\begin{aligned} P(M_n\\geq k)&amp;=P(M_n\\geq k,X_n&gt;k)+P(M_n\\geq k,X_n=k)+P(M_n\\geq k,X_n&lt;k)\\\\ &amp;=2P(M_n\\geq k,X_n&gt;k)+P(M_n\\geq k,X_n=k)\\\\ &amp;=2P(X_n&gt;k)+P(X_n=k).\\\\ \\end{aligned}\\] And finally we see that \\[\\begin{aligned} P(M_n= k)&amp;=P(M_n\\geq k-P(M_n\\geq k+1)\\\\ &amp;=(2P(M_n\\geq k,X_n&gt;k)+P(M_n\\geq k,X_n=k)\\\\ &amp;=(2P(X_n&gt;k)+P(X_n=k))-(2P(X_n&gt;k+1)+P(X_n=k+1))\\\\ &amp;=2P(X_n&gt;k+1)+2P(X_n=k+1)+P(X_n=k)-2P(X_n&gt;k+1)-P(X_n=k+1)\\\\ &amp;=P(X_n=k+1)+P(X_n=k).\\\\ \\end{aligned}\\] 5.5 Hit time for state \\(1\\) We wish to know how long it takes for the SARW to hit level \\(1\\). Let \\(T_1=\\min\\{n&gt;0 : X_n=1\\}\\) which we call the hitting time for state \\(1\\). \\[P(T_1=2k+1)=\\frac1{k+1}{2k\\choose k}p^{k+1}(1-p)^k, \\ k=0,1,2,\\ldots.\\] Hitting time for other states. If we are interested in how long it takes for the process to hit state \\(2\\), then we wait for it to hit state \\(1\\). From this point, we only need to wait for it to go up another +1 from the current state, which is equivalent for waiting a random time which is distributed exactly the same as the hitting time for state one. Let \\(T_2\\) be the hitting time for state \\(2.\\) What this reasoning shows is that \\(T_2=\\tau_1+\\tau_2\\) where \\(\\tau_1\\) and \\(\\tau_2\\) have the same distribution as \\(T_1\\) and are independent. In general, letting \\(T_k\\) be the hitting time for state \\(k\\), we have \\[T_k=\\sum_{j=1}^k \\tau_j\\] where \\(\\tau_j\\) are i.i.d. and distributed identically to \\(T_1\\). Example. For example \\(T_2=\\tau_1+\\tau_2\\). If we wish to calculate \\(P(T_2=4)\\) then we need to consider all possibilities for \\(\\tau_1,\\tau_2\\) that sum to give us 4 total time steps, and we use independence of the \\(\\tau_j\\). \\[\\begin{aligned} P(T_2=4)&amp;=P(\\tau_1+\\tau_2=4)\\\\ &amp;=P(\\tau_1=1,\\tau_2=3)+P(\\tau_1=3,\\tau_2=1)\\\\ &amp;=P(\\tau_1=1)P(\\tau_2=3)+P(\\tau_1=3)P(\\tau_2=1)\\\\ &amp;=P(T_1=1)P(T_1=3)+P(T_1=3)P(T_2=1)\\\\ &amp;=2P(T_1=1)P(T_1=3)\\\\ &amp;=2 \\frac1{0+1}{2\\cdot 0\\choose 0}p^{0+1}(1-p)^0 \\frac1{1+1}{2\\cdot 1\\choose 1}p^{1+1}(1-p)^1 \\\\ &amp;=2 p^3 (1-p) \\\\ \\end{aligned}\\] 5.6 Return time to state \\(0\\) We have that \\(X_0=0\\) initially. We want to know how long it takes for the random walk to return to state zero. Let \\(T_0=\\min\\{n&gt;0 : X_n=0\\}\\) which we call the return time to zero. We can calculate \\(P(T_0=2k)\\) for \\(k=1,2,\\ldots\\) by sketching a graph and counting paths. For example, \\(P(T_0=2)=\\frac12\\) since this means the first two time steps are up then down or vice versa. Similarly, we can calculate \\(P(T_0=4)=\\frac18\\). The general formula is \\[P(T_0=2k)=\\frac1{2k-1}{2k\\choose k}p^{k}(1-p)^k, \\ k=1,2,\\ldots.\\] Summary Summary of notation, formulas, and terminology For \\(X_n\\) the simple 1D random walk with \\(p\\) probability of an up step: \\(P(X_n=j)={n\\choose (n+j)/2}p^{(n+j)/2}(1-p)^{(n-j)/2}\\)     For SSRW: \\(P(X_n=j)={n\\choose (n+j)/2}\\frac1{2^n}\\) \\(P(X_n=j)\\approx\\)pnorm(j+1,2*n*p-n,sqrt(4*n*p*(1-p)))-pnorm(j-1,2*n*p-n,sqrt(4*n*p*(1-p)))     For SSRW: \\(P(X_n=j)\\approx\\)pnorm(j+1,0,sqrt(n)-pnorm(j-1,0,sqrt(n)) \\(P(T_1=2k+1)=\\frac1{k+1}{2k\\choose k}\\frac1{2^{2k+1}}\\), \\(T_1=~\\)first time SSRW (\\(p=\\frac12\\)) to hit state \\(1\\) \\(P(T_1=2k+1)=\\frac1{k+1}{2k\\choose k}p^{k+1}(1-p)^k\\), \\(T_1=~\\)first time SARW (any \\(p\\in[0,1]\\)) to hit state \\(1\\) \\(P(T_0=2k)=\\frac1{2k-1}{2k\\choose k}p^{k}(1-p)^k\\), \\(T_0=~\\)first time SARW returns to state \\(0\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
