<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes</title>
  <meta name="description" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  
  
  

<meta name="author" content="Joseph Stover" />


<meta name="date" content="2023-03-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="limit-theorems.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script type="text/javascript">
  function unhide(divID) {
    var item = document.getElementById(divID);
    if (item) {
      item.className=(item.className=='hiddendiv')?'unhiddendiv':'hiddendiv';
    }
  }
</script> 


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stochastic Processes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> Introduction to R and RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#getting-access-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> Getting access to R and RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#r-basics"><i class="fa fa-check"></i><b>1.2</b> R basics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#data-structures-vectors-matrices"><i class="fa fa-check"></i><b>1.2.1</b> Data structures, vectors, matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#installing-and-using-packages-in-r"><i class="fa fa-check"></i><b>1.3</b> Installing and using packages in R</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#random-variables"><i class="fa fa-check"></i><b>1.4</b> Random variables</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#basics-of-programming-r-scripts"><i class="fa fa-check"></i><b>1.5</b> Basics of programming, R scripts</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#importing-datasets-into-r"><i class="fa fa-check"></i><b>1.6</b> Importing datasets into R</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html"><i class="fa fa-check"></i><b>2</b> Counting, sets, and probability basics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#ticket-in-a-box-model-of-probability"><i class="fa fa-check"></i><b>2.1</b> Ticket-in-a-box model of probability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sampling-from-a-box-of-tickets"><i class="fa fa-check"></i><b>2.1.1</b> Sampling from a box of tickets</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#relative-area-model-of-probability"><i class="fa fa-check"></i><b>2.2</b> Relative area model of probability</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#one-dimension"><i class="fa fa-check"></i><b>2.2.1</b> One dimension</a></li>
<li class="chapter" data-level="2.2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#two-or-more-dimensions"><i class="fa fa-check"></i><b>2.2.2</b> Two or more dimensions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.3</b> Sample Spaces and Events</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-space"><i class="fa fa-check"></i><b>2.3.1</b> Sample space</a></li>
<li class="chapter" data-level="2.3.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#events"><i class="fa fa-check"></i><b>2.3.2</b> Events</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#set-operations"><i class="fa fa-check"></i><b>2.4</b> Set Operations</a></li>
<li class="chapter" data-level="2.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#venn-diagrams"><i class="fa fa-check"></i><b>2.5</b> Venn Diagrams</a></li>
<li class="chapter" data-level="2.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#counting-permutations-and-combinations"><i class="fa fa-check"></i><b>2.6</b> Counting, permutations, and combinations</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#multiplication-rule"><i class="fa fa-check"></i><b>2.6.1</b> Multiplication rule</a></li>
<li class="chapter" data-level="2.6.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#nk"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(n^k\)</span></a></li>
<li class="chapter" data-level="2.6.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#factorials"><i class="fa fa-check"></i><b>2.6.3</b> Factorials</a></li>
<li class="chapter" data-level="2.6.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#permutation"><i class="fa fa-check"></i><b>2.6.4</b> Permutation</a></li>
<li class="chapter" data-level="2.6.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#combination"><i class="fa fa-check"></i><b>2.6.5</b> Combination</a></li>
<li class="chapter" data-level="2.6.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#summary-of-counting"><i class="fa fa-check"></i><b>2.6.6</b> Summary of counting</a></li>
<li class="chapter" data-level="2.6.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#special-case-with-replacement-order-doesnt-matter-the-multiset"><i class="fa fa-check"></i><b>2.6.7</b> Special case: with replacement, order doesn’t matter: the multiset</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#probability"><i class="fa fa-check"></i><b>2.7</b> Probability</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#equally-likely-outcomes"><i class="fa fa-check"></i><b>2.7.1</b> Equally likely outcomes</a></li>
<li class="chapter" data-level="2.7.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#general-probability-theory"><i class="fa fa-check"></i><b>2.7.2</b> General probability theory</a></li>
<li class="chapter" data-level="2.7.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#independence"><i class="fa fa-check"></i><b>2.7.3</b> Independence</a></li>
<li class="chapter" data-level="2.7.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#conditional-probability"><i class="fa fa-check"></i><b>2.7.4</b> Conditional probability</a></li>
<li class="chapter" data-level="2.7.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#partitions"><i class="fa fa-check"></i><b>2.7.5</b> Partitions</a></li>
<li class="chapter" data-level="2.7.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#bayes-theorem"><i class="fa fa-check"></i><b>2.7.6</b> Baye’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html"><i class="fa fa-check"></i><b>3</b> Random variables and distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#expectation-and-variance"><i class="fa fa-check"></i><b>3.1</b> Expectation and variance</a></li>
<li class="chapter" data-level="3.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#joint-distributions"><i class="fa fa-check"></i><b>3.2</b> Joint distributions</a></li>
<li class="chapter" data-level="3.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#independence-of-random-variables"><i class="fa fa-check"></i><b>3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="3.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#discrete-bernoulli-binomial-geometric-poisson"><i class="fa fa-check"></i><b>3.4</b> Discrete: Bernoulli, binomial, geometric, Poisson</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#bernoulli"><i class="fa fa-check"></i><b>3.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="3.4.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#binomial"><i class="fa fa-check"></i><b>3.4.2</b> Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#geometric"><i class="fa fa-check"></i><b>3.4.3</b> Geometric</a></li>
<li class="chapter" data-level="3.4.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#poisson"><i class="fa fa-check"></i><b>3.4.4</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#continuous-uniform-exponential-normal"><i class="fa fa-check"></i><b>3.5</b> Continuous: Uniform, exponential, normal</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#uniform"><i class="fa fa-check"></i><b>3.5.1</b> Uniform</a></li>
<li class="chapter" data-level="3.5.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#exponential"><i class="fa fa-check"></i><b>3.5.2</b> Exponential</a></li>
<li class="chapter" data-level="3.5.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#normal"><i class="fa fa-check"></i><b>3.5.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-expectation.html"><a href="conditional-expectation.html"><i class="fa fa-check"></i><b>4</b> Conditional expectation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-distributions"><i class="fa fa-check"></i><b>4.1</b> Conditional distributions</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-expectation-1"><i class="fa fa-check"></i><b>4.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-expectation.html"><a href="conditional-expectation.html#random-conditional-expectation"><i class="fa fa-check"></i><b>4.3</b> (Random) conditional expectation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#total-expectation"><i class="fa fa-check"></i><b>4.3.1</b> Total expectation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conditional-expectation.html"><a href="conditional-expectation.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html"><i class="fa fa-check"></i><b>5</b> Intro Stochastic Processes</a>
<ul>
<li class="chapter" data-level="" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-walks.html"><a href="random-walks.html"><i class="fa fa-check"></i><b>6</b> Random walks</a>
<ul>
<li class="chapter" data-level="6.1" data-path="random-walks.html"><a href="random-walks.html#the-simple-symmetric-random-walk-ssrw"><i class="fa fa-check"></i><b>6.1</b> The simple symmetric random walk (SSRW)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="random-walks.html"><a href="random-walks.html#definition-of-a-random-walk"><i class="fa fa-check"></i><b>6.1.1</b> Definition of a random walk</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="random-walks.html"><a href="random-walks.html#distribution-of-x_n"><i class="fa fa-check"></i><b>6.2</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="random-walks.html"><a href="random-walks.html#shift-invariance-memorylessness"><i class="fa fa-check"></i><b>6.3</b> Shift invariance &amp; memorylessness</a></li>
<li class="chapter" data-level="6.4" data-path="random-walks.html"><a href="random-walks.html#reflection-principle"><i class="fa fa-check"></i><b>6.4</b> Reflection principle</a></li>
<li class="chapter" data-level="6.5" data-path="random-walks.html"><a href="random-walks.html#maximum-state-reached"><i class="fa fa-check"></i><b>6.5</b> Maximum state reached</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="random-walks.html"><a href="random-walks.html#maximum-over-infinite-sample-paths-for-p12"><i class="fa fa-check"></i><b>6.5.1</b> Maximum over infinite sample paths for <span class="math inline">\(p&lt;1/2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="random-walks.html"><a href="random-walks.html#hitting-times"><i class="fa fa-check"></i><b>6.6</b> Hitting times</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-state-1"><i class="fa fa-check"></i><b>6.6.1</b> Hitting time for state <span class="math inline">\(1\)</span></a></li>
<li class="chapter" data-level="6.6.2" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-other-states"><i class="fa fa-check"></i><b>6.6.2</b> Hitting time for other states</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="random-walks.html"><a href="random-walks.html#return-time-to-state-0"><i class="fa fa-check"></i><b>6.7</b> Return time to state <span class="math inline">\(0\)</span></a></li>
<li class="chapter" data-level="" data-path="random-walks.html"><a href="random-walks.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>7</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="7.1" data-path="limit-theorems.html"><a href="limit-theorems.html#inequalities"><i class="fa fa-check"></i><b>7.1</b> Inequalities</a></li>
<li class="chapter" data-level="7.2" data-path="limit-theorems.html"><a href="limit-theorems.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2</b> Law of large numbers</a></li>
<li class="chapter" data-level="7.3" data-path="limit-theorems.html"><a href="limit-theorems.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Central limit theorem</a></li>
<li class="chapter" data-level="7.4" data-path="limit-theorems.html"><a href="limit-theorems.html#borel-cantelli"><i class="fa fa-check"></i><b>7.4</b> Borel-Cantelli</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>8</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="8.1" data-path="markov-chains.html"><a href="markov-chains.html#graph-of-a-markov-chain"><i class="fa fa-check"></i><b>8.1</b> Graph of a Markov chain</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chains.html"><a href="markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>8.2</b> Classification of states</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chains.html"><a href="markov-chains.html#distribution-at-time-n"><i class="fa fa-check"></i><b>8.3</b> Distribution at time <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="markov-chains.html"><a href="markov-chains.html#simulating-a-markov-chain-in-r"><i class="fa fa-check"></i><b>8.4</b> simulating a Markov chain in R</a></li>
<li class="chapter" data-level="8.5" data-path="markov-chains.html"><a href="markov-chains.html#return-times-and-hitting-probabilities"><i class="fa fa-check"></i><b>8.5</b> Return times and hitting probabilities</a></li>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math 423 Stochastic Processes Course Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="markov-chains" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Markov Chains<a href="markov-chains.html#markov-chains" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Markov chains are one of the most important classes of stochastic process. A <strong>discrete-time Markov chain</strong> (DTMC) consists of specifying a state space and a transition matrix. For us, our state space will generally be <span class="math inline">\(S=\{0,1,\ldots,k\}\)</span> and our time index set will be <span class="math inline">\(\mathbb N_0\)</span>. The <strong>transition matrix</strong> gives us the transition probabilities between each pair of states and is given as
<span class="math display">\[T=
\left(\begin{matrix}
T_{00} &amp; T_{01} &amp; \cdots &amp; T_{0k}\\
T_{10} &amp; T_{11} &amp; \cdots &amp; T_{1k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
T_{k0} &amp; T_{k1} &amp; \cdots &amp; T_{kk}\\
\end{matrix}\right)\]</span>
where
<span class="math display">\[T_{ij}=P(X_n=j\mid X_{n-1}=i).\]</span></p>
<p>We assume this stochastic process satisfied the <em>Markov property</em> or <em>memorylessness</em>, which means that the probabilities for the next time step only depends on the current state and no other previous history:
<span class="math display">\[P(X_n=j \mid X_{n-1}=i,X_{n-2}=\ell_{n-2},\ldots,X_{1}=\ell_{1},X_{0}=\ell_{0})=P(X_n=j \mid X_{n-1}=i)=T_{ij}.\]</span></p>
<div id="graph-of-a-markov-chain" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Graph of a Markov chain<a href="markov-chains.html#graph-of-a-markov-chain" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For a Markov chain with state space <span class="math inline">\(S\)</span>, we can represent the possible transitions graphically in Euclidean space. For now, let’s assume the state space is finite, but even chains with infinite state spaces can have graphs constructed in this way. Plot a point for each state in the plane <span class="math inline">\(\mathbb R^2\)</span>, and label each point by the state it corresponds to. Draw a directed edge (an arrow) from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> whenever <span class="math inline">\(T_{ij}&gt;0\)</span>.</p>
<p>We can use <code>install.packages("igraph")</code> if we wish to plot transition graphs for Markov chains.</p>
<p>Consider the transition matrix
<span class="math display">\[
T=\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}.
\]</span>
Here is some R code for plotting the transition diagram along with the plot.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="markov-chains.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraph)</span>
<span id="cb44-2"><a href="markov-chains.html#cb44-2" aria-hidden="true" tabindex="-1"></a>tmvec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,</span>
<span id="cb44-3"><a href="markov-chains.html#cb44-3" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.0</span>,<span class="fl">0.3</span>,<span class="fl">0.7</span>,</span>
<span id="cb44-4"><a href="markov-chains.html#cb44-4" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.0</span>)</span>
<span id="cb44-5"><a href="markov-chains.html#cb44-5" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(tmvec,<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb44-6"><a href="markov-chains.html#cb44-6" aria-hidden="true" tabindex="-1"></a>mcg <span class="ot">&lt;-</span> <span class="fu">graph_from_adjacency_matrix</span>(<span class="dv">1</span><span class="sc">*</span>(TM<span class="sc">&gt;</span><span class="dv">0</span>))</span>
<span id="cb44-7"><a href="markov-chains.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.igraph</span>(mcg,</span>
<span id="cb44-8"><a href="markov-chains.html#cb44-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">vertex.size=</span><span class="dv">50</span>,</span>
<span id="cb44-9"><a href="markov-chains.html#cb44-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">vertex.color=</span><span class="st">&quot;grey90&quot;</span>,</span>
<span id="cb44-10"><a href="markov-chains.html#cb44-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.curved=</span><span class="fl">0.25</span>,</span>
<span id="cb44-11"><a href="markov-chains.html#cb44-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.color=</span><span class="st">&quot;black&quot;</span>,</span>
<span id="cb44-12"><a href="markov-chains.html#cb44-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.label=</span>tmvec[tmvec<span class="sc">&gt;</span><span class="dv">0</span>],</span>
<span id="cb44-13"><a href="markov-chains.html#cb44-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.loop.angle=</span><span class="fu">c</span>(pi,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">4</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>),</span>
<span id="cb44-14"><a href="markov-chains.html#cb44-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">margin=</span><span class="fl">0.5</span>,</span>
<span id="cb44-15"><a href="markov-chains.html#cb44-15" aria-hidden="true" tabindex="-1"></a>            <span class="at">loop.size=</span><span class="dv">2</span>,</span>
<span id="cb44-16"><a href="markov-chains.html#cb44-16" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>))</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="classification-of-states" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Classification of states<a href="markov-chains.html#classification-of-states" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>State <span class="math inline">\(j\)</span> is <em>accessible</em> from state <span class="math inline">\(i\)</span>, denoted <span class="math inline">\(i\to j\)</span> if there is a path from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> in the graph. This means that <span class="math inline">\((T^n)_{ij}&gt;0\)</span> for some <span class="math inline">\(n\geq0\)</span>. Note that <span class="math inline">\(i\to i\)</span> is always trivially true for any state <span class="math inline">\(i\)</span>.</p>
<p>States <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> <em>communicate</em> if they are both accessible from each other, i.e. that <span class="math inline">\(i\to j\)</span> and <span class="math inline">\(j\to i\)</span>. This is denoted <span class="math inline">\(i\leftrightarrow j\)</span>. Again, state <span class="math inline">\(i\)</span> always trivially communicates with itself, <span class="math inline">\(i\leftrightarrow i\)</span>.</p>
<p>Communication and accessibility are <em>transitive</em>, that is, <span class="math inline">\(i\to j\)</span> and <span class="math inline">\(j\to k\)</span> implies <span class="math inline">\(i\to k\)</span>, and if <span class="math inline">\(i\)</span> communicates with <span class="math inline">\(j\)</span> and <span class="math inline">\(j\)</span> communicates with <span class="math inline">\(k\)</span>, then <span class="math inline">\(i\)</span> communicates with <span class="math inline">\(k\)</span>.</p>
<p>Normally, we break the state space into <em>(communication) classes</em>. A class is a subset of the state space so that all states in the class communicate with each other, but do not communicate with any other states. A Markov chain is called <em>irreducible</em> if the entire state space is a class. It is called <em>reducible</em> if it’s state space is made of more than one class. As a trivial example, the identity matrix (ones on the diagonal) is a transition matrix with each state being in a class by itself. The chain just starts in some state and stays there forever!</p>
<div class="exbox">
<p><strong>Example.</strong>
For the transition matrix given above, we have: <span class="math inline">\(1\leftrightarrow2\leftrightarrow3\)</span> and we have a single class <span class="math inline">\(\{0,1,2\}\)</span>. This is an irreducible Markov chain since its state space is a class.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong>
Consider transition matrix with state space <span class="math inline">\(S=\{0,1,2,3,4\}\)</span> where positive entries are denoted by <span class="math inline">\(\star\)</span>’s:
<span class="math display">\[T=\begin{pmatrix}
\star&amp;0&amp;\star&amp;0&amp;0\\
0&amp;0&amp;\star&amp;0&amp;\star\\
\star&amp;0&amp;\star&amp;0&amp;0\\
0&amp;0&amp;0&amp;\star&amp;\star\\
0&amp;0&amp;0&amp;\star&amp;0\\
\end{pmatrix}.\]</span>
This has classes <span class="math inline">\(\{0,1,2\}\)</span> and <span class="math inline">\(\{3,4\}\)</span>. Note that the latter is accessible from the former, but not vice versa: <span class="math inline">\(\{0,1,2\}\to\{3,4\}\)</span>. This is an reducible Markov chain since its state space is not a single class. Eventually, the chain will get absorbed into class <span class="math inline">\(\{3,4\}\)</span> and stay there forever.</p>
</div>
</div>
<div id="distribution-at-time-n" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Distribution at time <span class="math inline">\(n\)</span><a href="markov-chains.html#distribution-at-time-n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(\mathbf p_n\)</span> be the <em>distribution of the process at time <span class="math inline">\(n\)</span></em>. We call <span class="math inline">\(\mathbf p_0\)</span> the <em>initial distribution</em> of the process. For a process on state space <span class="math inline">\(S=\{0,1,2,\ldots,m\}\)</span>, we have
<span class="math display">\[\mathbf p_n=\big(P(X_n=0),P(X_n=1),P(X_n=2),\ldots,P(X_n=m)\big)\]</span>
Note that this is actually conditional on knowing the initial distribution usually, i.e. when we write <span class="math inline">\(\mathbf p_n\)</span> and we ask about <span class="math inline">\(P(X_n=i)\)</span>, we normally mean <span class="math inline">\(P(X_n=i\mid X_0\sim \mathbf p_0)\)</span>. However, we could be conditioning on the state at any earlier time as well.</p>
<p>For example, with <span class="math inline">\(S=\{0,1,2,3\}\)</span>, a point mass on state <span class="math inline">\(2\)</span> initially is <span class="math inline">\(\mathbf p_0=(0,0,1,0)\)</span> which indicates that <span class="math inline">\(X_0=2\)</span> with certainty. If we wish to select the initial state randomly between states 1 and 2 with a fair coin flip, then <span class="math inline">\(\mathbf p_0=(0,0.5,0.5,0)\)</span>.</p>
<p>The future distribution of the process is given by matrix multiplication:
<span class="math display">\[\mathbf p_n = \mathbf p_{n-1} T.\]</span>
And from this, we can get the distribution at any future time:
<span class="math display">\[\mathbf p_{n} = \mathbf p_{0} T^n,\]</span>
<span class="math display">\[\mathbf p_{n+m} = \mathbf p_{n} T^m.\]</span>
We can think of the transition matrix raised to a power <span class="math inline">\(T^n\)</span> as the “<span class="math inline">\(n\)</span>-step transition matrix.” Be careful to note that this is matrix exponentiation using standard matrix multiplication.</p>
<div class="exbox">
<p>With <span class="math display">\[
T=\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix},
\]</span>
if we start the process with initial distribution <span class="math inline">\(\mathbf p_0=(0.7,0.1,0.2)\)</span> then the distribution at time one is
<span class="math display">\[\begin{aligned}
X_1\sim \mathbf p_1 &amp;=\mathbf p_0 T\\
&amp;=(0.7,0.1,0.2)\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}\\[4px]
&amp;=(0.45, 0.34, 0.21)
\end{aligned}
\]</span>
we can do this in R with the following code (assuming you already have <code>TM</code> enterd)</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="markov-chains.html#cb45-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>)</span>
<span id="cb45-2"><a href="markov-chains.html#cb45-2" aria-hidden="true" tabindex="-1"></a>x <span class="sc">%*%</span> TM</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,] 0.45 0.34 0.21</code></pre>
<p>Hence <span class="math inline">\(\mathbf p_1=(0.45, 0.34, 0.21)\)</span> as desired.</p>
<p>And the distribution of the process at time <span class="math inline">\(n=5\)</span> is
<span class="math display">\[\begin{aligned}
X_5\sim \mathbf p_5 &amp;=\mathbf p_0 T^5\\
&amp;=(0.7,0.1,0.2)\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}^5\\[4px]
&amp;\approx(0.31946, 0.364344, 0.316196)
\end{aligned}
\]</span>
And in R this is given below. Note that we need to use the <code>expm</code> matrix exponential library. Also note the parentheses around the transition matrix raised to a power <code>(TM %^% 5)</code>.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="markov-chains.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(expm)</span>
<span id="cb47-2"><a href="markov-chains.html#cb47-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>)</span>
<span id="cb47-3"><a href="markov-chains.html#cb47-3" aria-hidden="true" tabindex="-1"></a>x <span class="sc">%*%</span> (TM <span class="sc">%^%</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##         [,1]     [,2]     [,3]
## [1,] 0.31946 0.364344 0.316196</code></pre>
</div>
</div>
<div id="simulating-a-markov-chain-in-r" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> simulating a Markov chain in R<a href="markov-chains.html#simulating-a-markov-chain-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sampling from a discrete distribution can be accomplished as follows. Let <span class="math inline">\(\mathbb p=(p_0,p_1,p_2,\ldots,p_{m-1},p_m)\)</span> be a probability mass function on state space <span class="math inline">\(S=\{0,1,2,\ldots,m\}\)</span>. If we wish to sample formt he state space according to this distribution we can accomplish this in R using <code>sample(0:m,1,prob=c(p0,p1,\ldots,pm))</code>.</p>
<p>Suppose we have a Markov chain with state space <span class="math inline">\(\{0,1,2,3,4,5\}\)</span> and we wish to choose the initial state <span class="math inline">\(X_0\)</span> from initial distribution <span class="math inline">\(\mathbf p_0=(0.2,0,0.1,0.4,0.2,0.1)\)</span>. We can accopmlish this with the following code.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="markov-chains.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>,<span class="dv">1</span>,<span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.2</span>,<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.4</span>,<span class="fl">0.2</span>,<span class="fl">0.1</span>))</span></code></pre></div>
<p>Now, once we know the precise current state of the process, we select the state at the next timestep by randomly sampling from the state space according to the appropriate row of the transition matrix. If <span class="math inline">\(X_{n-1}=i\)</span>, we sample <span class="math inline">\(X_n\)</span> using the <span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(T\)</span>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="markov-chains.html#cb50-1" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.7</span>,<span class="fl">0.1</span>))</span>
<span id="cb50-2"><a href="markov-chains.html#cb50-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="at">prob=</span>TM[x0<span class="sc">+</span><span class="dv">1</span>,])</span></code></pre></div>
<p>Note, that since we index our sample space starting from zero, we must add one to the state to get R’s index number, i.e. state <span class="math inline">\(i\)</span> corresponds to row <span class="math inline">\(i+1\)</span> by R’s indexing scheme.</p>
<p>Now we just repeat this procedure for any number of timesteps. Here is a full R code that sets the transition matrix, samples the initial state randomly and simulates the chain for some number of timesteps and plots the resulting sample path.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="markov-chains.html#cb51-1" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,</span>
<span id="cb51-2"><a href="markov-chains.html#cb51-2" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.0</span>,<span class="fl">0.3</span>,<span class="fl">0.7</span>,</span>
<span id="cb51-3"><a href="markov-chains.html#cb51-3" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb51-4"><a href="markov-chains.html#cb51-4" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">nrow</span>(TM)<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb51-5"><a href="markov-chains.html#cb51-5" aria-hidden="true" tabindex="-1"></a>nsteps <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb51-6"><a href="markov-chains.html#cb51-6" aria-hidden="true" tabindex="-1"></a>initdistr <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.5</span>,<span class="fl">0.3</span>)</span>
<span id="cb51-7"><a href="markov-chains.html#cb51-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="at">length=</span>nsteps<span class="sc">+</span><span class="dv">1</span>)</span>
<span id="cb51-8"><a href="markov-chains.html#cb51-8" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sample</span>(S,<span class="dv">1</span>,<span class="at">prob=</span>initdistr)</span>
<span id="cb51-9"><a href="markov-chains.html#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsteps){</span>
<span id="cb51-10"><a href="markov-chains.html#cb51-10" aria-hidden="true" tabindex="-1"></a>  x[n<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sample</span>(S,<span class="dv">1</span>,<span class="at">prob=</span>TM[x[n]<span class="sc">+</span><span class="dv">1</span>,])</span>
<span id="cb51-11"><a href="markov-chains.html#cb51-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-12"><a href="markov-chains.html#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>nsteps,x,<span class="at">type=</span><span class="st">&quot;b&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">pch=</span><span class="dv">20</span>,<span class="at">col=</span><span class="fu">rgb</span>(<span class="fl">0.7</span>,<span class="fl">0.2</span>,<span class="fl">0.5</span>),<span class="at">xlab=</span><span class="st">&quot;time&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;state&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div>
<div id="return-times-and-hitting-probabilities" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Return times and hitting probabilities<a href="markov-chains.html#return-times-and-hitting-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(f_i\)</span> be the probability that, when starting in state <span class="math inline">\(i\)</span>, the chain ever returns to state <span class="math inline">\(i\)</span> at some point in the future.
<span class="math display">\[
\begin{aligned}
f_i&amp;=\mathsf{P}(X_n=i \text{ for some } n\in\mathbb N\mid X_0=i)\\
&amp;=\mathsf{P}(X_1=i \text{ or } X_2=i \text{ or } \cdots\mid X_0=i)\\
&amp;=\mathsf{P}\left(\cup_{n=1}^\infty \{X_n=i\} \mid X_0=i\right)
\end{aligned}
\]</span>
Then <span class="math inline">\(1-f_i\)</span> is the probability that the chain immediately leaves state <span class="math inline">\(i\)</span> and never returns. It is possible that <span class="math inline">\(f_i=1\)</span> or <span class="math inline">\(f_i=0\)</span> also. Consider the trivial chain with a single state <span class="math inline">\(S=\{0\}\)</span> that just stays there forever which implies <span class="math inline">\(f_0=1\)</span>. Consider the chain where state <span class="math inline">\(5\)</span> immediately jumps to state <span class="math inline">\(3\)</span> (with probability 1) but <span class="math inline">\(3\not\to5\)</span> (state 5 is not accessible from state 3), then <span class="math inline">\(f_5=0\)</span>.</p>
<p>Let <span class="math inline">\(N_i\)</span> be the total number of visits to state <span class="math inline">\(i\)</span> (including the initial visit since the chain starts in state <span class="math inline">\(i\)</span>). Then
<span class="math display">\[N_i\sim\mathsf{Geom}(p=1-f_i)\]</span>
with <span class="math inline">\(E(N_i)=\frac{1}{1-f_i}\)</span>.</p>
<p>If <span class="math inline">\(f_i=1\)</span>, then <span class="math inline">\(P(N_i=\infty)=1\)</span> and <span class="math inline">\(E(N_i)=\infty\)</span>. This means that with probability one, state <span class="math inline">\(i\)</span> will be visited infinitely-many times (when the chain starts in state <span class="math inline">\(i\)</span>). In this case, <span class="math inline">\(N_i\)</span> isn’t exactly “geometrically-distributed,” but we can still think of it as a geometric random variable with zero probaiblity of success.</p>
</div>
<div id="summary-5" class="section level2 unnumbered hasAnchor">
<h2>Summary<a href="markov-chains.html#summary-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="defbox">
<p><strong>Summary of notation, formulas, and terminology</strong></p>
<p>Transition matrix: <span class="math inline">\(T_{ij}=P(X_n=j \mid X_{n-1}=i)\)</span></p>
<p>Markov property (memorylessness):
<span class="math display">\[P(X_n=j \mid X_{n-1}=i,X_{n-2}=\ell_{n-2},\ldots,X_{1}=\ell_{1},X_{0}=\ell_{0})=P(X_n=j \mid X_{n-1}=i)=T_{ij}\]</span>
Matrix multiplication: <span class="math inline">\(\mathbf p_n =\mathbf p_{n-1} T\)</span></p>
<p><span class="math inline">\(N_i\sim\mathsf{Geom}(p=1-f_i)\)</span>, <span class="math inline">\(E(N_i)=\frac{1}{1-f_i}\)</span></p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="limit-theorems.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jstover79/stochproc423/edit/master/08-markov-proc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/jstover79/stochproc423/blob/master/08-markov-proc.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
