<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes</title>
  <meta name="description" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Markov Chains | Math 423 Stochastic Processes Course Notes" />
  
  
  

<meta name="author" content="Joseph Stover" />


<meta name="date" content="2023-04-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="limit-theorems.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script type="text/javascript">
  function unhide(divID) {
    var item = document.getElementById(divID);
    if (item) {
      item.className=(item.className=='hiddendiv')?'unhiddendiv':'hiddendiv';
    }
  }
</script> 


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stochastic Processes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> Introduction to R and RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#getting-access-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> Getting access to R and RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#r-basics"><i class="fa fa-check"></i><b>1.2</b> R basics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#data-structures-vectors-matrices"><i class="fa fa-check"></i><b>1.2.1</b> Data structures, vectors, matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#installing-and-using-packages-in-r"><i class="fa fa-check"></i><b>1.3</b> Installing and using packages in R</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#random-variables"><i class="fa fa-check"></i><b>1.4</b> Random variables</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#basics-of-programming-r-scripts"><i class="fa fa-check"></i><b>1.5</b> Basics of programming, R scripts</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#importing-datasets-into-r"><i class="fa fa-check"></i><b>1.6</b> Importing datasets into R</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html"><i class="fa fa-check"></i><b>2</b> Counting, sets, and probability basics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#ticket-in-a-box-model-of-probability"><i class="fa fa-check"></i><b>2.1</b> Ticket-in-a-box model of probability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sampling-from-a-box-of-tickets"><i class="fa fa-check"></i><b>2.1.1</b> Sampling from a box of tickets</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#relative-area-model-of-probability"><i class="fa fa-check"></i><b>2.2</b> Relative area model of probability</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#one-dimension"><i class="fa fa-check"></i><b>2.2.1</b> One dimension</a></li>
<li class="chapter" data-level="2.2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#two-or-more-dimensions"><i class="fa fa-check"></i><b>2.2.2</b> Two or more dimensions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.3</b> Sample Spaces and Events</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-space"><i class="fa fa-check"></i><b>2.3.1</b> Sample space</a></li>
<li class="chapter" data-level="2.3.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#events"><i class="fa fa-check"></i><b>2.3.2</b> Events</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#set-operations"><i class="fa fa-check"></i><b>2.4</b> Set Operations</a></li>
<li class="chapter" data-level="2.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#venn-diagrams"><i class="fa fa-check"></i><b>2.5</b> Venn Diagrams</a></li>
<li class="chapter" data-level="2.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#counting-permutations-and-combinations"><i class="fa fa-check"></i><b>2.6</b> Counting, permutations, and combinations</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#multiplication-rule"><i class="fa fa-check"></i><b>2.6.1</b> Multiplication rule</a></li>
<li class="chapter" data-level="2.6.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#nk"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(n^k\)</span></a></li>
<li class="chapter" data-level="2.6.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#factorials"><i class="fa fa-check"></i><b>2.6.3</b> Factorials</a></li>
<li class="chapter" data-level="2.6.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#permutation"><i class="fa fa-check"></i><b>2.6.4</b> Permutation</a></li>
<li class="chapter" data-level="2.6.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#combination"><i class="fa fa-check"></i><b>2.6.5</b> Combination</a></li>
<li class="chapter" data-level="2.6.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#summary-of-counting"><i class="fa fa-check"></i><b>2.6.6</b> Summary of counting</a></li>
<li class="chapter" data-level="2.6.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#special-case-with-replacement-order-doesnt-matter-the-multiset"><i class="fa fa-check"></i><b>2.6.7</b> Special case: with replacement, order doesn’t matter: the multiset</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#probability"><i class="fa fa-check"></i><b>2.7</b> Probability</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#equally-likely-outcomes"><i class="fa fa-check"></i><b>2.7.1</b> Equally likely outcomes</a></li>
<li class="chapter" data-level="2.7.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#general-probability-theory"><i class="fa fa-check"></i><b>2.7.2</b> General probability theory</a></li>
<li class="chapter" data-level="2.7.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#independence"><i class="fa fa-check"></i><b>2.7.3</b> Independence</a></li>
<li class="chapter" data-level="2.7.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#conditional-probability"><i class="fa fa-check"></i><b>2.7.4</b> Conditional probability</a></li>
<li class="chapter" data-level="2.7.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#partitions"><i class="fa fa-check"></i><b>2.7.5</b> Partitions</a></li>
<li class="chapter" data-level="2.7.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#bayes-theorem"><i class="fa fa-check"></i><b>2.7.6</b> Baye’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html"><i class="fa fa-check"></i><b>3</b> Random variables and distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#expectation-and-variance"><i class="fa fa-check"></i><b>3.1</b> Expectation and variance</a></li>
<li class="chapter" data-level="3.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#joint-distributions"><i class="fa fa-check"></i><b>3.2</b> Joint distributions</a></li>
<li class="chapter" data-level="3.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#independence-of-random-variables"><i class="fa fa-check"></i><b>3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="3.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#discrete-bernoulli-binomial-geometric-poisson"><i class="fa fa-check"></i><b>3.4</b> Discrete: Bernoulli, binomial, geometric, Poisson</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#bernoulli"><i class="fa fa-check"></i><b>3.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="3.4.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#binomial"><i class="fa fa-check"></i><b>3.4.2</b> Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#geometric"><i class="fa fa-check"></i><b>3.4.3</b> Geometric</a></li>
<li class="chapter" data-level="3.4.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#poisson"><i class="fa fa-check"></i><b>3.4.4</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#continuous-uniform-exponential-normal"><i class="fa fa-check"></i><b>3.5</b> Continuous: Uniform, exponential, normal</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#uniform"><i class="fa fa-check"></i><b>3.5.1</b> Uniform</a></li>
<li class="chapter" data-level="3.5.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#exponential"><i class="fa fa-check"></i><b>3.5.2</b> Exponential</a></li>
<li class="chapter" data-level="3.5.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#normal"><i class="fa fa-check"></i><b>3.5.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-expectation.html"><a href="conditional-expectation.html"><i class="fa fa-check"></i><b>4</b> Conditional expectation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-distributions"><i class="fa fa-check"></i><b>4.1</b> Conditional distributions</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-expectation-1"><i class="fa fa-check"></i><b>4.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-expectation.html"><a href="conditional-expectation.html#random-conditional-expectation"><i class="fa fa-check"></i><b>4.3</b> (Random) conditional expectation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#total-expectation"><i class="fa fa-check"></i><b>4.3.1</b> Total expectation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conditional-expectation.html"><a href="conditional-expectation.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html"><i class="fa fa-check"></i><b>5</b> Intro Stochastic Processes</a>
<ul>
<li class="chapter" data-level="" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-walks.html"><a href="random-walks.html"><i class="fa fa-check"></i><b>6</b> Random walks</a>
<ul>
<li class="chapter" data-level="6.1" data-path="random-walks.html"><a href="random-walks.html#the-simple-symmetric-random-walk-ssrw"><i class="fa fa-check"></i><b>6.1</b> The simple symmetric random walk (SSRW)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="random-walks.html"><a href="random-walks.html#definition-of-a-random-walk"><i class="fa fa-check"></i><b>6.1.1</b> Definition of a random walk</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="random-walks.html"><a href="random-walks.html#distribution-of-x_n"><i class="fa fa-check"></i><b>6.2</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="random-walks.html"><a href="random-walks.html#shift-invariance-memorylessness"><i class="fa fa-check"></i><b>6.3</b> Shift invariance &amp; memorylessness</a></li>
<li class="chapter" data-level="6.4" data-path="random-walks.html"><a href="random-walks.html#reflection-principle"><i class="fa fa-check"></i><b>6.4</b> Reflection principle</a></li>
<li class="chapter" data-level="6.5" data-path="random-walks.html"><a href="random-walks.html#maximum-state-reached"><i class="fa fa-check"></i><b>6.5</b> Maximum state reached</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="random-walks.html"><a href="random-walks.html#maximum-over-infinite-sample-paths-for-p12"><i class="fa fa-check"></i><b>6.5.1</b> Maximum over infinite sample paths for <span class="math inline">\(p&lt;1/2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="random-walks.html"><a href="random-walks.html#hitting-times"><i class="fa fa-check"></i><b>6.6</b> Hitting times</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-state-1"><i class="fa fa-check"></i><b>6.6.1</b> Hitting time for state <span class="math inline">\(1\)</span></a></li>
<li class="chapter" data-level="6.6.2" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-other-states"><i class="fa fa-check"></i><b>6.6.2</b> Hitting time for other states</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="random-walks.html"><a href="random-walks.html#return-time-to-state-0"><i class="fa fa-check"></i><b>6.7</b> Return time to state <span class="math inline">\(0\)</span></a></li>
<li class="chapter" data-level="" data-path="random-walks.html"><a href="random-walks.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>7</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="7.1" data-path="limit-theorems.html"><a href="limit-theorems.html#inequalities"><i class="fa fa-check"></i><b>7.1</b> Inequalities</a></li>
<li class="chapter" data-level="7.2" data-path="limit-theorems.html"><a href="limit-theorems.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2</b> Law of large numbers</a></li>
<li class="chapter" data-level="7.3" data-path="limit-theorems.html"><a href="limit-theorems.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Central limit theorem</a></li>
<li class="chapter" data-level="7.4" data-path="limit-theorems.html"><a href="limit-theorems.html#borel-cantelli"><i class="fa fa-check"></i><b>7.4</b> Borel-Cantelli</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>8</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="8.1" data-path="markov-chains.html"><a href="markov-chains.html#graph-of-a-markov-chain"><i class="fa fa-check"></i><b>8.1</b> Graph of a Markov chain</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chains.html"><a href="markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>8.2</b> Classification of states</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chains.html"><a href="markov-chains.html#distribution-at-time-n"><i class="fa fa-check"></i><b>8.3</b> Distribution at time <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="markov-chains.html"><a href="markov-chains.html#simulating-a-markov-chain-in-r"><i class="fa fa-check"></i><b>8.4</b> Simulating a Markov chain in R</a></li>
<li class="chapter" data-level="8.5" data-path="markov-chains.html"><a href="markov-chains.html#return-times-and-hitting-probabilities"><i class="fa fa-check"></i><b>8.5</b> Return times and hitting probabilities</a></li>
<li class="chapter" data-level="8.6" data-path="markov-chains.html"><a href="markov-chains.html#limiting-probabilities"><i class="fa fa-check"></i><b>8.6</b> Limiting probabilities</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="markov-chains.html"><a href="markov-chains.html#limiting-distributions"><i class="fa fa-check"></i><b>8.6.1</b> Limiting distributions</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="markov-chains.html"><a href="markov-chains.html#stationary-distributions"><i class="fa fa-check"></i><b>8.7</b> Stationary distributions</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="markov-chains.html"><a href="markov-chains.html#stationary-distributions-for-reducible-chains"><i class="fa fa-check"></i><b>8.7.1</b> Stationary distributions for reducible chains</a></li>
<li class="chapter" data-level="8.7.2" data-path="markov-chains.html"><a href="markov-chains.html#r-code-for-finding-stationary-distributions"><i class="fa fa-check"></i><b>8.7.2</b> R code for finding stationary distributions</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="markov-chains.html"><a href="markov-chains.html#probability-of-absorption-time-to-absorption"><i class="fa fa-check"></i><b>8.8</b> Probability of absorption &amp; time to absorption</a></li>
<li class="chapter" data-level="8.9" data-path="markov-chains.html"><a href="markov-chains.html#gamblers-ruin"><i class="fa fa-check"></i><b>8.9</b> Gambler’s ruin</a></li>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math 423 Stochastic Processes Course Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="markov-chains" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Markov Chains<a href="markov-chains.html#markov-chains" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Markov chains are one of the most important classes of stochastic process. A <strong>discrete-time Markov chain</strong> (DTMC) consists of specifying a state space and a transition matrix. For us, our state space will generally be <span class="math inline">\(S=\{0,1,\ldots,k\}\)</span> and our time index set will be <span class="math inline">\(\mathbb N_0\)</span>. The <strong>transition matrix</strong> gives us the transition probabilities between each pair of states and is given as
<span class="math display">\[T=
\left(\begin{matrix}
T_{00} &amp; T_{01} &amp; \cdots &amp; T_{0k}\\
T_{10} &amp; T_{11} &amp; \cdots &amp; T_{1k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
T_{k0} &amp; T_{k1} &amp; \cdots &amp; T_{kk}\\
\end{matrix}\right)\]</span>
where
<span class="math display">\[T_{ij}=P(X_n=j\mid X_{n-1}=i).\]</span></p>
<p>We assume this stochastic process satisfied the <em>Markov property</em> or <em>memorylessness</em>, which means that the probabilities for the next time step only depends on the current state and no other previous history:
<span class="math display">\[P(X_n=j \mid X_{n-1}=i,X_{n-2}=\ell_{n-2},\ldots,X_{1}=\ell_{1},X_{0}=\ell_{0})=P(X_n=j \mid X_{n-1}=i)=T_{ij}.\]</span></p>
<div id="graph-of-a-markov-chain" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Graph of a Markov chain<a href="markov-chains.html#graph-of-a-markov-chain" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For a Markov chain with state space <span class="math inline">\(S\)</span>, we can represent the possible transitions graphically in Euclidean space. For now, let’s assume the state space is finite, but even chains with infinite state spaces can have graphs constructed in this way. Plot a point for each state in the plane <span class="math inline">\(\mathbb R^2\)</span>, and label each point by the state it corresponds to. Draw a directed edge (an arrow) from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> whenever <span class="math inline">\(T_{ij}&gt;0\)</span>.</p>
<p>We can use <code>install.packages("igraph")</code> if we wish to plot transition graphs for Markov chains.</p>
<p>Consider the transition matrix
<span class="math display">\[
T=\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}.
\]</span>
Here is some R code for plotting the transition diagram along with the plot.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="markov-chains.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(igraph)</span>
<span id="cb44-2"><a href="markov-chains.html#cb44-2" aria-hidden="true" tabindex="-1"></a>tmvec <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,</span>
<span id="cb44-3"><a href="markov-chains.html#cb44-3" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.0</span>,<span class="fl">0.3</span>,<span class="fl">0.7</span>,</span>
<span id="cb44-4"><a href="markov-chains.html#cb44-4" aria-hidden="true" tabindex="-1"></a>           <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.0</span>)</span>
<span id="cb44-5"><a href="markov-chains.html#cb44-5" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(tmvec,<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb44-6"><a href="markov-chains.html#cb44-6" aria-hidden="true" tabindex="-1"></a>mcg <span class="ot">&lt;-</span> <span class="fu">graph_from_adjacency_matrix</span>(<span class="dv">1</span><span class="sc">*</span>(TM<span class="sc">&gt;</span><span class="dv">0</span>))</span>
<span id="cb44-7"><a href="markov-chains.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot.igraph</span>(mcg,</span>
<span id="cb44-8"><a href="markov-chains.html#cb44-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">vertex.size=</span><span class="dv">50</span>,</span>
<span id="cb44-9"><a href="markov-chains.html#cb44-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">vertex.color=</span><span class="st">&quot;grey90&quot;</span>,</span>
<span id="cb44-10"><a href="markov-chains.html#cb44-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.curved=</span><span class="fl">0.25</span>,</span>
<span id="cb44-11"><a href="markov-chains.html#cb44-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.color=</span><span class="st">&quot;black&quot;</span>,</span>
<span id="cb44-12"><a href="markov-chains.html#cb44-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.label=</span>tmvec[tmvec<span class="sc">&gt;</span><span class="dv">0</span>],</span>
<span id="cb44-13"><a href="markov-chains.html#cb44-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">edge.loop.angle=</span><span class="fu">c</span>(pi,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">4</span><span class="sc">*</span>pi<span class="sc">/</span><span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>),</span>
<span id="cb44-14"><a href="markov-chains.html#cb44-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">margin=</span><span class="fl">0.5</span>,</span>
<span id="cb44-15"><a href="markov-chains.html#cb44-15" aria-hidden="true" tabindex="-1"></a>            <span class="at">loop.size=</span><span class="dv">2</span>,</span>
<span id="cb44-16"><a href="markov-chains.html#cb44-16" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>))</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="classification-of-states" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Classification of states<a href="markov-chains.html#classification-of-states" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>State <span class="math inline">\(j\)</span> is <em>accessible</em> from state <span class="math inline">\(i\)</span>, denoted <span class="math inline">\(i\to j\)</span> if there is a path from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span> in the graph. This means that <span class="math inline">\((T^n)_{ij}&gt;0\)</span> for some <span class="math inline">\(n\geq0\)</span>. Note that <span class="math inline">\(i\to i\)</span> is always trivially true for any state <span class="math inline">\(i\)</span>.</p>
<p>States <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> <em>communicate</em> if they are both accessible from each other, i.e. that <span class="math inline">\(i\to j\)</span> and <span class="math inline">\(j\to i\)</span>. This is denoted <span class="math inline">\(i\leftrightarrow j\)</span>. Again, state <span class="math inline">\(i\)</span> always trivially communicates with itself, <span class="math inline">\(i\leftrightarrow i\)</span>.</p>
<p>Communication and accessibility are <em>transitive</em>, that is, <span class="math inline">\(i\to j\)</span> and <span class="math inline">\(j\to k\)</span> implies <span class="math inline">\(i\to k\)</span>, and if <span class="math inline">\(i\)</span> communicates with <span class="math inline">\(j\)</span> and <span class="math inline">\(j\)</span> communicates with <span class="math inline">\(k\)</span>, then <span class="math inline">\(i\)</span> communicates with <span class="math inline">\(k\)</span>.</p>
<p>Normally, we break the state space into <em>(communication) classes</em>. A class is a subset of the state space so that all states in the class communicate with each other, but do not communicate with any other states. A Markov chain is called <em>irreducible</em> if the entire state space is a class. It is called <em>reducible</em> if it’s state space is made of more than one class. As a trivial example, the identity matrix (ones on the diagonal) is a transition matrix with each state being in a class by itself. The chain just starts in some state and stays there forever!</p>
<p>A state is called <em>transient</em> if, when starting in that state, there is a positive probability of leaving and never returning. A state is called <em>recurrent</em> if, when starting in that state, with probability one, the chain will always hit that state again at some finite future time. Given that the chain starts in state <span class="math inline">\(i\)</span>, let <span class="math inline">\(f_i\)</span> be the probability that it is again in state <span class="math inline">\(i\)</span> at any future time <span class="math inline">\(n\geq1\)</span>.</p>
<div class="defbox">
<p><strong>Definition.</strong>
State <span class="math inline">\(i\)</span> is called <em>recurrent</em> if , when starting in state <span class="math inline">\(i\)</span>, the probability that it is visited again in the future is one. That is
<span class="math display">\[f_i=\mathsf P(\cup_{n=1}^\infty \{X_n=i\}\mid X_0=i)=1.\]</span></p>
<p>State <span class="math inline">\(i\)</span> is called <em>transient</em> if , when starting in state <span class="math inline">\(i\)</span>, the probability that it is visited again in the future is less than one. That is
<span class="math display">\[f_i=\mathsf P(\cup_{n=1}^\infty \{X_n=i\}\mid X_0=i)&lt;1.\]</span></p>
</div>
<div class="exbox">
<p><strong>Example.</strong>
For the transition matrix given above, we have: <span class="math inline">\(1\leftrightarrow2\leftrightarrow3\)</span> and we have a single class <span class="math inline">\(\{0,1,2\}\)</span>. This is an irreducible Markov chain since its state space is a class.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong>
Consider transition matrix with state space <span class="math inline">\(S=\{0,1,2,3,4\}\)</span> where positive entries are denoted by <span class="math inline">\(\star\)</span>’s:
<span class="math display">\[T=\begin{pmatrix}
\star&amp;0&amp;\star&amp;0&amp;0\\
0&amp;0&amp;\star&amp;0&amp;\star\\
\star&amp;0&amp;\star&amp;0&amp;0\\
0&amp;0&amp;0&amp;\star&amp;\star\\
0&amp;0&amp;0&amp;\star&amp;0\\
\end{pmatrix}.\]</span>
This has classes <span class="math inline">\(\{0,1,2\}\)</span> and <span class="math inline">\(\{3,4\}\)</span>. Note that the latter is accessible from the former, but not vice versa: <span class="math inline">\(\{0,1,2\}\to\{3,4\}\)</span>. This is an reducible Markov chain since its state space is not a single class. Eventually, the chain will get absorbed into class <span class="math inline">\(\{3,4\}\)</span> and stay there forever.</p>
</div>
</div>
<div id="distribution-at-time-n" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Distribution at time <span class="math inline">\(n\)</span><a href="markov-chains.html#distribution-at-time-n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(\mathbf p_n\)</span> be the <em>distribution of the process at time <span class="math inline">\(n\)</span></em>. We call <span class="math inline">\(\mathbf p_0\)</span> the <em>initial distribution</em> of the process. For a process on state space <span class="math inline">\(S=\{0,1,2,\ldots,m\}\)</span>, we have
<span class="math display">\[\mathbf p_n=\big(P(X_n=0),P(X_n=1),P(X_n=2),\ldots,P(X_n=m)\big)\]</span>
Note that this is actually conditional on knowing the initial distribution usually, i.e. when we write <span class="math inline">\(\mathbf p_n\)</span> and we ask about <span class="math inline">\(P(X_n=i)\)</span>, we normally mean <span class="math inline">\(P(X_n=i\mid X_0\sim \mathbf p_0)\)</span>. However, we could be conditioning on the state at any earlier time as well.</p>
<p>For example, with <span class="math inline">\(S=\{0,1,2,3\}\)</span>, a point mass on state <span class="math inline">\(2\)</span> initially is <span class="math inline">\(\mathbf p_0=(0,0,1,0)\)</span> which indicates that <span class="math inline">\(X_0=2\)</span> with certainty. If we wish to select the initial state randomly between states 1 and 2 with a fair coin flip, then <span class="math inline">\(\mathbf p_0=(0,0.5,0.5,0)\)</span>.</p>
<p>The future distribution of the process is given by matrix multiplication:
<span class="math display">\[\mathbf p_n = \mathbf p_{n-1} T.\]</span>
And from this, we can get the distribution at any future time:
<span class="math display">\[\mathbf p_{n} = \mathbf p_{0} T^n,\]</span>
<span class="math display">\[\mathbf p_{n+m} = \mathbf p_{n} T^m.\]</span>
We can think of the transition matrix raised to a power <span class="math inline">\(T^n\)</span> as the “<span class="math inline">\(n\)</span>-step transition matrix.” Be careful to note that this is matrix exponentiation using standard matrix multiplication.</p>
<div class="exbox">
<p>With <span class="math display">\[
T=\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix},
\]</span>
if we start the process with initial distribution <span class="math inline">\(\mathbf p_0=(0.7,0.1,0.2)\)</span> then the distribution at time one is
<span class="math display">\[\begin{aligned}
X_1\sim \mathbf p_1 &amp;=\mathbf p_0 T\\
&amp;=(0.7,0.1,0.2)\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}\\[4px]
&amp;=(0.45, 0.34, 0.21)
\end{aligned}
\]</span>
we can do this in R with the following code (assuming you already have <code>TM</code> enterd)</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="markov-chains.html#cb45-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>)</span>
<span id="cb45-2"><a href="markov-chains.html#cb45-2" aria-hidden="true" tabindex="-1"></a>x <span class="sc">%*%</span> TM</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,] 0.45 0.34 0.21</code></pre>
<p>Hence <span class="math inline">\(\mathbf p_1=(0.45, 0.34, 0.21)\)</span> as desired.</p>
<p>And the distribution of the process at time <span class="math inline">\(n=5\)</span> is
<span class="math display">\[\begin{aligned}
X_5\sim \mathbf p_5 &amp;=\mathbf p_0 T^5\\
&amp;=(0.7,0.1,0.2)\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0.5 &amp; 0.5 &amp; 0
\end{pmatrix}^5\\[4px]
&amp;\approx(0.31946, 0.364344, 0.316196)
\end{aligned}
\]</span>
And in R this is given below. Note that we need to use the <code>expm</code> matrix exponential library. Also note the parentheses around the transition matrix raised to a power <code>(TM %^% 5)</code>.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="markov-chains.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(expm)</span>
<span id="cb47-2"><a href="markov-chains.html#cb47-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>,<span class="fl">0.1</span>,<span class="fl">0.2</span>)</span>
<span id="cb47-3"><a href="markov-chains.html#cb47-3" aria-hidden="true" tabindex="-1"></a>x <span class="sc">%*%</span> (TM <span class="sc">%^%</span> <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##         [,1]     [,2]     [,3]
## [1,] 0.31946 0.364344 0.316196</code></pre>
</div>
</div>
<div id="simulating-a-markov-chain-in-r" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Simulating a Markov chain in R<a href="markov-chains.html#simulating-a-markov-chain-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sampling from a discrete distribution can be accomplished as follows. Let <span class="math inline">\(\mathbb p=(p_0,p_1,p_2,\ldots,p_{m-1},p_m)\)</span> be a probability mass function on state space <span class="math inline">\(S=\{0,1,2,\ldots,m\}\)</span>. If we wish to sample formt he state space according to this distribution we can accomplish this in R using <code>sample(0:m,1,prob=c(p0,p1,\ldots,pm))</code>.</p>
<p>Suppose we have a Markov chain with state space <span class="math inline">\(\{0,1,2,3,4,5\}\)</span> and we wish to choose the initial state <span class="math inline">\(X_0\)</span> from initial distribution <span class="math inline">\(\mathbf p_0=(0.2,0,0.1,0.4,0.2,0.1)\)</span>. We can accopmlish this with the following code.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="markov-chains.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">5</span>,<span class="dv">1</span>,<span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.2</span>,<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.4</span>,<span class="fl">0.2</span>,<span class="fl">0.1</span>))</span></code></pre></div>
<p>Now, once we know the precise current state of the process, we select the state at the next timestep by randomly sampling from the state space according to the appropriate row of the transition matrix. If <span class="math inline">\(X_{n-1}=i\)</span>, we sample <span class="math inline">\(X_n\)</span> using the <span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(T\)</span>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="markov-chains.html#cb50-1" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="at">prob=</span><span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.7</span>,<span class="fl">0.1</span>))</span>
<span id="cb50-2"><a href="markov-chains.html#cb50-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="at">prob=</span>TM[x0<span class="sc">+</span><span class="dv">1</span>,])</span></code></pre></div>
<p>Note, that since we index our sample space starting from zero, we must add one to the state to get R’s index number, i.e. state <span class="math inline">\(i\)</span> corresponds to row <span class="math inline">\(i+1\)</span> by R’s indexing scheme.</p>
<p>Now we just repeat this procedure for any number of timesteps. Here is a full R code that sets the transition matrix, samples the initial state randomly and simulates the chain for some number of timesteps and plots the resulting sample path.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="markov-chains.html#cb51-1" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,</span>
<span id="cb51-2"><a href="markov-chains.html#cb51-2" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.0</span>,<span class="fl">0.3</span>,<span class="fl">0.7</span>,</span>
<span id="cb51-3"><a href="markov-chains.html#cb51-3" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb51-4"><a href="markov-chains.html#cb51-4" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span>(<span class="fu">nrow</span>(TM)<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb51-5"><a href="markov-chains.html#cb51-5" aria-hidden="true" tabindex="-1"></a>nsteps <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb51-6"><a href="markov-chains.html#cb51-6" aria-hidden="true" tabindex="-1"></a>initdistr <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>,<span class="fl">0.5</span>,<span class="fl">0.3</span>)</span>
<span id="cb51-7"><a href="markov-chains.html#cb51-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="at">length=</span>nsteps<span class="sc">+</span><span class="dv">1</span>)</span>
<span id="cb51-8"><a href="markov-chains.html#cb51-8" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sample</span>(S,<span class="dv">1</span>,<span class="at">prob=</span>initdistr)</span>
<span id="cb51-9"><a href="markov-chains.html#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsteps){</span>
<span id="cb51-10"><a href="markov-chains.html#cb51-10" aria-hidden="true" tabindex="-1"></a>  x[n<span class="sc">+</span><span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">sample</span>(S,<span class="dv">1</span>,<span class="at">prob=</span>TM[x[n]<span class="sc">+</span><span class="dv">1</span>,])</span>
<span id="cb51-11"><a href="markov-chains.html#cb51-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-12"><a href="markov-chains.html#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span>nsteps,x,<span class="at">type=</span><span class="st">&quot;b&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>,<span class="at">pch=</span><span class="dv">20</span>,<span class="at">col=</span><span class="fu">rgb</span>(<span class="fl">0.7</span>,<span class="fl">0.2</span>,<span class="fl">0.5</span>),<span class="at">xlab=</span><span class="st">&quot;time&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;state&quot;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div>
<div id="return-times-and-hitting-probabilities" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Return times and hitting probabilities<a href="markov-chains.html#return-times-and-hitting-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(f_i\)</span> be the probability that, when starting in state <span class="math inline">\(i\)</span>, the chain ever returns to state <span class="math inline">\(i\)</span> at some point in the future.
<span class="math display">\[
\begin{aligned}
f_i&amp;=\mathsf{P}(X_n=i \text{ for some } n\in\mathbb N\mid X_0=i)\\
&amp;=\mathsf{P}(X_1=i \text{ or } X_2=i \text{ or } \cdots\mid X_0=i)\\
&amp;=\mathsf{P}\left(\cup_{n=1}^\infty \{X_n=i\} \mid X_0=i\right)
\end{aligned}
\]</span>
Then <span class="math inline">\(1-f_i\)</span> is the probability that the chain immediately leaves state <span class="math inline">\(i\)</span> and never returns. It is possible that <span class="math inline">\(f_i=1\)</span> or <span class="math inline">\(f_i=0\)</span> also. Consider the trivial chain with a single state <span class="math inline">\(S=\{0\}\)</span> that just stays there forever which implies <span class="math inline">\(f_0=1\)</span>. Consider the chain where state <span class="math inline">\(5\)</span> immediately jumps to state <span class="math inline">\(3\)</span> (with probability 1) but <span class="math inline">\(3\not\to5\)</span> (state 5 is not accessible from state 3), then <span class="math inline">\(f_5=0\)</span>.</p>
<p>Let <span class="math inline">\(N_i\)</span> be the total number of visits to state <span class="math inline">\(i\)</span> (including the initial visit since the chain starts in state <span class="math inline">\(i\)</span>). Then
<span class="math display">\[N_i\sim\mathsf{Geom}(p=1-f_i)\]</span>
with <span class="math inline">\(E(N_i)=\frac{1}{1-f_i}\)</span>.</p>
<p>If <span class="math inline">\(f_i=1\)</span>, then <span class="math inline">\(P(N_i=\infty)=1\)</span> and <span class="math inline">\(E(N_i)=\infty\)</span>. This means that with probability one, state <span class="math inline">\(i\)</span> will be visited infinitely-many times (when the chain starts in state <span class="math inline">\(i\)</span>). In this case, <span class="math inline">\(N_i\)</span> isn’t exactly “geometrically-distributed,” but we can still think of it as a geometric random variable with zero probability of success.</p>
<p>Now we can say a bit more about recurrence and transience.</p>
<div class="thmbox">
<p><strong>Theorem.</strong>
State <span class="math inline">\(i\)</span> is recurent if and only if
<span class="math display">\[\sum_{n=1}^\infty (T^n)_{ii}=\infty.\]</span></p>
<p>State <span class="math inline">\(i\)</span> is transient if and only if
<span class="math display">\[\sum_{n=1}^\infty (T^n)_{ii}&lt;\infty.\]</span></p>
</div>
</div>
<div id="limiting-probabilities" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Limiting probabilities<a href="markov-chains.html#limiting-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let <span class="math inline">\(\tau_{ij}\)</span> be the number of steps to first hit state <span class="math inline">\(j\)</span> when starting in state <span class="math inline">\(i\)</span> and <span class="math inline">\(\tau_i\)</span> the return time to state <span class="math inline">\(i\)</span> (the number of steps to next be in state <span class="math inline">\(i\)</span> when starting in state <span class="math inline">\(i\)</span>):
<span class="math display">\[\tau_{ij}=\min\{n\mid X_n=j\},\]</span>
<span class="math display">\[\tau_{i}=\min\{n\mid X_n=i\},\]</span></p>
<p>Let <span class="math inline">\(m_{ij}=\mathsf E(\tau_{ij}\mid X_0=i)\)</span> and <span class="math inline">\(m_{i}=\mathsf E(\tau_{i}\mid X_0=i)\)</span>.</p>
<p>Now we investigate the proportion of time that the chain spends in state <span class="math inline">\(i\)</span>.</p>
<p><strong>[..to be continued…]</strong></p>
<div id="limiting-distributions" class="section level3 hasAnchor" number="8.6.1">
<h3><span class="header-section-number">8.6.1</span> Limiting distributions<a href="markov-chains.html#limiting-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="stationary-distributions" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Stationary distributions<a href="markov-chains.html#stationary-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A stationary distribution is any distribution that if it is the initial distribution for the process, then it is the distribution at all future times. I.e. <span class="math inline">\(\boldsymbol \pi\)</span> is a stationary distribution if, given <span class="math inline">\(\mathbf p_0=\boldsymbol \pi\)</span>, then <span class="math inline">\(\mathbf p_n=\boldsymbol \pi\)</span> for all time <span class="math inline">\(n\)</span>. This means it must satisfy the equation:
<span class="math display">\[\boldsymbol \pi =\boldsymbol \pi T.\]</span>
Note that <span class="math inline">\(\boldsymbol \pi\)</span> is a probability distribution on the state space:
<span class="math display">\[\boldsymbol \pi=(\pi_0,\pi_1,\pi_2,\ldots,\pi_m)\]</span>
with <span class="math inline">\(\sum_{j=0}^m \pi_j=1\)</span>.</p>
<p>The equation <span class="math inline">\(\boldsymbol \pi =\boldsymbol \pi T\)</span> tells us that <span class="math inline">\(\boldsymbol \pi\)</span> is a left eigenvector of <span class="math inline">\(T\)</span> with eigenvalue one. In linear algebra, it is more common to deal with column vectors and multiplication with matrices on the left and column vectors on the right, but, in Markov chain theory, it is more common to have row vectors on the left and matrices on the right. This means, that when you have encountered eigenvalues and eigenvectors in the past it was probably with that former convention.</p>
<div class="thmbox">
<p><strong>Theorem.</strong> Any convex combination of stationary distributions is also a stationary distribution. A convex combination is a linear combination where the coefficients sum to one. For example, if <span class="math inline">\(\boldsymbol \pi_1\)</span> and <span class="math inline">\(\boldsymbol \pi_2\)</span> are stationary distributions for some Markov chain, then <span class="math inline">\(a\boldsymbol \pi_1+(1-a)\boldsymbol \pi_2\)</span> is also a stationary distribution for any <span class="math inline">\(a\in[0,1]\)</span>.</p>
</div>
<div class="thmbox">
<p><strong>Theorem.</strong> A Markov chain with a finite state space that is irreducible and aperiodic has a single unique stationary distribution. A Markov chain that is periodic or reducible may have multiple stationary distributions or a single one only.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong> (<span class="math inline">\(2\times 2\)</span> stationary distribution)
Consider transition matrix
<span class="math display">\[T=\begin{pmatrix}1-b &amp; b\\a &amp; 1-a\end{pmatrix}.\]</span>
This matrix is irreducible if and only if both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are positive (and hence has a single unique stationary distribution. Otherwise it is reducible. It is aperiodic if and only if both <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are less than one.</p>
</div>
<div id="stationary-distributions-for-reducible-chains" class="section level3 hasAnchor" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> Stationary distributions for reducible chains<a href="markov-chains.html#stationary-distributions-for-reducible-chains" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A finite state Markov chain will always have at least one recurrent state or class of states. This is because the chain “must get absorbed somewhere” so-to-speak. An chain with infinitely-many states doesn’t have to behave this way. Consider the chain that just goes form state <span class="math inline">\(i\)</span> to state <span class="math inline">\(i+1\)</span> deterministically (with probability one). It will never settle down in any state and does not have any limiting or stationary distributions. The SSRW also doesn’t have limiting or stationary distributions as the probability of finding it in any particular state decays to zero as time goes on.</p>
<p>For the finite state space case, we can find stationary distributions by considering each recurrent class on its own and extracting the part of the transition matrix corresponding to the states in that recurrent class alone.</p>
<p>Let <span class="math inline">\(C\)</span> be a recurrent class of states, and define <span class="math inline">\(T_C\)</span> as the restriction of <span class="math inline">\(T\)</span> to <span class="math inline">\(C\)</span>. Furthermore, lets keep the original states as indices for <span class="math inline">\(T_C\)</span>. This means that <span class="math inline">\((T_C)_{ij} =T_{ij}\)</span> for all <span class="math inline">\(i,j\in C\)</span> and <span class="math inline">\((T_C)_{ij}\)</span> is left undefined if <span class="math inline">\(i\not\in C\)</span> or <span class="math inline">\(j\not\in C\)</span>. If <span class="math inline">\(C=S\)</span> the entire state space, then <span class="math inline">\(T_C=T\)</span> simply. Any convex combination of stationary distributions found in this way, will also be a stationary distribution.</p>
<div class="exbox">
<p><strong>Example.</strong>
transition matrix
<span class="math display">\[T=\begin{pmatrix}
0.5 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.5 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.25 &amp; 0 &amp; 0.5 &amp; 0.25 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0.25 &amp; 0.25 &amp; 0.5 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.5 &amp; 0.5\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0
\end{pmatrix}\]</span>
has transient class <span class="math inline">\(\{2,3\}\)</span> and recurrent classes <span class="math inline">\(\{0,1\}\)</span> and <span class="math inline">\(\{4,5\}\)</span>.</p>
<p>The restriction to <span class="math inline">\(\{0,1\}\)</span> is
<span class="math display">\[T_{\{0,1\}}=\begin{pmatrix}
0.5 &amp; 0.5 \\
0.5 &amp; 0.5
\end{pmatrix}.\]</span>
This has stationary distribution <span class="math inline">\((1/2,1/2)\)</span>. This means that <span class="math inline">\((1/2,1/2,0,0,0,0)\)</span> is a stationary distribution for the original <span class="math inline">\(T\)</span>.</p>
<p>Now, the restriction of <span class="math inline">\(T\)</span> to <span class="math inline">\(\{4,5\}\)</span> is
<span class="math display">\[T_{\{4,5\}}=\begin{pmatrix}
0.5 &amp; 0.5 \\
1 &amp; 0
\end{pmatrix}\]</span>
and has stationary distribution <span class="math inline">\((2/3,1/3)\)</span>. This means that <span class="math inline">\((0,0,0,0,2/3,1/3)\)</span> is a stationary distribution for the original <span class="math inline">\(T\)</span>.</p>
<p>Note that, implicitly, we are indexing <span class="math inline">\(T_{\{4,5\}}\)</span> by <span class="math inline">\(4\)</span> and <span class="math inline">\(5\)</span>, e.g. <span class="math inline">\((T_{\{4,5\}})_{44}=T_{44}\)</span> and <span class="math inline">\((T_{\{4,5\}})_{45}=T_{45}\)</span>, etc. But <span class="math inline">\((T_{\{4,5\}})_{40}\)</span>, <span class="math inline">\((T_{\{4,5\}})_{41}\)</span>, etc. are left undefined. This is just to keep the numerical labels for our states consistent.</p>
</div>
</div>
<div id="r-code-for-finding-stationary-distributions" class="section level3 hasAnchor" number="8.7.2">
<h3><span class="header-section-number">8.7.2</span> R code for finding stationary distributions<a href="markov-chains.html#r-code-for-finding-stationary-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here we continue with the <span class="math inline">\(3\times3\)</span> transition matrix used above and find its stationary distribution. First we enter the matrix and find all left (row) eigenvectors using the <code>eigen()</code> method. Note that we must first transpose the matrix with <code>t()</code>. We would get right (column) eigenvectors with <code>eigen(TM)</code>, so we instead need to use <code>eigen(t(TM))</code>.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="markov-chains.html#cb52-1" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,</span>
<span id="cb52-2"><a href="markov-chains.html#cb52-2" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.0</span>,<span class="fl">0.3</span>,<span class="fl">0.7</span>,</span>
<span id="cb52-3"><a href="markov-chains.html#cb52-3" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="fl">0.0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">3</span>)</span>
<span id="cb52-4"><a href="markov-chains.html#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(<span class="fu">t</span>(TM))</span></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1]  1.0000000 -0.4316625  0.2316625
## 
## $vectors
##            [,1]       [,2]       [,3]
## [1,] -0.5499719 -0.4378009 -0.8157654
## [2,] -0.6285394 -0.3779645  0.3779645
## [3,] -0.5499719  0.8157654  0.4378009</code></pre>
<p>Eigenvectors int eh above R output are listed as columns. The first column goes with the first eigenvalue in the list, etc. We can see that there is one eigenvector that has eigenvalue one. Note that it has all negative entries, that’s ok, we just need to turn it into a probability distribution with</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="markov-chains.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(<span class="fu">t</span>(TM))<span class="sc">$</span>vectors[,<span class="dv">1</span>] <span class="ot">-&gt;</span> pivec</span>
<span id="cb54-2"><a href="markov-chains.html#cb54-2" aria-hidden="true" tabindex="-1"></a>pivec <span class="ot">&lt;-</span> pivec<span class="sc">/</span><span class="fu">sum</span>(pivec)</span>
<span id="cb54-3"><a href="markov-chains.html#cb54-3" aria-hidden="true" tabindex="-1"></a>pivec</span></code></pre></div>
<pre><code>## [1] 0.3181818 0.3636364 0.3181818</code></pre>
<p>Then we can check that it does indeed work with the following calculation of <span class="math inline">\(\boldsymbol \pi T-\boldsymbol \pi\)</span> which should give us the zero vector.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="markov-chains.html#cb56-1" aria-hidden="true" tabindex="-1"></a>pivec <span class="sc">%*%</span> TM <span class="sc">-</span> pivec</span></code></pre></div>
<pre><code>##              [,1]         [,2]          [,3]
## [1,] 5.551115e-17 2.775558e-16 -3.330669e-16</code></pre>
<p>Notice that we didn’t exactly get zeros. That is typical, and normally (for many computations) something on the order of <span class="math inline">\(10^{-16}\)</span> or smaller indicates the actual value is zero. There are times when that isn’t true though, so understanding the theory is very important!</p>
<div class="exbox">
<p><strong>Example.</strong> (a reducible matrix with a unique stationary distribution)
Consider the transition matrix
<span class="math display">\[T=\begin{pmatrix}
0.5 &amp; 0.3 &amp; 0.2\\
0 &amp; 0.3 &amp; 0.7\\
0 &amp; 0 &amp; 1
\end{pmatrix}.\]</span>
There is only a single absorbing state, <span class="math inline">\(\{2\}\)</span>, and we have transient class <span class="math inline">\(\{0,1\}\)</span>. Trying to find stationary distributions will show that <span class="math inline">\((0,0,1)\)</span> is the only possibility. Raising this matrix to a large power in R will give back a matrix where each row is (approximately) <span class="math inline">\((0,0,1)\)</span> as well. In this case, <span class="math inline">\((0,0,1)\)</span> is the limiting distribution, no matter which state we start the chain in.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong> (a reducible matrix with a multiple stationary distributions)
Consider the transition matrix
<span class="math display">\[T=\begin{pmatrix}
1 &amp; 0 &amp; 0\\
0.2 &amp; 0.3 &amp; 0.5\\
0 &amp; 0 &amp; 1
\end{pmatrix}.\]</span>
There are two absorbing states: <span class="math inline">\(\{0\}\)</span> and <span class="math inline">\(\{2\}\)</span>, and we have transient state <span class="math inline">\(\{1\}\)</span>. Trying to find stationary distributions will give <span class="math inline">\((1,0,0)\)</span> and <span class="math inline">\((0,0,1)\)</span>. If we start the chain in state <span class="math inline">\(1\)</span>, then the absorption probabilities are <span class="math inline">\(2/7\)</span> for absorption into state <span class="math inline">\(0\)</span> and <span class="math inline">\(5/7\)</span> for absorption into state <span class="math inline">\(2\)</span>. This gives stationary distribution <span class="math inline">\((2/7,0,5/7)\)</span> which is the convex combination <span class="math inline">\(2/7(1,0,0)+5/7(0,0,1)\)</span>. In fact <span class="math inline">\((a,0,1-a)\)</span> is a stationary distribution for any <span class="math inline">\(a\in[0,1]\)</span> so we have an “infinite family of stationary distributions.”</p>
</div>
<div class="exbox">
<p><strong>Example.</strong> (a reducible matrix with a multiple stationary distributions)
Consider the transition matrix
<span class="math display">\[T=\begin{pmatrix}
0.5 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.5 &amp; 0.5 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
0.25 &amp; 0 &amp; 0.5 &amp; 0.25 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0.25 &amp; 0.25 &amp; 0.5 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.5 &amp; 0.5\\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0
\end{pmatrix}.\]</span>
We have transient class <span class="math inline">\(\{2,3\}\)</span> and recurrent classes <span class="math inline">\(\{0,1\}\)</span> and <span class="math inline">\(\{4,5\}\)</span>. The chain will always get absorbed eventually into one the recurrent classes.</p>
<p>If we extract the transition matrix for a recurrent class, we can get the stationary probabilities for it. We do this fo class <span class="math inline">\(\{0,1\}\)</span>.
<span class="math display">\[T_{\{0,1\}}=\begin{pmatrix}
0.5 &amp; 0.5 \\
0.5 &amp; 0.5
\end{pmatrix}\]</span>
which has stationary distribution <span class="math inline">\((1/2,1/2)\)</span>. This means that <span class="math inline">\((1/2,1/2,0,0,0,0)\)</span> is a stationary distribution for the original <span class="math inline">\(T\)</span>.</p>
<p>Now for recurrent class ${4,5}, we get:
<span class="math display">\[T_{\{4,5\}}=\begin{pmatrix}
0.5 &amp; 0.5 \\
1 &amp; 0
\end{pmatrix}\]</span>
which has stationary distribution <span class="math inline">\((2/3,1/3)\)</span>. This means that <span class="math inline">\((0,0,0,0,2/3,1/3)\)</span> is a stationary distribution for the original <span class="math inline">\(T\)</span>.</p>
<p>These are the two basic stationary distributions, and any convex combination of them is also a stationary distribution.</p>
<p>Finding eigenvectors with R on examples like this can be misleading though. It will give you stationary distributions but not necessarily separated out by recurrent class like the above.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="markov-chains.html#cb58-1" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb58-2"><a href="markov-chains.html#cb58-2" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb58-3"><a href="markov-chains.html#cb58-3" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.25</span>,<span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.25</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb58-4"><a href="markov-chains.html#cb58-4" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,</span>
<span id="cb58-5"><a href="markov-chains.html#cb58-5" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,</span>
<span id="cb58-6"><a href="markov-chains.html#cb58-6" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">6</span>)</span>
<span id="cb58-7"><a href="markov-chains.html#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="fu">eigen</span>(<span class="fu">t</span>(TM))</span></code></pre></div>
<pre><code>## eigen() decomposition
## $values
## [1]  1.000000e+00  1.000000e+00  6.545085e-01 -5.000000e-01  9.549150e-02  1.110223e-16
## 
## $vectors
##           [,1]          [,2]       [,3]          [,4]        [,5]       [,6]
## [1,] 0.7071068  1.525695e-01  0.1172126 -5.719172e-18 -0.42281793 -0.7071068
## [2,] 0.7071068  1.525695e-01  0.3793081  2.859586e-18  0.52263170  0.7071068
## [3,] 0.0000000 -2.710180e-16 -0.6861748  2.496558e-17 -0.36112962  0.0000000
## [4,] 0.0000000  1.761617e-16 -0.4240793 -9.986232e-17  0.58432000  0.0000000
## [5,] 0.0000000  8.733591e-01  0.3479348 -7.071068e-01 -0.05179612  0.0000000
## [6,] 0.0000000  4.366795e-01  0.2657985  7.071068e-01 -0.27120803  0.0000000</code></pre>
<p>Notice the first eigenvector is as desired, but we just need to normalize it to sum to one. The second eigenvector, after ignoring the two tiny order <span class="math inline">\(10^{-16}\)</span> terms in the middle, is actually a linear combination of the two stationary distributions we found above. Another problem that can arise when doing this in R is that it might give you a linear combination using a mix of positive and negative coefficients! So pay attention and take care!</p>
</div>
</div>
</div>
<div id="probability-of-absorption-time-to-absorption" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Probability of absorption &amp; time to absorption<a href="markov-chains.html#probability-of-absorption-time-to-absorption" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If we have a chain with a transient class and more than one recurrent class, we may wish to know the probability it is absorbed into either recurrent class, given some initial transient state. We can accomplish this numerically as follows.</p>
<p>If <span class="math inline">\(T\)</span> is a transition matrix with recurrent class <span class="math inline">\(C\)</span> and transient state <span class="math inline">\(i\)</span>, then we can raise <span class="math inline">\(T\)</span> to a large power in R and the absorbing probability into class <span class="math inline">\(C\)</span> from initial state <span class="math inline">\(i\)</span> is <span class="math inline">\(\sum_{j\in C} T^\infty_{ij}\)</span>.</p>
<div class="exbox">
<p><strong>Example.</strong></p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="markov-chains.html#cb60-1" aria-hidden="true" tabindex="-1"></a>TM <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb60-2"><a href="markov-chains.html#cb60-2" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.5</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb60-3"><a href="markov-chains.html#cb60-3" aria-hidden="true" tabindex="-1"></a>               <span class="fl">0.25</span>,<span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.25</span>,<span class="dv">0</span>,<span class="dv">0</span>,</span>
<span id="cb60-4"><a href="markov-chains.html#cb60-4" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.5</span>,<span class="dv">0</span>,</span>
<span id="cb60-5"><a href="markov-chains.html#cb60-5" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>,</span>
<span id="cb60-6"><a href="markov-chains.html#cb60-6" aria-hidden="true" tabindex="-1"></a>               <span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>),<span class="at">byrow=</span>T,<span class="at">nrow=</span><span class="dv">6</span>)</span>
<span id="cb60-7"><a href="markov-chains.html#cb60-7" aria-hidden="true" tabindex="-1"></a>TM <span class="sc">%^%</span> <span class="dv">100</span></span></code></pre></div>
<pre><code>##      [,1] [,2]         [,3]         [,4]      [,5]      [,6]
## [1,]  0.5  0.5 0.000000e+00 0.000000e+00 0.0000000 0.0000000
## [2,]  0.5  0.5 0.000000e+00 0.000000e+00 0.0000000 0.0000000
## [3,]  0.3  0.3 2.825085e-19 1.745999e-19 0.2666667 0.1333333
## [4,]  0.1  0.1 1.745999e-19 1.079087e-19 0.5333333 0.2666667
## [5,]  0.0  0.0 0.000000e+00 0.000000e+00 0.6666667 0.3333333
## [6,]  0.0  0.0 0.000000e+00 0.000000e+00 0.6666667 0.3333333</code></pre>
<p>We can see that starting the chain in state <span class="math inline">\(2\)</span> (the third row) gives an approximate limiting distribution of
<span class="math display">\[(0.3,  0.3, 2.8(10)^{-19}, 1.7(10)^{-19}, 0.2667, 0.1333).\]</span>
Summing the first two components gives <span class="math inline">\(0.6\)</span> probability of being absorbed into <span class="math inline">\(\{0,1\}\)</span> and the last two gives <span class="math inline">\(0.4\)</span> probability of absorption into class <span class="math inline">\(\{4,5\}\)</span>.</p>
</div>
<p>To find the exact absorption probabilities, we use linear algebra. Let <span class="math inline">\(S_{trans}\)</span> be the set of transient states and <span class="math inline">\(S_{rec}\)</span> the set of recurrent states, so that <span class="math inline">\(S=S_{trans}\cup S_{rec}\)</span>. Note that these are not necessarily classes as we could have multiple recurrent and multiple transient classes.</p>
<p>Now define the matrices <span class="math inline">\(T_{trans}=T_{S_{trans}}\)</span> which is just <span class="math inline">\(T\)</span> restricted to the transient states. Now define <span class="math inline">\(R\)</span> to be the matrix giving us transitions form transient states to recurrent states, that is, <span class="math inline">\(R_{ij}\)</span> is only defined for <span class="math inline">\(i\in S_{trans}\)</span> and <span class="math inline">\(j\in S_{rec}\)</span>. Note that <span class="math inline">\(R\)</span> is not necessarily a square matrix since the number of transient and recurrent states does not have to be equal!</p>
<p>Now consider the matrix
<span class="math display">\[B=(I-T_{trans})^{-1}R.\]</span>
Note that <span class="math inline">\(B_{ij}\)</span> is defined only for <span class="math inline">\(i\)</span> transient and <span class="math inline">\(j\)</span> recurrent. Also note that, although we are staying consistent with the original state space for our numerical labels for indices here, that the number of rows and columns is appropriate for this matrix multiplication to make sense.</p>
<p>If state <span class="math inline">\(j\)</span> is in a recurrent class on its own, then <span class="math inline">\(B_{ij}\)</span> is the probability of absorption into state <span class="math inline">\(j\)</span> with initial state <span class="math inline">\(i\)</span>. If we have a class <span class="math inline">\(C\)</span> of recurrent states, then <span class="math inline">\(\sum_{j\in C}B_{ij}\)</span> is the probability of being absorbed into that class from initial transient state <span class="math inline">\(i\)</span>.</p>
<div class="exbox">
<p><strong>Example.</strong>
Continuing with the same <span class="math inline">\(6\times6\)</span> matrix above, we have
<span class="math display">\[T_{trans}=\begin{pmatrix}
0.5 &amp; 0.25 \\
0.25 &amp; 0.25
\end{pmatrix}.\]</span>
Note that this is not a transition matrix!
And we have that <span class="math inline">\(R\)</span> is the rest of the rows corresponding to teh transient states:
<span class="math display">\[R=\begin{pmatrix}
0.25 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0.5 &amp; 0
\end{pmatrix}.\]</span>
Now
<span class="math display">\[\begin{aligned}
B&amp;=(I-T_{trans})^{-1}R\\
&amp;=\left(\begin{pmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{pmatrix}-
\begin{pmatrix}
0.5 &amp; 0.25 \\
0.25 &amp; 0.25
\end{pmatrix}\right)^{-1}
\begin{pmatrix}
0.25 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0.5 &amp; 0
\end{pmatrix}\\
&amp;=
\begin{pmatrix}
0.5 &amp; -0.25 \\
-0.25 &amp; 0.75
\end{pmatrix}^{-1}
\begin{pmatrix}
0.25 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0.5 &amp; 0
\end{pmatrix}\\
&amp;=
\frac{1}{(0.75)(0.5)-(0.25)^2}\begin{pmatrix}
0.75 &amp; 0.25 \\
0.25 &amp; 0.5
\end{pmatrix}
\begin{pmatrix}
0.25 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0.5 &amp; 0
\end{pmatrix}\\
&amp;=
\begin{pmatrix}
2.4 &amp; 0.8 \\
0.8 &amp; 1.6
\end{pmatrix}
\begin{pmatrix}
0.25 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0.5 &amp; 0
\end{pmatrix}\\
&amp;=
\begin{pmatrix}
0.6 &amp; 0 &amp; 0.4 &amp; 0 \\
0.2 &amp; 0 &amp; 0.8 &amp; 0
\end{pmatrix}.
\end{aligned}\]</span>
Hence, we can now see that, for example, the probability of state <span class="math inline">\(2\)</span> being absorbed into class <span class="math inline">\(\{0,1\}\)</span> is exactly <span class="math inline">\(B_{20}+B_{21}=0.6+0=0.6\)</span>. Even though the matrix <span class="math inline">\(B\)</span> has many zeros, it is not correct to interpret <span class="math inline">\(B_{20}=0.6\)</span> as the probability of being absorbed into state <span class="math inline">\(0\)</span>, for example. An absorption probability only makes sense when calculated over an entire recurrent class.</p>
</div>
</div>
<div id="gamblers-ruin" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Gambler’s ruin<a href="markov-chains.html#gamblers-ruin" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="summary-5" class="section level2 unnumbered hasAnchor">
<h2>Summary<a href="markov-chains.html#summary-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="defbox">
<p><strong>Summary of notation, formulas, and terminology</strong></p>
<p>Transition matrix: <span class="math inline">\(T_{ij}=P(X_n=j \mid X_{n-1}=i)\)</span></p>
<p>Markov property (memorylessness):
<span class="math display">\[P(X_n=j \mid X_{n-1}=i,X_{n-2}=\ell_{n-2},\ldots,X_{1}=\ell_{1},X_{0}=\ell_{0})=P(X_n=j \mid X_{n-1}=i)=T_{ij}\]</span>
Matrix multiplication: <span class="math inline">\(\mathbf p_n =\mathbf p_{n-1} T\)</span></p>
<p><span class="math inline">\(N_i\sim\mathsf{Geom}(p=1-f_i)\)</span>, <span class="math inline">\(E(N_i)=\frac{1}{1-f_i}\)</span></p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="limit-theorems.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jstover79/stochproc423/edit/master/08-markov-proc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/jstover79/stochproc423/blob/master/08-markov-proc.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
