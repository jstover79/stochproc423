<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Random variables and distributions | Math 423 Stochastic Processes Course Notes</title>
  <meta name="description" content="Chapter 3 Random variables and distributions | Math 423 Stochastic Processes Course Notes" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Random variables and distributions | Math 423 Stochastic Processes Course Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Random variables and distributions | Math 423 Stochastic Processes Course Notes" />
  
  
  

<meta name="author" content="Joseph Stover" />


<meta name="date" content="2023-03-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="counting-sets-and-probability-basics.html"/>
<link rel="next" href="conditional-expectation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script type="text/javascript">
  function unhide(divID) {
    var item = document.getElementById(divID);
    if (item) {
      item.className=(item.className=='hiddendiv')?'unhiddendiv':'hiddendiv';
    }
  }
</script> 


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Stochastic Processes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1</b> Introduction to R and RStudio</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#getting-access-to-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> Getting access to R and RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#r-basics"><i class="fa fa-check"></i><b>1.2</b> R basics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#data-structures-vectors-matrices"><i class="fa fa-check"></i><b>1.2.1</b> Data structures, vectors, matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#installing-and-using-packages-in-r"><i class="fa fa-check"></i><b>1.3</b> Installing and using packages in R</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#random-variables"><i class="fa fa-check"></i><b>1.4</b> Random variables</a></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#basics-of-programming-r-scripts"><i class="fa fa-check"></i><b>1.5</b> Basics of programming, R scripts</a></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#importing-datasets-into-r"><i class="fa fa-check"></i><b>1.6</b> Importing datasets into R</a></li>
<li class="chapter" data-level="" data-path="introduction-to-r-and-rstudio.html"><a href="introduction-to-r-and-rstudio.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html"><i class="fa fa-check"></i><b>2</b> Counting, sets, and probability basics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#ticket-in-a-box-model-of-probability"><i class="fa fa-check"></i><b>2.1</b> Ticket-in-a-box model of probability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sampling-from-a-box-of-tickets"><i class="fa fa-check"></i><b>2.1.1</b> Sampling from a box of tickets</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#relative-area-model-of-probability"><i class="fa fa-check"></i><b>2.2</b> Relative area model of probability</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#one-dimension"><i class="fa fa-check"></i><b>2.2.1</b> One dimension</a></li>
<li class="chapter" data-level="2.2.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#two-or-more-dimensions"><i class="fa fa-check"></i><b>2.2.2</b> Two or more dimensions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>2.3</b> Sample Spaces and Events</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#sample-space"><i class="fa fa-check"></i><b>2.3.1</b> Sample space</a></li>
<li class="chapter" data-level="2.3.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#events"><i class="fa fa-check"></i><b>2.3.2</b> Events</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#set-operations"><i class="fa fa-check"></i><b>2.4</b> Set Operations</a></li>
<li class="chapter" data-level="2.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#venn-diagrams"><i class="fa fa-check"></i><b>2.5</b> Venn Diagrams</a></li>
<li class="chapter" data-level="2.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#counting-permutations-and-combinations"><i class="fa fa-check"></i><b>2.6</b> Counting, permutations, and combinations</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#multiplication-rule"><i class="fa fa-check"></i><b>2.6.1</b> Multiplication rule</a></li>
<li class="chapter" data-level="2.6.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#nk"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(n^k\)</span></a></li>
<li class="chapter" data-level="2.6.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#factorials"><i class="fa fa-check"></i><b>2.6.3</b> Factorials</a></li>
<li class="chapter" data-level="2.6.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#permutation"><i class="fa fa-check"></i><b>2.6.4</b> Permutation</a></li>
<li class="chapter" data-level="2.6.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#combination"><i class="fa fa-check"></i><b>2.6.5</b> Combination</a></li>
<li class="chapter" data-level="2.6.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#summary-of-counting"><i class="fa fa-check"></i><b>2.6.6</b> Summary of counting</a></li>
<li class="chapter" data-level="2.6.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#special-case-with-replacement-order-doesnt-matter-the-multiset"><i class="fa fa-check"></i><b>2.6.7</b> Special case: with replacement, order doesn’t matter: the multiset</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#probability"><i class="fa fa-check"></i><b>2.7</b> Probability</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#equally-likely-outcomes"><i class="fa fa-check"></i><b>2.7.1</b> Equally likely outcomes</a></li>
<li class="chapter" data-level="2.7.2" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#general-probability-theory"><i class="fa fa-check"></i><b>2.7.2</b> General probability theory</a></li>
<li class="chapter" data-level="2.7.3" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#independence"><i class="fa fa-check"></i><b>2.7.3</b> Independence</a></li>
<li class="chapter" data-level="2.7.4" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#conditional-probability"><i class="fa fa-check"></i><b>2.7.4</b> Conditional probability</a></li>
<li class="chapter" data-level="2.7.5" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#partitions"><i class="fa fa-check"></i><b>2.7.5</b> Partitions</a></li>
<li class="chapter" data-level="2.7.6" data-path="counting-sets-and-probability-basics.html"><a href="counting-sets-and-probability-basics.html#bayes-theorem"><i class="fa fa-check"></i><b>2.7.6</b> Baye’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html"><i class="fa fa-check"></i><b>3</b> Random variables and distributions</a>
<ul>
<li class="chapter" data-level="3.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#expectation-and-variance"><i class="fa fa-check"></i><b>3.1</b> Expectation and variance</a></li>
<li class="chapter" data-level="3.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#joint-distributions"><i class="fa fa-check"></i><b>3.2</b> Joint distributions</a></li>
<li class="chapter" data-level="3.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#independence-of-random-variables"><i class="fa fa-check"></i><b>3.3</b> Independence of random variables</a></li>
<li class="chapter" data-level="3.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#discrete-bernoulli-binomial-geometric-poisson"><i class="fa fa-check"></i><b>3.4</b> Discrete: Bernoulli, binomial, geometric, Poisson</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#bernoulli"><i class="fa fa-check"></i><b>3.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="3.4.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#binomial"><i class="fa fa-check"></i><b>3.4.2</b> Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#geometric"><i class="fa fa-check"></i><b>3.4.3</b> Geometric</a></li>
<li class="chapter" data-level="3.4.4" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#poisson"><i class="fa fa-check"></i><b>3.4.4</b> Poisson</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#continuous-uniform-exponential-normal"><i class="fa fa-check"></i><b>3.5</b> Continuous: Uniform, exponential, normal</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#uniform"><i class="fa fa-check"></i><b>3.5.1</b> Uniform</a></li>
<li class="chapter" data-level="3.5.2" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#exponential"><i class="fa fa-check"></i><b>3.5.2</b> Exponential</a></li>
<li class="chapter" data-level="3.5.3" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#normal"><i class="fa fa-check"></i><b>3.5.3</b> Normal</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="random-variables-and-distributions.html"><a href="random-variables-and-distributions.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-expectation.html"><a href="conditional-expectation.html"><i class="fa fa-check"></i><b>4</b> Conditional expectation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-distributions"><i class="fa fa-check"></i><b>4.1</b> Conditional distributions</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-expectation.html"><a href="conditional-expectation.html#conditional-expectation-1"><i class="fa fa-check"></i><b>4.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-expectation.html"><a href="conditional-expectation.html#random-conditional-expectation"><i class="fa fa-check"></i><b>4.3</b> (Random) conditional expectation</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="conditional-expectation.html"><a href="conditional-expectation.html#total-expectation"><i class="fa fa-check"></i><b>4.3.1</b> Total expectation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conditional-expectation.html"><a href="conditional-expectation.html#summary-2"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html"><i class="fa fa-check"></i><b>5</b> Intro Stochastic Processes</a>
<ul>
<li class="chapter" data-level="" data-path="intro-stochastic-processes.html"><a href="intro-stochastic-processes.html#summary-3"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="random-walks.html"><a href="random-walks.html"><i class="fa fa-check"></i><b>6</b> Random walks</a>
<ul>
<li class="chapter" data-level="6.1" data-path="random-walks.html"><a href="random-walks.html#the-simple-symmetric-random-walk-ssrw"><i class="fa fa-check"></i><b>6.1</b> The simple symmetric random walk (SSRW)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="random-walks.html"><a href="random-walks.html#definition-of-a-random-walk"><i class="fa fa-check"></i><b>6.1.1</b> Definition of a random walk</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="random-walks.html"><a href="random-walks.html#distribution-of-x_n"><i class="fa fa-check"></i><b>6.2</b> Distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="random-walks.html"><a href="random-walks.html#shift-invariance-memorylessness"><i class="fa fa-check"></i><b>6.3</b> Shift invariance &amp; memorylessness</a></li>
<li class="chapter" data-level="6.4" data-path="random-walks.html"><a href="random-walks.html#reflection-principle"><i class="fa fa-check"></i><b>6.4</b> Reflection principle</a></li>
<li class="chapter" data-level="6.5" data-path="random-walks.html"><a href="random-walks.html#maximum-state-reached"><i class="fa fa-check"></i><b>6.5</b> Maximum state reached</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="random-walks.html"><a href="random-walks.html#maximum-over-infinite-sample-paths-for-p12"><i class="fa fa-check"></i><b>6.5.1</b> Maximum over infinite sample paths for <span class="math inline">\(p&lt;1/2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="random-walks.html"><a href="random-walks.html#hitting-times"><i class="fa fa-check"></i><b>6.6</b> Hitting times</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-state-1"><i class="fa fa-check"></i><b>6.6.1</b> Hitting time for state <span class="math inline">\(1\)</span></a></li>
<li class="chapter" data-level="6.6.2" data-path="random-walks.html"><a href="random-walks.html#hitting-time-for-other-states"><i class="fa fa-check"></i><b>6.6.2</b> Hitting time for other states</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="random-walks.html"><a href="random-walks.html#return-time-to-state-0"><i class="fa fa-check"></i><b>6.7</b> Return time to state <span class="math inline">\(0\)</span></a></li>
<li class="chapter" data-level="" data-path="random-walks.html"><a href="random-walks.html#summary-4"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="limit-theorems.html"><a href="limit-theorems.html"><i class="fa fa-check"></i><b>7</b> Limit theorems</a>
<ul>
<li class="chapter" data-level="7.1" data-path="limit-theorems.html"><a href="limit-theorems.html#inequalities"><i class="fa fa-check"></i><b>7.1</b> Inequalities</a></li>
<li class="chapter" data-level="7.2" data-path="limit-theorems.html"><a href="limit-theorems.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2</b> Law of large numbers</a></li>
<li class="chapter" data-level="7.3" data-path="limit-theorems.html"><a href="limit-theorems.html#central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Central limit theorem</a></li>
<li class="chapter" data-level="7.4" data-path="limit-theorems.html"><a href="limit-theorems.html#borel-cantelli"><i class="fa fa-check"></i><b>7.4</b> Borel-Cantelli</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>8</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="8.1" data-path="markov-chains.html"><a href="markov-chains.html#graph-of-a-markov-chain"><i class="fa fa-check"></i><b>8.1</b> Graph of a Markov chain</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chains.html"><a href="markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>8.2</b> Classification of states</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chains.html"><a href="markov-chains.html#distribution-at-time-n"><i class="fa fa-check"></i><b>8.3</b> Distribution at time <span class="math inline">\(n\)</span></a></li>
<li class="chapter" data-level="8.4" data-path="markov-chains.html"><a href="markov-chains.html#return-times-and-hitting-probabilities"><i class="fa fa-check"></i><b>8.4</b> Return times and hitting probabilities</a></li>
<li class="chapter" data-level="" data-path="markov-chains.html"><a href="markov-chains.html#summary-5"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Math 423 Stochastic Processes Course Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-variables-and-distributions" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Random variables and distributions<a href="random-variables-and-distributions.html#random-variables-and-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="defbox">
<p><strong>Definition.</strong> A <strong>random variable</strong> <span class="math inline">\(X\)</span> is a variable where you must perform a random experiment to determine its value. The <strong>sample space</strong> <span class="math inline">\(S\)</span> is the set of numerical values that the random variable can take. An <strong>event</strong> is a subset of the sample space. A random variable can be either <em>discrete</em> (if it takes values in a discrete set such as <span class="math inline">\(\mathbb N\)</span>) or <em>continuous</em> (if it can take on any value in some interval).</p>
</div>
<div class="exbox">
<p><strong>Examples.</strong></p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(X\)</span> be the number of dots on the upper face of a dice roll.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> be the mass of a randomly selected person form a specific population.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> be the number of cars that pass by a given intersection during a particular day.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> be the number of radioactive decays in one hour of some particular material.</p></li>
</ol>
</div>
<div class="defbox">
<p><strong>Definition.</strong> A <strong>probability function</strong> allows us to calculate the probabilities of observing specific numerical values or ranges of values for random variable <span class="math inline">\(X\)</span>. A discrete random variable has a <strong>probability mass function</strong> (pmf) <span class="math inline">\(f_X(x)=P(X=x)\)</span>, and a continuous random variable has a <strong>probability density function</strong> (pdf) <span class="math inline">\(f_X(x)\)</span> which we must integrate to get probabilities <span class="math inline">\(P(a&lt;X&lt;b)=\int_a^b f_X(x)dx\)</span>. The <strong>cumulative distribution function</strong> (cdf) gives cumulative probabilities <span class="math inline">\(F_X(x)=P(X\leq x)\)</span>.</p>
</div>
<div id="expectation-and-variance" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Expectation and variance<a href="random-variables-and-distributions.html#expectation-and-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <strong>expected value</strong> of a random variable is also called its mean or average value, and denoted <span class="math inline">\(E(X)\)</span>.</p>
<div class="defbox">
<p><strong>Expected value.</strong></p>
<p>Discrete: <br>
  <span class="math inline">\(E(X)=\sum_x x f_X(x)\)</span><br>
  <span class="math inline">\(E[g(X)]=\sum_x g(x) f_X(x)\)</span></p>
<p>Continuous: <br>
  <span class="math inline">\(E(X)=\int_{-\infty}^\infty x f_X(x)~dx\)</span><br>
  <span class="math inline">\(E[g(X)]=\int_{-\infty}^\infty g(x) f_X(x)~dx\)</span></p>
</div>
<div class="defbox">
<p><strong>Variance.</strong></p>
<p><span class="math inline">\(\mathsf{Var}(X)=E[(X-E(X))^2]=E(X^2)-E(X)^2\)</span></p>
</div>
<div class="exbox">
<p>Let <span class="math inline">\(X\)</span> have pmf given below.
<span class="math display">\[
f_X(x)=\begin{cases}
0.5 &amp;\text{ if } x=0\\
0.3 &amp;\text{ if } x=1\\
0.2 &amp;\text{ if } x=2\\
\end{cases}
\]</span>
Then <span class="math inline">\(E(X)=0.5\cdot 0+0.3\cdot 1+0.2\cdot 2=0.7\)</span>. If we repeatedly and independently performed the random experiment that led us to observe random variable <span class="math inline">\(X\)</span>, then we would observe a sequence of <span class="math inline">\(0\)</span>’s, <span class="math inline">\(1\)</span>’s, and <span class="math inline">\(2\)</span>’s, and the average observed <span class="math inline">\(X\)</span>-value should be close to <span class="math inline">\(0.7\)</span>. The law of large numbers says that if we observe more and more <span class="math inline">\(X\)</span>-values, the average will actually get closer and closer to <span class="math inline">\(0.7.\)</span></p>
<p>The variance is <span class="math inline">\(Var(X)=E(X^2)-E(X)^2\)</span> so we need to calculate the expected value of the function <span class="math inline">\(X^2\)</span> which is <span class="math inline">\(E(X^2)=0.5\cdot0^2+0.3\cdot1^2+0.2\cdot2^2=1.1\)</span>. Thus <span class="math inline">\(Var(X)=1.1-0.7^2=1.1-0.49=0.61.\)</span></p>
</div>
</div>
<div id="joint-distributions" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Joint distributions<a href="random-variables-and-distributions.html#joint-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sometimes a random experiment yields more than one measurement. As an example, we might drill a water well and record several things such as the depth, width, flow rate, and density of the material drilled through. There could be dependencies such as a deeper well having a higher flow rate. Or maybe flow rate is completely independent of depth of the well. We can think of “flow rate” as one random variable, <span class="math inline">\(X\)</span>, and “depth” as another random variable, <span class="math inline">\(Y\)</span>. We could ask for the probabilities for <span class="math inline">\(X\)</span> or <span class="math inline">\(Y\)</span> alone, e.g. <span class="math inline">\(P(X=1.3)\)</span> or <span class="math inline">\(P(Y&gt;1000)\)</span> (these are called <strong>marginal probabilities</strong>), or we could ask for their <strong>joint probabilities</strong>, e.g. <span class="math inline">\(P(X=1.3 \text{ and } Y&gt;1000)\)</span>.</p>
<p>Normally we can list joint probabilities for two random variables, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, in a tabular format. We can list the <span class="math inline">\(X\)</span>-values along the first row <span class="math inline">\((x_1,x_2,...)\)</span>, the <span class="math inline">\(Y\)</span>-values along the first column <span class="math inline">\((y_1,y_2,...)\)</span>, and in the box for the <span class="math inline">\(i^{th}\)</span> column and <span class="math inline">\(j^{th}\)</span> row, we write the joint probability <span class="math inline">\(P(X=x_i,Y=y_j)\)</span>. See the example below.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>X</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>10</td>
<td>20</td>
</tr>
<tr class="even">
<td>Y</td>
<td>5</td>
<td>0.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td></td>
<td>500</td>
<td>0.1</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>Here we have <span class="math inline">\(P(X=10,Y=500)=0.1\)</span> for example. If we wish to calculate a marginal probability, then we must sum over the appropriate row or column, e.g. <span class="math inline">\(P(X=10)=P(X=10,Y=5)+P(X=10,Y=500)=0.5+0.1=0.6.\)</span> We can calculate the marginal pmf for <span class="math inline">\(X\)</span> by summing each column and the marginal pmf for <span class="math inline">\(Y\)</span> by summing each row.</p>
<p>In general the marginal probabilities are given by:
<span class="math display">\[f_X(x)=P(X=x)=\sum_y P(X=x,Y=y)=\sum_y f_{X,Y}(x,y)\]</span>
<span class="math display">\[f_Y(y)=P(Y=y)=\sum_x P(X=x,Y=y)=\sum_x f_{X,Y}(x,y).\]</span>
The above is using an example of <strong>partitioning</strong> the entire (joint) sample space. If we are interested in the even <span class="math inline">\(\{X=x\}\)</span> but we only know joint probabilities <span class="math inline">\(\{X=x,Y=y_j\}\)</span> for <span class="math inline">\(j=1,2,...,m\)</span> (assume there are <span class="math inline">\(m\)</span> total <span class="math inline">\(y\)</span>-values. Then we have a partition <span class="math inline">\(\{Y=y_1\},\ldots,\{Y=y_m\}\)</span>, and we can intersect <span class="math inline">\(\{X=x\}\)</span> with each of these to create a list of pairwise mutually exclusive events: <span class="math inline">\(\{X=x\}\cap\{Y=y_1\},\ldots,\{X=x\}\cap\{Y=y_m\}\)</span>. Now we calculate
<span class="math display">\[
\begin{aligned}
P(X=x)&amp;=P(\{X=x\}\cap\{Y=y_1\})+\cdots P(\{X=x\}\cap\{Y=y_m\})\\
&amp;=P(X=x,Y=y_1)+\cdots P(X=x,Y=y_m)\\
&amp;=\sum_{j=1}^m P(X=x,Y=y_j).
\end{aligned}
\]</span></p>
</div>
<div id="independence-of-random-variables" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Independence of random variables<a href="random-variables-and-distributions.html#independence-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When working with introductory probability the idea of <em>independent events</em> was covered. Events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if and only if <span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span>. Independence for random variables works similarly.</p>
<div class="defbox">
<p><strong>Definition.</strong> Random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <strong>independent</strong> if and only if every <span class="math inline">\(X\)</span>-event is independent of every <span class="math inline">\(Y\)</span>-event. That is for every subset of possible <span class="math inline">\(X\)</span>-values <span class="math inline">\(A\)</span> and every subset of possible <span class="math inline">\(Y\)</span>-values <span class="math inline">\(B\)</span> we have
<span class="math display">\[P(\{X\in A\}\cap \{Y\in B\})=P(X\in A)P(Y\in B).\]</span></p>
<p>For discrete random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, they are independent if and only if <span class="math inline">\(P(X=x,Y=y)=P(X=x)P(Y=y)\)</span> for all <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. That is the joint pmf must be exactly the product of the marginal pmfs.</p>
<p>For continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, they are independent if and only if their joint pdf is exactly the product of the marginal pdfs: <span class="math inline">\(f_{X,Y}(x,y)=f_X(x)f_Y(y)\)</span>.</p>
<p>Note that for independent random variables, independence requires that the allowable values for one variable must not be affected by the other variable, e.g. the set of possible <span class="math inline">\(X\)</span>-values must not depend on <span class="math inline">\(Y\)</span> in any way.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong> Let <span class="math inline">\(X\)</span> be the outcome of a fair 6-sided die and <span class="math inline">\(Y\)</span> be the outcome of a fair coin flip (<span class="math inline">\(0=~\)</span>tails,<span class="math inline">\(1=~\)</span>heads). Then we naturally think of them as independent, and they are in the technical sense of the term. It makes physical sense that the coin flip shouldn’t impact the die roll at all unless we are to use some contrived mechanism to force them to interact, e.g. if a machine were to control the force of the coin flip and die roll is some specific way so that the coin tended to be heads when the die tended to be even.</p>
<p>Here the marginal pmfs are <span class="math inline">\(f_X(x)=\frac16\)</span> for <span class="math inline">\(x=1,2,3,4,5,6\)</span> (and zero otherwise), and the pmf for <span class="math inline">\(Y\)</span> is <span class="math inline">\(f_Y(y)=\frac12\)</span> for <span class="math inline">\(y=0,1\)</span>. Their joint pmf is <span class="math inline">\(f_{X,Y}(x,y)=\frac1{12}\)</span> for <span class="math inline">\((x,y)=(1,0),\ldots,(6,0),(1,1),\ldots,(6,1)\)</span>.</p>
</div>
<div class="exbox">
<p><strong>Example.</strong> Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have joint probabilities given by the table below.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>X</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>10</td>
<td>20</td>
</tr>
<tr class="even">
<td>Y</td>
<td>5</td>
<td>0.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td></td>
<td>500</td>
<td>0.1</td>
<td>0.2</td>
</tr>
</tbody>
</table>
<p>You can actually look at the table and see that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent by seeing the <span class="math inline">\(Y\)</span>-values of 5 and 500 have equal probability mass under the <span class="math inline">\(X=20\)</span> column but unequal probability mass under the <span class="math inline">\(X=10\)</span> column. It isn’t always that simple though. Here is a joint pmf for an independent <span class="math inline">\(X,Y\)</span> pair, and it isn’t obvious they are independent.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th></th>
<th>X</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>10</td>
<td>20</td>
<td>30</td>
</tr>
<tr class="even">
<td>Y</td>
<td>5</td>
<td>0.36</td>
<td>0.18</td>
<td>0.06</td>
</tr>
<tr class="odd">
<td></td>
<td>500</td>
<td>0.24</td>
<td>0.12</td>
<td>0.04</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="discrete-bernoulli-binomial-geometric-poisson" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Discrete: Bernoulli, binomial, geometric, Poisson<a href="random-variables-and-distributions.html#discrete-bernoulli-binomial-geometric-poisson" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="bernoulli" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Bernoulli<a href="random-variables-and-distributions.html#bernoulli" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Situation/explanation: We perform a single random experiment that has only two outcomes: success and failure. Success and failure can mean almost anything. Success can mean a no vote on a particular election item, or it can mean we find a defective item, or it can mean a die roll has a particular value.</p>
<p><span class="math inline">\(X=0\)</span> for failure, <span class="math inline">\(X=1\)</span> for success, <span class="math inline">\(p=\)</span> probability of success.</p>
<p><span class="math display">\[X\sim \text{Bernoulli($p$)}\]</span>
<span class="math display">\[X=0,1\]</span>
<span class="math display">\[f_X(x)=
\begin{cases}
1-p &amp;\text{ if } x=0\\
p &amp;\text{ if } x=1
\end{cases}\]</span></p>
<p><span class="math display">\[E(X)=p\]</span>
<span class="math display">\[\text{Var}(X)=p(1-p)\]</span></p>
<p>In R:
<span class="math display">\[f(x) = P(X=x) = \texttt{dbinom($x$,size=$1$,prob=$p$)}.\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{pbinom($x$,size=$1$,prob=$p$)}.\]</span></p>
</div>
<div id="binomial" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Binomial<a href="random-variables-and-distributions.html#binomial" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Situation/explanation: We perform a fixed number of Bernoulli trials. Count the total number of successes.</p>
<p><span class="math inline">\(X=\)</span> number of successes out of <span class="math inline">\(n\)</span> Bernoulli trials with <span class="math inline">\(p=\)</span> probability of success.</p>
<p><span class="math display">\[X\sim \text{Bin($n$,$p$)}\]</span>
<span class="math display">\[X=0,1,2,3,\ldots,n\]</span>
<span class="math display">\[f_X(x)={n\choose x}p^x(1-p)^{n-x}\]</span></p>
<p><span class="math display">\[E(X)=np\]</span>
<span class="math display">\[\text{Var}(X)=np(1-p)\]</span></p>
<p>In R:
<span class="math display">\[f(x) = P(X=x) = \texttt{dbinom($x$,size=$n$,prob=$p$)}. \quad \text{ (pmf)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{pbinom($x$,size=$n$,prob=$p$)}.  \quad \text{ (cdf)}\]</span>
<span class="math display">\[\tilde{x}_q=F^{-1}(q) =\texttt{qbinom($q$,size=$n$,prob=$p$)}.  \quad \text{ ($q$100$^{th}$ percentile, inverse cdf)}\]</span></p>
</div>
<div id="geometric" class="section level3 hasAnchor" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Geometric<a href="random-variables-and-distributions.html#geometric" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Situation/explanation: We perform Bernoulli trials until we get our first success. Count the total number of trials (a bunch of failures, and one success).</p>
<p><span class="math inline">\(X=\)</span> total number of trials required to get a single success with <span class="math inline">\(p=\)</span> probability of success. (the count includes the success also)</p>
<p>Note that there is no fixed total number of trials here. Note: there is a single success, the last trial, the first <span class="math inline">\(x-1\)</span> trials are all failures.
<span class="math display">\[X\sim \text{Geom($p$)}\]</span>
<span class="math display">\[X=0,1,2,3,\ldots\]</span>
<span class="math display">\[f(x)=p(1-p)^{x-1}\]</span>
<span class="math display">\[F(x)=1-(1-p)^{x}\]</span>
<span class="math display">\[E(X)=\frac1p\]</span>
<span class="math display">\[\text{Var}(X)=\frac{(1-p)}{p^2}\]</span>
<!-- %$$\text{median } \tilde\mu=\left\lceil\frac{\ln(0.5)}{\ln(1-p)}\right\rceil \quad \text{ note that the $\lceil\cdot\rceil$ notation means to round up to next integer}$$ --></p>
<p>(Note that in R, the definition of <span class="math inline">\(X\)</span> varies from this. In R, <span class="math inline">\(X\)</span> is the number of failures. So when calculating in R for the Geometric random variable, we must either subtract 1 from the <span class="math inline">\(x\)</span> values in R for the pmf and cdf, but add 1 to the output from an R quantile.)</p>
In R:
<span class="math display">\[f(x) = P(X=x) = \texttt{dgeom($x$-1,prob=$p$)}.\quad \text{ (pmf)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{pgeom($x$-1,prob=$p$)}.\quad \text{ (cdf)}\]</span>
<span class="math display">\[\tilde{x}_q=F^{-1}(q) =\texttt{qgeom($q$,prob=$p$)+1}.  \quad \text{ ($q$100$^{th}$ percentile, inverse cdf)}\]</span>
</div>
<div id="poisson" class="section level3 hasAnchor" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Poisson<a href="random-variables-and-distributions.html#poisson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Situation/explanation: (1) Events arrive over time. Count the number of events in a given time interval. (2) Events are distributed over a spatial region randomly. Count the number of events in a given region.</p>
<p><span class="math inline">\(X=\)</span> number of events that occur at rate <span class="math inline">\(\lambda\)</span>. The rate can be thought of as “the number of events per unit time” or more generally, “number of events per unit.” Often it is the number of events per unit length or per unit time.</p>
<p><span class="math display">\[X\sim \text{Pois($\lambda$)}\]</span>
<span class="math display">\[X=0,1,2,\ldots\]</span>
<span class="math display">\[f_X(x)=\frac{e^{-\lambda}\lambda^x}{x!}\]</span>
<span class="math display">\[E(X)=\lambda\]</span>
<span class="math display">\[Var(X)=\lambda\]</span>
<!-- % \ thus \ $\sigma=\sqrt{\lambda}$ --></p>
<p>In R:
<span class="math display">\[f(x) = P(X=x) = \texttt{dpois($x$,lambda=$\lambda$)}. \quad \text{ (pmf)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{ppois($x$,lambda=$\lambda$)}.  \quad \text{ (cdf)}\]</span></p>
<span class="math display">\[\tilde{x}_q=F^{-1}(q) =\texttt{qpois($q$,lambda=$\lambda$)}.  \quad \text{ ($q$100$^{th}$ percentile, inverse cdf)}\]</span>
</div>
</div>
<div id="continuous-uniform-exponential-normal" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Continuous: Uniform, exponential, normal<a href="random-variables-and-distributions.html#continuous-uniform-exponential-normal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="uniform" class="section level3 hasAnchor" number="3.5.1">
<h3><span class="header-section-number">3.5.1</span> Uniform<a href="random-variables-and-distributions.html#uniform" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The random variable is the continuous analog of ``equally likely’’.</p>
<p><span class="math display">\[X\sim \text{Unif($a,b$)}\]</span>
<span class="math display">\[a \leq X \leq b\]</span>
<span class="math display">\[f_X(x)=\frac{1}{b-a} \quad \text{ for } x\in[a,b]\]</span>
<span class="math display">\[ F(x)=\frac{x-a}{b-a}\]</span>
<span class="math display">\[E(X)=\frac{a+b}{2}\]</span>
<span class="math display">\[\text{Var}(X)=\frac{1}{12}(b-a)^2\]</span></p>
<p>In R:
<span class="math display">\[f(x) = \texttt{dunif($x$,min=$a$,max=$a$)}. \quad \text{ (pdf, not probability mass)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{punif($x$,min=$a$,max=$a$)}.  \quad \text{ (cdf)}\]</span></p>
</div>
<div id="exponential" class="section level3 hasAnchor" number="3.5.2">
<h3><span class="header-section-number">3.5.2</span> Exponential<a href="random-variables-and-distributions.html#exponential" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose events happen at random times (or at random locations along a physical length). The length of time between events can be modeled by an .</p>
<p><span class="math inline">\(X=\)</span> wait time until an event.\
Rate parameter <span class="math inline">\(\lambda\)</span> is the number of events per unit time. It can be number of events per unit length as well; it just depends on the context. This is very closely related to the Poisson, as we’ll discuss later.</p>
<p>We can refer to <span class="math inline">\(X\)</span> as the <code>inter-arrival time,''</code>wait time,’’ or ``inter-event time.’’</p>
<p><span class="math display">\[X\sim \text{Exp($\lambda$)}\]</span>
<span class="math display">\[0 \leq X\]</span>
<span class="math display">\[f_X(x)=\lambda e^{-\lambda x} \quad \text{ for } x\geq 0\]</span>
<span class="math display">\[ F(x)=1-e^{-\lambda x}\]</span>
<span class="math display">\[E(X)=\frac{1}{\lambda}\]</span>
<span class="math display">\[\text{Var}(X)=\frac{1}{\lambda^2}\]</span></p>
<p>In R:
<span class="math display">\[f(x) = \texttt{dexp($x$,rate=$\lambda$)}. \quad \text{ (pdf, not probability mass)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{pexp($x$,rate=$\lambda$)}.  \quad \text{ (cdf)}\]</span></p>
<span class="math display">\[\tilde{x}_q=F^{-1}(q) =\texttt{qexp($q$,rate=$\lambda$)}.  \quad \text{ ($q$100$^{th}$ percentile, inverse cdf)}\]</span>
</div>
<div id="normal" class="section level3 hasAnchor" number="3.5.3">
<h3><span class="header-section-number">3.5.3</span> Normal<a href="random-variables-and-distributions.html#normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The normal distribution is one of the most important. Its probability density function is often called the “bell curve” or “Gaussian.”</p>
<p><span class="math display">\[X\sim \text{N($\mu$,$\sigma^2$)}\]</span>
<span class="math display">\[-\infty &lt; X &lt; \infty\]</span>
<span class="math display">\[f_X(x)=\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \quad \text{ for } x\in\mathbb R\]</span>
<span class="math display">\[ F(x)=\text{Unfortunately, can&#39;t be written down in a closed fomula}\]</span>
<span class="math display">\[E(X)=\mu\]</span>
<span class="math display">\[\text{Var}(X)=\sigma^2\]</span></p>
<p>In R:
<span class="math display">\[f(x) = \texttt{dnorm($x$,mean=$\mu$,sd=$\sigma$)}. \quad \text{ (pdf, not probability mass)}\]</span>
<span class="math display">\[F(x) = P(X\leq x) =\texttt{pnorm($x$,mean=$\mu$,sd=$\sigma$)}.  \quad \text{ (cdf)}\]</span></p>
<span class="math display">\[\tilde{x}_q=F^{-1}(q) =\texttt{qnorm($q$,mean=$\mu$,sd=$\sigma$)}.  \quad \text{ ($q$100$^{th}$ percentile, inverse cdf)}\]</span>
<div id="the-68-95-99.7-rule" class="section level4 hasAnchor" number="3.5.3.1">
<h4><span class="header-section-number">3.5.3.1</span> The 68-95-99.7 rule<a href="random-variables-and-distributions.html#the-68-95-99.7-rule" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For any normally distributed random variable, we have that there is approximately a 68% chance of being within 1 standard deviation of the mean, a 95% chance of being within 2 standard deviations of the mean, and a 99.7% chance of being within 3 standard deviations of the mean, i.e. that
<span class="math display">\[\begin{aligned}
P(\mu-\sigma &lt; X &lt; \mu+\sigma) &amp;\approx 68\%\\
P(\mu-2\sigma &lt; X &lt; \mu+2\sigma) &amp;\approx 95\%\\
P(\mu-3\sigma &lt; X &lt; \mu+3\sigma) &amp;\approx 99.7\%
\end{aligned}\]</span></p>
</div>
</div>
</div>
<div id="summary-1" class="section level2 unnumbered hasAnchor">
<h2>Summary<a href="random-variables-and-distributions.html#summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="defbox">
<p><strong>Summary of notation, formulas, and terminology</strong></p>
<p>Discrete RVs:<br>
  pmf <span class="math inline">\(f_X(x)=P(X=x)\)</span> <br>
  cdf <span class="math inline">\(F_X(x)=P(X\leq x)=\sum_{j\leq x} f_X(j)\)</span> <br>
  <span class="math inline">\(E(X)=\sum_{x} x P(X=x)=\sum_{x} x f_X(x)\)</span></p>
<p>Continuous RVs:<br>
  pdf <span class="math inline">\(f_X(x)\)</span>, <span class="math inline">\(P(a&lt;X&lt;b)=\int_a^b f_X(x)dx\)</span> <br>
  cdf <span class="math inline">\(F_X(x)=P(X\leq x)=\int_{-\infty}^x f_X(t)dt\)</span>, <span class="math inline">\(f_X(x)=\frac{d}{dx}F_X(x)\)</span><br>
  <span class="math inline">\(E(X)=\int_{-\infty}^\infty x f_X(x) dx\)</span></p>
<p>Variance: <span class="math inline">\(\textrm{Var}(X)=E[(X-E(X))^2]=E(X^2)-E(X)^2\)</span></p>
<p>Expected value of function of RV: <span class="math inline">\(E(h(X))=\sum_x h(x) f_X(x)\)</span> (discrete)<br>
  <span class="math inline">\(E(h(X))=\int_{-\infty}^\infty h(x) f_X(x) dx\)</span> (continuous)</p>
<p>Jointly distributed RVs: <br>
  <span class="math inline">\(f_{X,Y}(x,y)=P(X=x,Y=y)=P(\{X=x\}\cap\{Y=y\})\)</span></p>
<p>Independence of RVs: <br>
  <span class="math inline">\(X,Y\)</span> independent if and only if <span class="math inline">\(f_{X,Y}(x,y)=f_X(x) f_Y(y)\)</span>, <br>
  i.e. <span class="math inline">\(P(X=x,Y=y)=P(X=x)P(Y=y)\)</span>, for all <span class="math inline">\(x,y\)</span></p>
<p><strong>Discrete RVs</strong></p>
<p><em>Bernoulli:</em> models a process with only two outcomes<br>
  <span class="math inline">\(X\sim\mathsf{Bernoulli}(p)\)</span><br>
  <span class="math inline">\(f_X(x)=\begin{cases}p &amp;\text{ for } x=1\\ 1-p &amp;\text{ for } x=0\end{cases}\)</span><br>
  <span class="math inline">\(E(X)=p\)</span>, <span class="math inline">\(Var(X)=p(1-p)\)</span><br>
  R: <span class="math inline">\(P(X=x)=~\)</span><code>dbinom(x,size=1,prob=p)</code><br></p>
<p><em>Binomial:</em> models number of successes in <span class="math inline">\(n\)</span> independent trials with <span class="math inline">\(p\)</span> the probability of success for each trial<br>
  <span class="math inline">\(X\sim\mathsf{Binom}(n,p)\)</span><br>
  <span class="math inline">\(f_X(x)={n\choose x}p^x (1-p)^{n-x}\)</span>, <span class="math inline">\(x=0,1,\ldots,n\)</span><br>
  <span class="math inline">\(E(X)=np\)</span>, <span class="math inline">\(Var(X)=np(1-p)\)</span><br>
  R: <span class="math inline">\(P(X=x)=~\)</span><code>dbinom(x,size=n,prob=p)</code><br></p>
<p><em>Geometric:</em> models number of trials up to and including first success<br>
  <span class="math inline">\(X\sim\mathsf{Geom}(p)\)</span><br>
  <span class="math inline">\(f_X(x)=p(1-p)^{x-1}\)</span>, <span class="math inline">\(x\in\{1,2,\ldots\}=\mathbb N\)</span><br>
  <span class="math inline">\(E(X)=\frac1p\)</span>, <span class="math inline">\(Var(X)=\frac{1-p}{p^2}\)</span><br>
  R: <span class="math inline">\(P(X=x)=~\)</span><code>dgeom(x-1,prob=p)</code> (note that R only counts the failures)<br></p>
<p><em>Poisson:</em> models number of events over a continuous extent<br>
  <span class="math inline">\(X\sim\mathsf{Pois}(\lambda)\)</span><br>
  <span class="math inline">\(f_X(x)=\frac{e^{-\lambda}\lambda^x}{x!}\)</span>, <span class="math inline">\(x\in\{0,1,\ldots\}=\mathbb N_0\)</span><br>
  <span class="math inline">\(E(X)=\lambda\)</span>, <span class="math inline">\(Var(X)=\lambda\)</span><br>
  R: <span class="math inline">\(P(X=x)=~\)</span><code>dpois(x,lambda=λ)</code><br></p>
<p><strong>Continuous RVs</strong></p>
<p><em>Uniform:</em> models a continuous quantity that takes any value in an interval with equal likelihood<br>
  <span class="math inline">\(X\sim\mathsf{Unif}(a,b)\)</span><br>
  <span class="math inline">\(f_X(x)=\frac1{b-a}\)</span>, <span class="math inline">\(x\in(a,b)\)</span><br>
  <span class="math inline">\(E(X)=\frac12(a+b)\)</span>, <span class="math inline">\(Var(X)=\frac1{12}(b^2-a^2)\)</span><br>
  R: <span class="math inline">\(P(X\leq x)=~\)</span><code>punif(x,min=a,max=b)</code><br></p>
<p><em>Normal:</em> models quantity that is symmetrically distributed and random variation from many small additive contributions<br>
  <span class="math inline">\(X\sim\mathsf{N}(\mu,\sigma^2)\)</span><br>
  <span class="math inline">\(f_X(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span>, <span class="math inline">\(x\in\mathbb R\)</span><br>
  <span class="math inline">\(E(X)=\mu\)</span>, <span class="math inline">\(Var(X)=\sigma^2\)</span><br>
  R: <span class="math inline">\(P(X\leq x)=~\)</span><code>pnorm(x,mean=μ,sd=σ)</code><br></p>
<p><em>Exponential:</em> models wait times between events occurring at random times<br>
  <span class="math inline">\(X\sim\mathsf{Exp}(\lambda)\)</span><br>
  <span class="math inline">\(f_X(x)=\lambda e^{-\lambda x}\)</span>, <span class="math inline">\(x&gt;0\)</span><br>
  <span class="math inline">\(E(X)=\frac1\lambda\)</span>, <span class="math inline">\(Var(X)=\frac1{\lambda^2}\)</span><br>
  R: <span class="math inline">\(P(X\leq x)=~\)</span><code>pexp(x,rate=λ)</code><br></p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="counting-sets-and-probability-basics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conditional-expectation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jstover79/stochproc423/edit/master/03-rv-distr.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/jstover79/stochproc423/blob/master/03-rv-distr.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
